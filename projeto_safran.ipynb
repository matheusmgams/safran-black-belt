{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29849,"status":"ok","timestamp":1664850411625,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"zrkpE8KfcJqG","outputId":"06ccd664-63db-4e4b-ae63-1f82dab34935"},"outputs":[],"source":["# Inclusão das bibliotecas e módulos utilizados\n","import numpy as np  # Numpy: biblioteca para manipular vetores e matrizes\n","import pandas as pd # Pandas: biblioteca para manipular tabelas\n","import matplotlib.pyplot as plt # matplotlib: biblioteca para gráficos\n","import seaborn as sns # seaborn: biblioteca para gráficos\n","\n","# Pre-processamento\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.utils import resample\n","from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif, RFECV\n","from sklearn.decomposition import PCA\n","from imblearn.over_sampling import SMOTE\n","\n","# Métricas de desempenho\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer, roc_curve, roc_auc_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, auc\n","\n","# Classificadores\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC, SVR\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Pipeline\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n","from sklearn.compose import ColumnTransformer\n","from sklearn.base import TransformerMixin, BaseEstimator, clone\n","from sklearn.model_selection import cross_val_predict, cross_val_score\n","\n","# Árvore\n","from sklearn.tree import export_graphviz\n","import graphviz\n","\n","import sklearn as skl\n","from sklearn import svm\n","from sklearn import datasets\n","from sklearn.cluster import KMeans\n","\n","from statistics import mode\n","import jellyfish"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":23466,"status":"error","timestamp":1664850455528,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"sm3_um-bcJqJ","outputId":"3f8f3fcf-ed1e-4c3d-d599-93d9e1c36eaa"},"outputs":[],"source":["# IF DATA IS IN YOUR DRIVE\n","data = pd.read_excel('BLACK_BELT_DATABASE_CASE_FISRT_ANALISYS.xlsx', header=0)\n","data.info()\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iN5ZZv0NcJqK"},"outputs":[],"source":["# Semente aleatória para reproducibilidade dos experimentos\n","seed = 123"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlbTWqHBcJqL"},"outputs":[],"source":["# Função para pré-processar os dados\n","def preProcessingDataBase(data):\n","\n","    # PART_NUMBER\n","    data = data.drop('PART_NUMBER',axis=1)\n","\n","    # REV\n","    data = data.drop('REV',axis=1)\n","\n","    # DESCRIPTION\n","    data = data.drop('DESCRIPTION',axis=1) #MODIFY TO GROUP BY SIMILARITY\n","\n","    # RELEASED_DATE_1\n","    data = data.drop('RELEASED_DATE_1',axis=1)\n","\n","    # RELEASED_DATE\n","    data = data.drop('RELEASED_DATE',axis=1)\n","\n","    # QTN_REV_3D\n","    data['QTN_REV_3D'] = data['QTN_REV_3D'].dropna()\n","    data['QTN_REV_3D'] = (data['QTN_REV_3D']-data['QTN_REV_3D'].min())/(data['QTN_REV_3D'].max()-data['QTN_REV_3D'].min())\n","\n","    # MEAN_SIZE_3D\n","    data['MEAN_SIZE_3D'] = data['MEAN_SIZE_3D'].dropna()\n","    data['MEAN_SIZE_3D'] = (data['MEAN_SIZE_3D']-data['MEAN_SIZE_3D'].min())/(data['MEAN_SIZE_3D'].max()-data['MEAN_SIZE_3D'].min())\n","\n","    # DRAWING_CODE\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'].dropna()\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'][data['DRAWING_CODE'] != \"EL\"]\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'][data['DRAWING_CODE'] != \"\"]\n","    data = data.join(pd.get_dummies(data.pop('DRAWING_CODE')))\n","\n","    # ATP\n","    data['ATP'] = data['ATP'].dropna()\n","    data['ATP'] = data['ATP'][data['ATP'] != \"\"]\n","    data = data.join(pd.get_dummies(data.pop('ATP')))\n","\n","\n","    # QTN_REV_2D\n","    data['QTN_REV_2D'] = data['QTN_REV_2D'].dropna()\n","    data['QTN_REV_2D'] = (data['QTN_REV_2D']-data['QTN_REV_2D'].min())/(data['QTN_REV_2D'].max()-data['QTN_REV_2D'].min())\n","\n","\n","    # QTY_ECN_2D\n","    data['QTY_ECN_2D'] = data['QTY_ECN_2D'].dropna()\n","    data['QTY_ECN_2D'] = (data['QTY_ECN_2D']-data['QTY_ECN_2D'].min())/(data['QTY_ECN_2D'].max()-data['QTY_ECN_2D'].min())\n","\t\n","\n","    # MEAN_SIZE_2D\n","    data['MEAN_SIZE_2D'] = data['MEAN_SIZE_2D'].dropna()\n","    data['MEAN_SIZE_2D'] = (data['MEAN_SIZE_2D']-data['MEAN_SIZE_2D'].min())/(data['MEAN_SIZE_2D'].max()-data['MEAN_SIZE_2D'].min())\n","\n","\n","    # QTY_SHEETS\n","    data['QTY_SHEETS'] = data['QTY_SHEETS'].dropna()\n","    data['QTY_SHEETS'] = (data['QTY_SHEETS']-data['QTY_SHEETS'].min())/(data['QTY_SHEETS'].max()-data['QTY_SHEETS'].min())\n","\n","    # QTY_DIMENSIONS\n","    data['QTY_DIMENSIONS'] = data['QTY_DIMENSIONS'].dropna()\n","    data['QTY_DIMENSIONS'] = (data['QTY_DIMENSIONS']-data['QTY_DIMENSIONS'].min())/(data['QTY_DIMENSIONS'].max()-data['QTY_DIMENSIONS'].min())\n","\n","    # QTY_VIEWS\n","    data['QTY_VIEWS'] = data['QTY_VIEWS'].dropna()\n","    data['QTY_VIEWS'] = (data['QTY_VIEWS']-data['QTY_VIEWS'].min())/(data['QTY_VIEWS'].max()-data['QTY_VIEWS'].min())\n","\n","    # QTY_PART_LIST\n","    data['QTY_PART_LIST'] = data['QTY_PART_LIST'].dropna()\n","    data['QTY_PART_LIST'] = (data['QTY_PART_LIST']-data['QTY_PART_LIST'].min())/(data['QTY_PART_LIST'].max()-data['QTY_PART_LIST'].min())\n","\n","    # QTY_TEXT_INFORMATION\n","    data['QTY_TEXT_INFORMATION'] = data['QTY_TEXT_INFORMATION'].dropna()\n","    data['QTY_TEXT_INFORMATION'] = (data['QTY_TEXT_INFORMATION']-data['QTY_TEXT_INFORMATION'].min())/(data['QTY_TEXT_INFORMATION'].max()-data['QTY_TEXT_INFORMATION'].min())\n","\n","    # CREATED_ON\n","    data = data.drop('CREATED_ON',axis=1)\n","\n","    # CREATED_ON_1\n","    data = data.drop('CREATED_ON_1',axis=1)\n","\n","    # LEAD_TIME_1\n","    data = data.drop('LEAD_TIME_1',axis=1)\n","\n","    # LEAD_TIME\n","    data['LEAD_TIME'] = data['LEAD_TIME'].dropna()\n","    data['LEAD_TIME'] = data['LEAD_TIME'][data['LEAD_TIME'] > 0]\n","    data['LEAD_TIME'] = (data['LEAD_TIME']-data['LEAD_TIME'].min())/(data['LEAD_TIME'].max()-data['LEAD_TIME'].min())\n","\n","    # TRIM_AND_FINISH\n","    data['TRIM_AND_FINISH'] = data['TRIM_AND_FINISH'].dropna()\n","    data['TRIM_AND_FINISH'] = (data['TRIM_AND_FINISH']*-1)\n","\n","    # LEAD_TIME\n","    data['LEAD_TO_RELEASE'] = data['LEAD_TO_RELEASE'].dropna()\n","    data['LEAD_TO_RELEASE'] = data['LEAD_TO_RELEASE'][data['LEAD_TO_RELEASE'] > 0]\n","    data['LEAD_TO_RELEASE'] = (data['LEAD_TO_RELEASE']-data['LEAD_TO_RELEASE'].min())/(data['LEAD_TO_RELEASE'].max()-data['LEAD_TO_RELEASE'].min())\n","\n","    # DROP ANY ROW NULL\n","    data = data.dropna()\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7heJVrDIcJqM"},"outputs":[],"source":["# Pré-processing\n","data = preProcessingDataBase(data)\n","# sample_data = data.sample(frac=1)\n","data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"executionInfo":{"elapsed":348,"status":"ok","timestamp":1659053954952,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"zRzhfkKSDdwG","outputId":"c0a1631a-5f61-4f66-c2a3-ad8089ba430c"},"outputs":[],"source":["data.head(5)"]},{"cell_type":"markdown","metadata":{},"source":["Visualizar"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":68780,"status":"ok","timestamp":1659054905462,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"ZnqIQtlbP6Qu","outputId":"07f0ecbe-ae34-4891-840e-b823d6b1286b"},"outputs":[],"source":["## Data Without Pre-Processing\n","# =============================================================================\n","sns.pairplot(data, hue=\"QTY_SHEETS\", palette=\"tab10\")\n","# ============================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kM87fT6LfXJz"},"outputs":[],"source":["## Data Without Pre-Processing\n","# =============================================================================\n","sns.pairplot(data, hue=\"QTN_REV_3D\", palette=\"tab10\")\n","# ============================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"guiS2cf0ffOf"},"outputs":[],"source":["## Data Without Pre-Processing\n","# =============================================================================\n","sns.pairplot(data, hue=\"QTN_REV_2D\", palette=\"tab10\")\n","# ============================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":142369,"status":"ok","timestamp":1658805548913,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"sskkPp71SJ_D","outputId":"8302482e-41a4-4f19-afcd-1fbbdf0f2f87"},"outputs":[],"source":["## Data Without Pre-Processing\n","# =============================================================================\n","sns.pairplot(data, hue=\"DRAWING_CODE (3D)\", palette=\"tab10\")\n","# ============================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMLczrrCoKxq"},"outputs":[],"source":["## Data Without Pre-Processing\n","# =============================================================================\n","sns.pairplot(data, hue=\"QTY_ECN_2D\", palette=\"tab10\")\n","# ============================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrGUHq17Yvq6"},"outputs":[],"source":["# =============================================================================\n","sns.relplot(x='LEAD_TIME', y='QTY_ECN_2D', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","sns.relplot(x='QTY_PART_LIST', y='QTY_VIEWS', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","sns.relplot(x='LEAD_TIME', y='QTY_ECN_2D', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","\n","sns.relplot(x='QTN_REV_3D', y='QTY_ECN_2D', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","sns.relplot(x='QTN_REV_3D', y='QTY_ECN_2D', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","sns.relplot(x='QTY_ECN_2D', y='QTY_ECN_2D', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","\n","sns.relplot(x='QTY_VIEWS', y='QTY_ECN_2D', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","sns.relplot(x='QTY_DIMENSIONS', y='QTY_VIEWS', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","sns.relplot(x='QTY_TEXT_INFORMATION', y='QTY_VIEWS', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","\n","sns.relplot(x='MEAN_SIZE_2D', y='MEAN_SIZE_2D', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","sns.relplot(x='MEAN_SIZE_3D', y='QTY_VIEWS', hue='QTY_SHEETS', palette=\"tab10\", data=data)\n","# ============================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfhtQdrKIzAD"},"outputs":[],"source":["# =============================================================================\n","g = sns.PairGrid(data, diag_sharey=False)\n","g.map_upper(sns.scatterplot, s=15)\n","g.map_lower(sns.kdeplot)\n","g.map_diag(sns.kdeplot, lw=2)\n","# ============================================================================="]},{"cell_type":"markdown","metadata":{"id":"hHxyG8wb5_kw"},"source":["Trainning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOm8xfoToYak"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","from sklearn import neighbors, datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1659060096746,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"VHvdUid07Cpx","outputId":"a4eca575-eebb-46bf-d5ac-7ceab827dce5"},"outputs":[],"source":["data.head(5)\n","data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1659060321685,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"wQIoxN2UbD7f","outputId":"4ce4a4e1-18d3-4e03-a796-09d96934a0ba"},"outputs":[],"source":["data_new = data\n","\n","X = data_new.drop(columns=\"QTY_ECN_2D\")\n","y = data_new[\"QTY_ECN_2D\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","X.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import feature_column\n","from keras import layers\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# IF DATA IS IN YOUR DRIVE\n","data = pd.read_excel('BLACK_BELT_DATABASE_CASE_FISRT_ANALISYS.xlsx', header=0)\n","data.info()\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Função para pré-processar os dados\n","def preProcessingDataBase2(data):\n","\n","    # QTN_REV_3D\n","    data['QTN_REV_3D'] = data['QTN_REV_3D'].dropna()\n","    data['QTN_REV_3D'] = (data['QTN_REV_3D']-data['QTN_REV_3D'].min())/(data['QTN_REV_3D'].max()-data['QTN_REV_3D'].min())\n","\n","    # MEAN_SIZE_3D\n","    data['MEAN_SIZE_3D'] = data['MEAN_SIZE_3D'].dropna()\n","    data['MEAN_SIZE_3D'] = (data['MEAN_SIZE_3D']-data['MEAN_SIZE_3D'].min())/(data['MEAN_SIZE_3D'].max()-data['MEAN_SIZE_3D'].min())\n","\n","    # DRAWING_CODE\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'].dropna()\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'][data['DRAWING_CODE'] != \"EL\"]\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'][data['DRAWING_CODE'] != \"\"]\n","    #data = data.join(pd.get_dummies(data.pop('DRAWING_CODE')))\n","\n","    # ATP\n","    data['ATP'] = data['ATP'].dropna()\n","    data['ATP'] = data['ATP'][data['ATP'] != \"\"]\n","    #data = data.join(pd.get_dummies(data.pop('ATP')))\n","\n","\n","    # QTN_REV_2D\n","    data['QTN_REV_2D'] = data['QTN_REV_2D'].dropna()\n","    data['QTN_REV_2D'] = (data['QTN_REV_2D']-data['QTN_REV_2D'].min())/(data['QTN_REV_2D'].max()-data['QTN_REV_2D'].min())\n","\n","\n","    # QTY_ECN_2D\n","    data['QTY_ECN_2D'] = data['QTY_ECN_2D'].dropna()\n","    data['QTY_ECN_2D'] = (data['QTY_ECN_2D']-data['QTY_ECN_2D'].min())/(data['QTY_ECN_2D'].max()-data['QTY_ECN_2D'].min())\n","\t\n","\n","    # MEAN_SIZE_2D\n","    data['MEAN_SIZE_2D'] = data['MEAN_SIZE_2D'].dropna()\n","    data['MEAN_SIZE_2D'] = (data['MEAN_SIZE_2D']-data['MEAN_SIZE_2D'].min())/(data['MEAN_SIZE_2D'].max()-data['MEAN_SIZE_2D'].min())\n","\n","\n","    # QTY_SHEETS\n","    data['QTY_SHEETS'] = data['QTY_SHEETS'].dropna()\n","    data['QTY_SHEETS'] = (data['QTY_SHEETS']-data['QTY_SHEETS'].min())/(data['QTY_SHEETS'].max()-data['QTY_SHEETS'].min())\n","\n","    # QTY_DIMENSIONS\n","    data['QTY_DIMENSIONS'] = data['QTY_DIMENSIONS'].dropna()\n","    data['QTY_DIMENSIONS'] = (data['QTY_DIMENSIONS']-data['QTY_DIMENSIONS'].min())/(data['QTY_DIMENSIONS'].max()-data['QTY_DIMENSIONS'].min())\n","\n","    # QTY_VIEWS\n","    data['QTY_VIEWS'] = data['QTY_VIEWS'].dropna()\n","    data['QTY_VIEWS'] = (data['QTY_VIEWS']-data['QTY_VIEWS'].min())/(data['QTY_VIEWS'].max()-data['QTY_VIEWS'].min())\n","\n","    # QTY_PART_LIST\n","    data['QTY_PART_LIST'] = data['QTY_PART_LIST'].dropna()\n","    data['QTY_PART_LIST'] = (data['QTY_PART_LIST']-data['QTY_PART_LIST'].min())/(data['QTY_PART_LIST'].max()-data['QTY_PART_LIST'].min())\n","\n","    # QTY_TEXT_INFORMATION\n","    data['QTY_TEXT_INFORMATION'] = data['QTY_TEXT_INFORMATION'].dropna()\n","    data['QTY_TEXT_INFORMATION'] = (data['QTY_TEXT_INFORMATION']-data['QTY_TEXT_INFORMATION'].min())/(data['QTY_TEXT_INFORMATION'].max()-data['QTY_TEXT_INFORMATION'].min())\n","\n","    # LEAD_TIME\n","    data['LEAD_TIME'] = data['LEAD_TIME'].dropna()\n","    data['LEAD_TIME'] = data['LEAD_TIME'][data['LEAD_TIME'] > 0]\n","    data['LEAD_TIME'] = (data['LEAD_TIME']-data['LEAD_TIME'].min())/(data['LEAD_TIME'].max()-data['LEAD_TIME'].min())\n","\n","    # TRIM_AND_FINISH\n","    data['TRIM_AND_FINISH'] = data['TRIM_AND_FINISH'].dropna()\n","    data['TRIM_AND_FINISH'] = (data['TRIM_AND_FINISH']*-1)\n","\n","    # LEAD_TIME\n","    data['LEAD_TO_RELEASE'] = data['LEAD_TO_RELEASE'].dropna()\n","    data['LEAD_TO_RELEASE'] = data['LEAD_TO_RELEASE'][data['LEAD_TO_RELEASE'] > 0]\n","    data['LEAD_TO_RELEASE'] = (data['LEAD_TO_RELEASE']-data['LEAD_TO_RELEASE'].min())/(data['LEAD_TO_RELEASE'].max()-data['LEAD_TO_RELEASE'].min())\n","\n","    # DROP ANY ROW NULL\n","    data = data.dropna()\n","\n","    return data"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[],"source":["\n","FEATURES = [  \"QTN_REV_3D\",\n","              \"MEAN_SIZE_3D\",\n","              \"DRAWING_CODE\",\n","              \"ATP\",\n","              \"QTN_REV_2D\",\n","              \"MEAN_SIZE_2D\",\n","              \"QTY_SHEETS\",\n","              \"QTY_DIMENSIONS\",\n","              \"QTY_VIEWS\",\n","              \"QTY_PART_LIST\",\n","              \"QTY_TEXT_INFORMATION\",\n","              \"LEAD_TIME_1\",\n","              \"TRIM_AND_FINISH\",\n","              \"LEAD_TO_RELEASE\",\n","              \"QTY_ECN_2D\" ]\n","\n","QTN_REV_3D = tf.feature_column.numeric_column(\"QTN_REV_3D\")\n","MEAN_SIZE_3D = tf.feature_column.numeric_column(\"MEAN_SIZE_3D\")\n","DRAWING_CODE = tf.feature_column.categorical_column_with_vocabulary_list(\"DRAWING_CODE\", [\"True\", \"False\"])\n","ATP = tf.feature_column.categorical_column_with_vocabulary_list(\"ATP\", [\"True\", \"False\"])\n","QTN_REV_2D = tf.feature_column.numeric_column(\"QTN_REV_2D\")\n","MEAN_SIZE_2D = tf.feature_column.numeric_column(\"MEAN_SIZE_2D\")\n","QTY_SHEETS = tf.feature_column.numeric_column(\"QTY_SHEETS\")\n","QTY_DIMENSIONS = tf.feature_column.numeric_column(\"QTY_DIMENSIONS\")\n","QTY_VIEWS = tf.feature_column.numeric_column(\"QTY_VIEWS\")\n","QTY_PART_LIST = tf.feature_column.numeric_column(\"QTY_PART_LIST\")\n","QTY_TEXT_INFORMATION = tf.feature_column.numeric_column(\"QTY_TEXT_INFORMATION\")\n","LEAD_TIME_1 = tf.feature_column.numeric_column(\"LEAD_TIME_1\")\n","TRIM_AND_FINISH = tf.feature_column.numeric_column(\"TRIM_AND_FINISH\")\n","LEAD_TO_RELEASE = tf.feature_column.numeric_column(\"LEAD_TO_RELEASE\")\n","\n","feature_columns = [ QTN_REV_3D, \n","                    MEAN_SIZE_3D,\n","                    DRAWING_CODE,\n","                    ATP, \n","                    QTN_REV_2D,\n","                    MEAN_SIZE_2D, \n","                    QTY_SHEETS, \n","                    QTY_DIMENSIONS, \n","                    QTY_VIEWS, \n","                    QTY_PART_LIST, \n","                    QTY_TEXT_INFORMATION, \n","                    LEAD_TIME_1, \n","                    TRIM_AND_FINISH, \n","                    LEAD_TO_RELEASE ]\n","\n","def input_fn(num_epochs=None, shuffle=True, batch_size=100):\n","  df = pd.read_csv('BLACK_BELT_DATABASE_CASE_FISRT_ANALISYS.csv',\n","                    names=FEATURES,\n","                    dtype={'ATP': str},\n","                    skipinitialspace=True,\n","                    header=0)\n","  labels = df[\"QTY_ECN_2D\"]\n","  df = df.drop(columns=\"QTY_ECN_2D\", axis=0)\n","  return tf.compat.v1.estimator.inputs.pandas_input_fn( x=df,\n","                                                        y=labels,\n","                                                        batch_size=100,\n","                                                        num_epochs=3,\n","                                                        shuffle=True,\n","                                                        num_threads=5)"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Using default config.\n","WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmplxguyscd\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmplxguyscd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n","WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n"]},{"name":"stderr","output_type":"stream","text":["2022-10-04 23:29:56.227566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-04 23:29:56.228425: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InternalError'>, Graph execution error:\n","\n","Unsupported object type float\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n","INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmplxguyscd/model.ckpt.\n","INFO:tensorflow:/tmp/tmplxguyscd/model.ckpt-0.index\n","INFO:tensorflow:0\n","INFO:tensorflow:/tmp/tmplxguyscd/model.ckpt-0.meta\n","INFO:tensorflow:500\n","INFO:tensorflow:/tmp/tmplxguyscd/model.ckpt-0.data-00000-of-00001\n","INFO:tensorflow:500\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n","WARNING:tensorflow:Training with estimator made no steps. Perhaps input is empty or misspecified.\n"]},{"ename":"InternalError","evalue":"Graph execution error:\n\nUnsupported object type float","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1377\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1378\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1361\u001b[0m                                 target_list, run_metadata)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1453\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1452\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1453\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[1;32m   1454\u001b[0m                                           fetch_list, target_list,\n\u001b[1;32m   1455\u001b[0m                                           run_metadata)\n","\u001b[0;31mInternalError\u001b[0m: Unsupported object type float","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn [121], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mLinearClassifier(model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      2\u001b[0m                                       feature_columns\u001b[38;5;241m=\u001b[39mfeature_columns)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(input_fn\u001b[38;5;241m=\u001b[39minput_fn(), steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    357\u001b[0m hooks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[1;32m    359\u001b[0m saving_listeners \u001b[39m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[0;32m--> 360\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model(input_fn, hooks, saving_listeners)\n\u001b[1;32m    361\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoss for final step: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[1;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[1;32m   1185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model_default(input_fn, hooks, saving_listeners)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1217\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1214\u001b[0m estimator_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_model_fn(features, labels, ModeKeys\u001b[39m.\u001b[39mTRAIN,\n\u001b[1;32m   1215\u001b[0m                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig)\n\u001b[1;32m   1216\u001b[0m global_step_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mget_global_step(g)\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1218\u001b[0m                                        hooks, global_step_tensor,\n\u001b[1;32m   1219\u001b[0m                                        saving_listeners)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1512\u001b[0m, in \u001b[0;36mEstimator._train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1505\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mlog_step_count_steps \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mlog_step_count_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m   1507\u001b[0m       worker_hooks\u001b[39m.\u001b[39mappend(\n\u001b[1;32m   1508\u001b[0m           tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mStepCounterHook(\n\u001b[1;32m   1509\u001b[0m               every_n_steps\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mlog_step_count_steps,\n\u001b[1;32m   1510\u001b[0m               output_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mmodel_dir))\n\u001b[0;32m-> 1512\u001b[0m \u001b[39mwith\u001b[39;00m training\u001b[39m.\u001b[39mMonitoredTrainingSession(\n\u001b[1;32m   1513\u001b[0m     master\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mmaster,\n\u001b[1;32m   1514\u001b[0m     is_chief\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mis_chief,\n\u001b[1;32m   1515\u001b[0m     checkpoint_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_dir,\n\u001b[1;32m   1516\u001b[0m     scaffold\u001b[39m=\u001b[39mestimator_spec\u001b[39m.\u001b[39mscaffold,\n\u001b[1;32m   1517\u001b[0m     hooks\u001b[39m=\u001b[39mworker_hooks,\n\u001b[1;32m   1518\u001b[0m     chief_only_hooks\u001b[39m=\u001b[39m(\u001b[39mtuple\u001b[39m(chief_hooks) \u001b[39m+\u001b[39m\n\u001b[1;32m   1519\u001b[0m                       \u001b[39mtuple\u001b[39m(estimator_spec\u001b[39m.\u001b[39mtraining_chief_hooks)),\n\u001b[1;32m   1520\u001b[0m     save_checkpoint_secs\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,  \u001b[39m# Saving is handled by a hook.\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m     save_summaries_steps\u001b[39m=\u001b[39msave_summary_steps,\n\u001b[1;32m   1522\u001b[0m     config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session_config,\n\u001b[1;32m   1523\u001b[0m     max_wait_secs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39msession_creation_timeout_secs,\n\u001b[1;32m   1524\u001b[0m     log_step_count_steps\u001b[39m=\u001b[39mlog_step_count_steps,\n\u001b[1;32m   1525\u001b[0m     save_graph_def\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mcheckpoint_save_graph_def) \u001b[39mas\u001b[39;00m mon_sess:\n\u001b[1;32m   1526\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m   current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:893\u001b[0m, in \u001b[0;36m_MonitoredSession.__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mif\u001b[39;00m exception_type \u001b[39min\u001b[39;00m [errors\u001b[39m.\u001b[39mOutOfRangeError, \u001b[39mStopIteration\u001b[39;00m]:\n\u001b[1;32m    892\u001b[0m   exception_type \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_close_internal(exception_type)\n\u001b[1;32m    894\u001b[0m \u001b[39m# __exit__ should return True to suppress an exception.\u001b[39;00m\n\u001b[1;32m    895\u001b[0m \u001b[39mreturn\u001b[39;00m exception_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:931\u001b[0m, in \u001b[0;36m_MonitoredSession._close_internal\u001b[0;34m(self, exception_type)\u001b[0m\n\u001b[1;32m    929\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSession is already closed.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 931\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mclose()\n\u001b[1;32m    932\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1222\u001b[0m, in \u001b[0;36m_WrappedSession.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess:\n\u001b[1;32m   1221\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mclose()\n\u001b[1;32m   1223\u001b[0m   \u001b[39mexcept\u001b[39;00m _PREEMPTION_ERRORS \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1224\u001b[0m     logging\u001b[39m.\u001b[39merror(\n\u001b[1;32m   1225\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mAn error occurred when attempting to close the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1226\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msession. This may be due to a preemption in a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1227\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mconnected worker or parameter server. Error: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, e)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1388\u001b[0m, in \u001b[0;36m_CoordinatedSession.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coord\u001b[39m.\u001b[39mrequest_stop()\n\u001b[1;32m   1387\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1388\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coord\u001b[39m.\u001b[39;49mjoin(\n\u001b[1;32m   1389\u001b[0m       stop_grace_period_secs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stop_grace_period_secs,\n\u001b[1;32m   1390\u001b[0m       ignore_live_threads\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1391\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1392\u001b[0m   \u001b[39mtry\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/training/coordinator.py:385\u001b[0m, in \u001b[0;36mCoordinator.join\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registered_threads \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info_to_raise:\n\u001b[0;32m--> 385\u001b[0m   six\u001b[39m.\u001b[39;49mreraise(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exc_info_to_raise)\n\u001b[1;32m    386\u001b[0m \u001b[39melif\u001b[39;00m stragglers:\n\u001b[1;32m    387\u001b[0m   \u001b[39mif\u001b[39;00m ignore_live_threads:\n","File \u001b[0;32m/usr/lib/python3/dist-packages/six.py:718\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    716\u001b[0m         value \u001b[39m=\u001b[39m tp()\n\u001b[1;32m    717\u001b[0m     \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m--> 718\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    719\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[1;32m    720\u001b[0m \u001b[39mfinally\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:96\u001b[0m, in \u001b[0;36m_FeedingQueueRunner._run\u001b[0;34m(self, sess, enqueue_op, feed_fn, coord)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m   feed_dict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m feed_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m feed_fn()\n\u001b[0;32m---> 96\u001b[0m   sess\u001b[39m.\u001b[39;49mrun(enqueue_op, feed_dict\u001b[39m=\u001b[39;49mfeed_dict)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mOutOfRangeError, tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mCancelledError):\n\u001b[1;32m     98\u001b[0m   \u001b[39m# This exception indicates that a queue was closed.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    968\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m    970\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1190\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[1;32m   1191\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1193\u001b[0m   results \u001b[39m=\u001b[39m []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1370\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1369\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1370\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m   1371\u001b[0m                        run_metadata)\n\u001b[1;32m   1372\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1396\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[1;32m   1392\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1393\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1394\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1395\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1396\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n","\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nUnsupported object type float"]}],"source":["model = tf.estimator.LinearClassifier(model_dir=None,\n","                                      feature_columns=feature_columns)\n","model.train(input_fn=input_fn(), steps=10000)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1syPlu_EWeKuktOXznQC-wwmgHMFYcc5L","timestamp":1658443470778},{"file_id":"1bEMJfskpHEAw26jo8c-60Nt_qSRbntcT","timestamp":1657765031742},{"file_id":"1xNtEzyOYTQR2P7TtSP0VBDDYK99QzY24","timestamp":1655648351750}]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
