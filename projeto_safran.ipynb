{"cells":[{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["import datetime\n","import subprocess\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns \n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow import feature_column\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":23466,"status":"error","timestamp":1664850455528,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"sm3_um-bcJqJ","outputId":"3f8f3fcf-ed1e-4c3d-d599-93d9e1c36eaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6182 entries, 0 to 6181\n","Data columns (total 36 columns):\n"," #   Column                Non-Null Count  Dtype         \n","---  ------                --------------  -----         \n"," 0   Unnamed: 0            0 non-null      float64       \n"," 1   PART_NUMBER           6182 non-null   object        \n"," 2   REV                   6182 non-null   object        \n"," 3   DESCRIPTION           6182 non-null   object        \n"," 4   CONFIGURATION         6182 non-null   object        \n"," 5   RELEASED_DATE         6182 non-null   datetime64[ns]\n"," 6   OBJECT_ID_3D          6182 non-null   int64         \n"," 7   FILE_NAME_3D          6182 non-null   object        \n"," 8   CLASS_3D              6182 non-null   object        \n"," 9   DRAWING_CODE_3D       6180 non-null   object        \n"," 10  ATP_3D                6182 non-null   object        \n"," 11  QTN_REV_3D            6182 non-null   int64         \n"," 12  MEAN_SIZE_3D          5559 non-null   float64       \n"," 13  OBJECT_ID_2D          6182 non-null   int64         \n"," 14  FILE_NAME_2D          6182 non-null   object        \n"," 15  CLASS_2D              6182 non-null   object        \n"," 16  DRAWING_CODE_2D       6179 non-null   object        \n"," 17  ATP_2D                6182 non-null   object        \n"," 18  QTN_REV_2D            6182 non-null   int64         \n"," 19  QTY_ECN_2D            1555 non-null   float64       \n"," 20  MEAN_SIZE_2D          5562 non-null   float64       \n"," 21  QTY_SHEETS            5296 non-null   float64       \n"," 22  QTY_DIMENSIONS        4810 non-null   float64       \n"," 23  QTY_VIEWS             5296 non-null   float64       \n"," 24  QTY_PART_LIST         4377 non-null   float64       \n"," 25  QTY_TEXT_INFORMATION  5296 non-null   float64       \n"," 26  WORKFLOW              6174 non-null   object        \n"," 27  CREATED_ON            6174 non-null   datetime64[ns]\n"," 28  COMPLETED_ON          6159 non-null   datetime64[ns]\n"," 29  LEAD_TIME             6182 non-null   float64       \n"," 30  NEW_DESIGN            0 non-null      float64       \n"," 31  TRIM_AND_FINISH       6182 non-null   int64         \n"," 32  COMPLEXITY            762 non-null    object        \n"," 33  RTF                   762 non-null    float64       \n"," 34  HOV                   762 non-null    float64       \n"," 35  NEW_DEV               762 non-null    float64       \n","dtypes: datetime64[ns](3), float64(14), int64(5), object(14)\n","memory usage: 1.7+ MB\n"]}],"source":["# IF DATA IS IN YOUR DRIVE\n","data = pd.read_excel('BLACK_BELT_DATABASE_CASE_COMPLETE.xlsx', header=0)\n","data.info()"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"KlbTWqHBcJqL"},"outputs":[],"source":["# Função para pré-processar os dados\n","def preProcessingDataBase(data):\n","\n","    to_drop = ['NEW_DEV',\n","               'HOV',\n","               'RTF',\n","               'COMPLEXITY',\n","               'CREATED_ON',\n","               'COMPLETED_ON',\n","               'CLASS_2D',\n","               'PART_NUMBER',\n","               'REV',\n","               'DESCRIPTION',\n","               'CONFIGURATION',\n","               'RELEASED_DATE',\n","               'OBJECT_ID_3D',\n","               'FILE_NAME_3D',\n","               'CLASS_3D',\n","               'DRAWING_CODE_3D',\n","               'ATP_3D',\n","               'OBJECT_ID_2D',\n","               'FILE_NAME_2D', \n","               'TRIM_AND_FINISH',\n","               'NEW_DESIGN',\n","               'WORKFLOW',\n","               'Unnamed: 0']\n","\n","    data.drop(to_drop, inplace=True, axis=1)\n","\n","    # QTN_REV_3D\n","    data = data[~data['QTN_REV_3D'].isnull()]\n","    data['QTN_REV_3D'] = data['QTN_REV_3D'].dropna()\n","    data['QTN_REV_3D'] = (data['QTN_REV_3D']-data['QTN_REV_3D'].min())/(data['QTN_REV_3D'].max()-data['QTN_REV_3D'].min())\n","\n","    # DRAWING_CODE\n","    data = data[~data['DRAWING_CODE_2D'].isnull()]\n","    data['DRAWING_CODE_2D'] = data['DRAWING_CODE_2D'].dropna()\n","    #data = data.join(pd.get_dummies(data.pop('DRAWING_CODE')))\n","\n","    # ATP\n","    data = data[~data['ATP_2D'].isnull()]\n","    data['ATP_2D'] = data['ATP_2D'].dropna()\n","    #data = data.join(pd.get_dummies(data.pop('ATP')))\n","\n","    # QTN_REV_2D\n","    data = data[~data['QTN_REV_2D'].isnull()]\n","    data['QTN_REV_2D'] = data['QTN_REV_2D'].dropna()\n","    data['QTN_REV_2D'] = (data['QTN_REV_2D']-data['QTN_REV_2D'].min())/(data['QTN_REV_2D'].max()-data['QTN_REV_2D'].min())\n","\n","    # QTY_ECN_2D\n","    data['QTY_ECN_2D'] = data['QTY_ECN_2D'].fillna(0)\n","    data.loc[(data.QTY_ECN_2D != 0), 'QTY_ECN_2D'] = \"RUIM\"\n","    data.loc[(data.QTY_ECN_2D == 0), 'QTY_ECN_2D'] = \"BOM\"\n","    data['QTY_ECN_2D'] = pd.Series(np.searchsorted(['BOM', 'RUIM'], data.QTY_ECN_2D.values), data.index)\n","    #data['QTY_ECN_2D'] = data.loc[(data.QTY_ECN_2D == 0), 'QTY_ECN_2D']\n","\n","    # LEAD_TIME\n","    data = data[~data['LEAD_TIME'].isnull()]\n","    data['LEAD_TIME'] = data['LEAD_TIME'].dropna()\n","    data['LEAD_TIME'] = (data['LEAD_TIME']-data['LEAD_TIME'].min())/(data['LEAD_TIME'].max()-data['LEAD_TIME'].min())\n","\n","    # MEAN_SIZE_3D\n","    data = data[~data['MEAN_SIZE_3D'].isnull()]\n","    data['MEAN_SIZE_3D'] = data['MEAN_SIZE_3D'].dropna()\n","    data['MEAN_SIZE_3D'] = (data['MEAN_SIZE_3D']-data['MEAN_SIZE_3D'].min())/(data['MEAN_SIZE_3D'].max()-data['MEAN_SIZE_3D'].min())\n","\n","    # MEAN_SIZE_2D\n","    data = data[~data['MEAN_SIZE_2D'].isnull()]\n","    data['MEAN_SIZE_2D'] = data['MEAN_SIZE_2D'].dropna()\n","    data['MEAN_SIZE_2D'] = (data['MEAN_SIZE_2D']-data['MEAN_SIZE_2D'].min())/(data['MEAN_SIZE_2D'].max()-data['MEAN_SIZE_2D'].min())\n","\n","    # QTY_SHEETS\n","    data['QTY_SHEETS'] = data['QTY_SHEETS'].fillna(0)\n","    data['QTY_SHEETS'] = (data['QTY_SHEETS']-data['QTY_SHEETS'].min())/(data['QTY_SHEETS'].max()-data['QTY_SHEETS'].min())\n","\n","    # QTY_DIMENSIONS\n","    # FOI ALTERADO PARA QUANDO VAZIO RECEBER 0\n","    data['QTY_DIMENSIONS'] = data['QTY_DIMENSIONS'].fillna(0)\n","    data['QTY_DIMENSIONS'] = (data['QTY_DIMENSIONS']-data['QTY_DIMENSIONS'].min())/(data['QTY_DIMENSIONS'].max()-data['QTY_DIMENSIONS'].min())\n","\n","    # QTY_VIEWS\n","    # FOI ALTERADO PARA QUANDO VAZIO RECEBER 0\n","    data['QTY_VIEWS'] = data['QTY_VIEWS'].fillna(0)\n","    data['QTY_VIEWS'] = (data['QTY_VIEWS']-data['QTY_VIEWS'].min())/(data['QTY_VIEWS'].max()-data['QTY_VIEWS'].min())\n","\n","    # QTY_PART_LIST\n","    # FOI ALTERADO PARA QUANDO VAZIO RECEBER 1\n","    data['QTY_PART_LIST'] = data['QTY_PART_LIST'].fillna(1)\n","    data['QTY_PART_LIST'] = (data['QTY_PART_LIST']-data['QTY_PART_LIST'].min())/(data['QTY_PART_LIST'].max()-data['QTY_PART_LIST'].min())\n","\n","    # QTY_TEXT_INFORMATION\n","    # FOI ALTERADO PARA QUANDO VAZIO RECEBER 0\n","    data['QTY_TEXT_INFORMATION'] = data['QTY_TEXT_INFORMATION'].fillna(0)\n","    data['QTY_TEXT_INFORMATION'] = (data['QTY_TEXT_INFORMATION']-data['QTY_TEXT_INFORMATION'].min())/(data['QTY_TEXT_INFORMATION'].max()-data['QTY_TEXT_INFORMATION'].min())\n","\n","    return data"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 5555 entries, 0 to 6181\n","Data columns (total 13 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   QTN_REV_3D            5555 non-null   float64\n"," 1   MEAN_SIZE_3D          5555 non-null   float64\n"," 2   DRAWING_CODE_2D       5555 non-null   object \n"," 3   ATP_2D                5555 non-null   object \n"," 4   QTN_REV_2D            5555 non-null   float64\n"," 5   QTY_ECN_2D            5555 non-null   int64  \n"," 6   MEAN_SIZE_2D          5555 non-null   float64\n"," 7   QTY_SHEETS            5555 non-null   float64\n"," 8   QTY_DIMENSIONS        5555 non-null   float64\n"," 9   QTY_VIEWS             5555 non-null   float64\n"," 10  QTY_PART_LIST         5555 non-null   float64\n"," 11  QTY_TEXT_INFORMATION  5555 non-null   float64\n"," 12  LEAD_TIME             5555 non-null   float64\n","dtypes: float64(10), int64(1), object(2)\n","memory usage: 607.6+ KB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>QTN_REV_3D</th>\n","      <th>MEAN_SIZE_3D</th>\n","      <th>DRAWING_CODE_2D</th>\n","      <th>ATP_2D</th>\n","      <th>QTN_REV_2D</th>\n","      <th>QTY_ECN_2D</th>\n","      <th>MEAN_SIZE_2D</th>\n","      <th>QTY_SHEETS</th>\n","      <th>QTY_DIMENSIONS</th>\n","      <th>QTY_VIEWS</th>\n","      <th>QTY_PART_LIST</th>\n","      <th>QTY_TEXT_INFORMATION</th>\n","      <th>LEAD_TIME</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000</td>\n","      <td>0.014674</td>\n","      <td>PL</td>\n","      <td>F49-1-AFR1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>0.010192</td>\n","      <td>0.2</td>\n","      <td>0.357143</td>\n","      <td>0.236364</td>\n","      <td>0.037125</td>\n","      <td>0.268595</td>\n","      <td>0.980932</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000</td>\n","      <td>0.005768</td>\n","      <td>DA</td>\n","      <td>F49-1-AFR1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>0.003197</td>\n","      <td>0.1</td>\n","      <td>0.057143</td>\n","      <td>0.109091</td>\n","      <td>0.006044</td>\n","      <td>0.102617</td>\n","      <td>0.980602</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000</td>\n","      <td>0.014559</td>\n","      <td>NM</td>\n","      <td>F49-1-AFR1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>0.001954</td>\n","      <td>0.1</td>\n","      <td>0.078571</td>\n","      <td>0.090909</td>\n","      <td>0.000216</td>\n","      <td>0.085399</td>\n","      <td>0.980602</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.125</td>\n","      <td>0.026743</td>\n","      <td>IN</td>\n","      <td>F49-1-AFR1</td>\n","      <td>0.125</td>\n","      <td>1</td>\n","      <td>0.034812</td>\n","      <td>0.3</td>\n","      <td>0.000000</td>\n","      <td>0.290909</td>\n","      <td>0.061731</td>\n","      <td>0.124656</td>\n","      <td>0.980525</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000</td>\n","      <td>0.041557</td>\n","      <td>TA</td>\n","      <td>F49-1-AFR1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>0.138805</td>\n","      <td>0.2</td>\n","      <td>0.078571</td>\n","      <td>0.400000</td>\n","      <td>0.197928</td>\n","      <td>0.247245</td>\n","      <td>0.980830</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   QTN_REV_3D  MEAN_SIZE_3D DRAWING_CODE_2D      ATP_2D  QTN_REV_2D  \\\n","0       0.000      0.014674              PL  F49-1-AFR1       0.000   \n","1       0.000      0.005768              DA  F49-1-AFR1       0.000   \n","2       0.000      0.014559              NM  F49-1-AFR1       0.000   \n","3       0.125      0.026743              IN  F49-1-AFR1       0.125   \n","4       0.000      0.041557              TA  F49-1-AFR1       0.000   \n","\n","   QTY_ECN_2D  MEAN_SIZE_2D  QTY_SHEETS  QTY_DIMENSIONS  QTY_VIEWS  \\\n","0           0      0.010192         0.2        0.357143   0.236364   \n","1           0      0.003197         0.1        0.057143   0.109091   \n","2           0      0.001954         0.1        0.078571   0.090909   \n","3           1      0.034812         0.3        0.000000   0.290909   \n","4           0      0.138805         0.2        0.078571   0.400000   \n","\n","   QTY_PART_LIST  QTY_TEXT_INFORMATION  LEAD_TIME  \n","0       0.037125              0.268595   0.980932  \n","1       0.006044              0.102617   0.980602  \n","2       0.000216              0.085399   0.980602  \n","3       0.061731              0.124656   0.980525  \n","4       0.197928              0.247245   0.980830  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["data = preProcessingDataBase(data)\n","data.info()\n","data.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"7heJVrDIcJqM"},"outputs":[],"source":["# Post pré-processing\n","data, validation_data = train_test_split(data, test_size=0.3)\n","validation_data, test_data = train_test_split(validation_data, test_size=0.5)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["0    2880\n","1    1008\n","Name: QTY_ECN_2D, dtype: int64"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["## Contar saídas\n","data[\"QTY_ECN_2D\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Balancear saídas\n","data = data.groupby('QTY_ECN_2D').sample(n=4110)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Visualizar\n","sample_data = data.sample(frac=0.3)\n","sns.pairplot(sample_data, hue=\"QTY_ECN_2D\", palette=\"tab10\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n","  dataframe = dataframe.copy()\n","  labels = dataframe.pop('QTY_ECN_2D')\n","  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n","  if shuffle:\n","    ds = ds.shuffle(buffer_size=len(dataframe))\n","  ds = ds.batch(batch_size)\n","  return ds"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["feature_columns = []\n","\n","to_feature = ['QTN_REV_3D', \n","              'MEAN_SIZE_3D',\n","              'QTN_REV_2D',\n","              'MEAN_SIZE_2D', \n","              'QTY_SHEETS', \n","              'QTY_DIMENSIONS', \n","              'QTY_VIEWS', \n","              'QTY_PART_LIST', \n","              'QTY_TEXT_INFORMATION',\n","              'LEAD_TIME']\n","\n","for header in to_feature:\n","  feature_columns.append(feature_column.numeric_column(header))\n","\n","\n","feature_columns.append(feature_column.embedding_column(feature_column.categorical_column_with_vocabulary_list('ATP_2D', data.ATP_2D.unique()), dimension=8))\n","feature_columns.append(feature_column.embedding_column(feature_column.categorical_column_with_vocabulary_list('DRAWING_CODE_2D', data.DRAWING_CODE_2D.unique()), dimension=8))\n","\n","feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["batch_size = 8\n","train_ds = df_to_dataset(data, shuffle=True, batch_size=batch_size)\n","validation_ds = df_to_dataset(validation_data, shuffle=True, batch_size=batch_size)\n","test_ds = df_to_dataset(test_data, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10000\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","464/486 [===========================>..] - ETA: 0s - loss: 0.7934 - accuracy: 0.6649"]},{"name":"stderr","output_type":"stream","text":["2022-10-18 23:35:33.718989: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n","2022-10-18 23:35:33.719063: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: matheus-notebook\n","2022-10-18 23:35:33.719082: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: matheus-notebook\n","2022-10-18 23:35:33.719320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.85.2\n","2022-10-18 23:35:33.719377: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.1\n","2022-10-18 23:35:33.719391: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 515.65.1 does not match DSO version 510.85.2 -- cannot find working devices in this configuration\n","\n","NOTE: Using experimental fast data loading logic. To disable, pass\n","    \"--load_fast=false\" and report issues on GitHub. More details:\n","    https://github.com/tensorflow/tensorboard/issues/4784\n","\n"]},{"name":"stdout","output_type":"stream","text":["481/486 [============================>.] - ETA: 0s - loss: 0.7919 - accuracy: 0.6687WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"]},{"name":"stderr","output_type":"stream","text":["Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n","TensorBoard 2.9.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":["486/486 [==============================] - 7s 9ms/step - loss: 0.7908 - accuracy: 0.6700 - val_loss: 0.6953 - val_accuracy: 0.7407\n","Epoch 2/10000\n","486/486 [==============================] - 4s 7ms/step - loss: 0.7302 - accuracy: 0.7096 - val_loss: 0.6930 - val_accuracy: 0.7407\n","Epoch 3/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.7087 - accuracy: 0.7287 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 4/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.7001 - accuracy: 0.7361 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 5/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6970 - accuracy: 0.7387 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 6/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6949 - accuracy: 0.7418 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 7/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6948 - accuracy: 0.7397 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 8/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6948 - accuracy: 0.7387 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 9/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6935 - accuracy: 0.7413 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 10/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6934 - accuracy: 0.7413 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 11/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.7410 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 12/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.7415 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 13/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.7407 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 14/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6939 - accuracy: 0.7395 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 15/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6930 - accuracy: 0.7405 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 16/10000\n","486/486 [==============================] - 4s 8ms/step - loss: 0.6932 - accuracy: 0.7415 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 17/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6930 - accuracy: 0.7415 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 18/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6930 - accuracy: 0.7410 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 19/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6928 - accuracy: 0.7415 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 20/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6925 - accuracy: 0.7418 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 21/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6922 - accuracy: 0.7433 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 22/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6926 - accuracy: 0.7415 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 23/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6913 - accuracy: 0.7449 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 24/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6910 - accuracy: 0.7456 - val_loss: 0.6931 - val_accuracy: 0.7407\n","Epoch 25/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6909 - accuracy: 0.7454 - val_loss: 0.6930 - val_accuracy: 0.7407\n","Epoch 26/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6902 - accuracy: 0.7467 - val_loss: 0.6930 - val_accuracy: 0.7407\n","Epoch 27/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6908 - accuracy: 0.7459 - val_loss: 0.6929 - val_accuracy: 0.7407\n","Epoch 28/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6887 - accuracy: 0.7521 - val_loss: 0.6927 - val_accuracy: 0.7407\n","Epoch 29/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6887 - accuracy: 0.7521 - val_loss: 0.6924 - val_accuracy: 0.7407\n","Epoch 30/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6881 - accuracy: 0.7523 - val_loss: 0.6920 - val_accuracy: 0.7407\n","Epoch 31/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6885 - accuracy: 0.7518 - val_loss: 0.6920 - val_accuracy: 0.7407\n","Epoch 32/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6875 - accuracy: 0.7533 - val_loss: 0.6915 - val_accuracy: 0.7418\n","Epoch 33/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6856 - accuracy: 0.7600 - val_loss: 0.6910 - val_accuracy: 0.7418\n","Epoch 34/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6861 - accuracy: 0.7551 - val_loss: 0.6905 - val_accuracy: 0.7423\n","Epoch 35/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6840 - accuracy: 0.7603 - val_loss: 0.6898 - val_accuracy: 0.7436\n","Epoch 36/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6824 - accuracy: 0.7629 - val_loss: 0.6889 - val_accuracy: 0.7451\n","Epoch 37/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6818 - accuracy: 0.7665 - val_loss: 0.6880 - val_accuracy: 0.7456\n","Epoch 38/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6841 - accuracy: 0.7598 - val_loss: 0.6877 - val_accuracy: 0.7459\n","Epoch 39/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6838 - accuracy: 0.7600 - val_loss: 0.6857 - val_accuracy: 0.7495\n","Epoch 40/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6780 - accuracy: 0.7716 - val_loss: 0.6822 - val_accuracy: 0.7585\n","Epoch 41/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6769 - accuracy: 0.7734 - val_loss: 0.6800 - val_accuracy: 0.7626\n","Epoch 42/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6766 - accuracy: 0.7770 - val_loss: 0.6774 - val_accuracy: 0.7683\n","Epoch 43/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6740 - accuracy: 0.7788 - val_loss: 0.6757 - val_accuracy: 0.7724\n","Epoch 44/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6721 - accuracy: 0.7809 - val_loss: 0.6732 - val_accuracy: 0.7755\n","Epoch 45/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6682 - accuracy: 0.7940 - val_loss: 0.6678 - val_accuracy: 0.7834\n","Epoch 46/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6672 - accuracy: 0.7909 - val_loss: 0.6659 - val_accuracy: 0.7881\n","Epoch 47/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6673 - accuracy: 0.7912 - val_loss: 0.6627 - val_accuracy: 0.7955\n","Epoch 48/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6672 - accuracy: 0.7917 - val_loss: 0.6577 - val_accuracy: 0.8066\n","Epoch 49/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6604 - accuracy: 0.8035 - val_loss: 0.6505 - val_accuracy: 0.8128\n","Epoch 50/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6620 - accuracy: 0.8035 - val_loss: 0.6494 - val_accuracy: 0.8135\n","Epoch 51/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6587 - accuracy: 0.8086 - val_loss: 0.6460 - val_accuracy: 0.8171\n","Epoch 52/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6537 - accuracy: 0.8151 - val_loss: 0.6412 - val_accuracy: 0.8236\n","Epoch 53/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6546 - accuracy: 0.8117 - val_loss: 0.6319 - val_accuracy: 0.8462\n","Epoch 54/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6508 - accuracy: 0.8166 - val_loss: 0.6274 - val_accuracy: 0.8627\n","Epoch 55/10000\n","486/486 [==============================] - 3s 7ms/step - loss: 0.6492 - accuracy: 0.8182 - val_loss: 0.6222 - val_accuracy: 0.8809\n","Epoch 56/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6498 - accuracy: 0.8205 - val_loss: 0.6198 - val_accuracy: 0.8873\n","Epoch 57/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6431 - accuracy: 0.8279 - val_loss: 0.6119 - val_accuracy: 0.9136\n","Epoch 58/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6448 - accuracy: 0.8300 - val_loss: 0.6074 - val_accuracy: 0.9221\n","Epoch 59/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6395 - accuracy: 0.8351 - val_loss: 0.6039 - val_accuracy: 0.9318\n","Epoch 60/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.6408 - accuracy: 0.8333 - val_loss: 0.5998 - val_accuracy: 0.9380\n","Epoch 61/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6373 - accuracy: 0.8380 - val_loss: 0.5947 - val_accuracy: 0.9421\n","Epoch 62/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6350 - accuracy: 0.8413 - val_loss: 0.5907 - val_accuracy: 0.9439\n","Epoch 63/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6299 - accuracy: 0.8513 - val_loss: 0.5853 - val_accuracy: 0.9519\n","Epoch 64/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6312 - accuracy: 0.8454 - val_loss: 0.5791 - val_accuracy: 0.9586\n","Epoch 65/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6282 - accuracy: 0.8480 - val_loss: 0.5769 - val_accuracy: 0.9583\n","Epoch 66/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6218 - accuracy: 0.8580 - val_loss: 0.5695 - val_accuracy: 0.9627\n","Epoch 67/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6244 - accuracy: 0.8555 - val_loss: 0.5680 - val_accuracy: 0.9624\n","Epoch 68/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6214 - accuracy: 0.8560 - val_loss: 0.5639 - val_accuracy: 0.9637\n","Epoch 69/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6200 - accuracy: 0.8601 - val_loss: 0.5610 - val_accuracy: 0.9642\n","Epoch 70/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.6196 - accuracy: 0.8634 - val_loss: 0.5597 - val_accuracy: 0.9642\n","Epoch 71/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.6181 - accuracy: 0.8663 - val_loss: 0.5572 - val_accuracy: 0.9645\n","Epoch 72/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6152 - accuracy: 0.8678 - val_loss: 0.5547 - val_accuracy: 0.9648\n","Epoch 73/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6195 - accuracy: 0.8593 - val_loss: 0.5531 - val_accuracy: 0.9648\n","Epoch 74/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6128 - accuracy: 0.8699 - val_loss: 0.5518 - val_accuracy: 0.9648\n","Epoch 75/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6072 - accuracy: 0.8778 - val_loss: 0.5497 - val_accuracy: 0.9650\n","Epoch 76/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6120 - accuracy: 0.8722 - val_loss: 0.5481 - val_accuracy: 0.9650\n","Epoch 77/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6116 - accuracy: 0.8701 - val_loss: 0.5465 - val_accuracy: 0.9650\n","Epoch 78/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6033 - accuracy: 0.8837 - val_loss: 0.5446 - val_accuracy: 0.9655\n","Epoch 79/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6068 - accuracy: 0.8771 - val_loss: 0.5439 - val_accuracy: 0.9655\n","Epoch 80/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6016 - accuracy: 0.8853 - val_loss: 0.5432 - val_accuracy: 0.9655\n","Epoch 81/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6031 - accuracy: 0.8835 - val_loss: 0.5420 - val_accuracy: 0.9658\n","Epoch 82/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6047 - accuracy: 0.8809 - val_loss: 0.5414 - val_accuracy: 0.9658\n","Epoch 83/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.6020 - accuracy: 0.8814 - val_loss: 0.5408 - val_accuracy: 0.9660\n","Epoch 84/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5982 - accuracy: 0.8884 - val_loss: 0.5407 - val_accuracy: 0.9660\n","Epoch 85/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5991 - accuracy: 0.8855 - val_loss: 0.5400 - val_accuracy: 0.9658\n","Epoch 86/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5968 - accuracy: 0.8907 - val_loss: 0.5400 - val_accuracy: 0.9658\n","Epoch 87/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5979 - accuracy: 0.8866 - val_loss: 0.5397 - val_accuracy: 0.9660\n","Epoch 88/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5985 - accuracy: 0.8904 - val_loss: 0.5394 - val_accuracy: 0.9655\n","Epoch 89/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5972 - accuracy: 0.8912 - val_loss: 0.5392 - val_accuracy: 0.9658\n","Epoch 90/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5901 - accuracy: 0.8984 - val_loss: 0.5387 - val_accuracy: 0.9660\n","Epoch 91/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5918 - accuracy: 0.8971 - val_loss: 0.5385 - val_accuracy: 0.9658\n","Epoch 92/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5898 - accuracy: 0.8999 - val_loss: 0.5383 - val_accuracy: 0.9660\n","Epoch 93/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5889 - accuracy: 0.8999 - val_loss: 0.5380 - val_accuracy: 0.9666\n","Epoch 94/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5871 - accuracy: 0.9015 - val_loss: 0.5381 - val_accuracy: 0.9658\n","Epoch 95/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5871 - accuracy: 0.9012 - val_loss: 0.5378 - val_accuracy: 0.9666\n","Epoch 96/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5896 - accuracy: 0.8994 - val_loss: 0.5379 - val_accuracy: 0.9658\n","Epoch 97/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5861 - accuracy: 0.9023 - val_loss: 0.5376 - val_accuracy: 0.9658\n","Epoch 98/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5842 - accuracy: 0.9046 - val_loss: 0.5377 - val_accuracy: 0.9658\n","Epoch 99/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5840 - accuracy: 0.9041 - val_loss: 0.5375 - val_accuracy: 0.9668\n","Epoch 100/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5854 - accuracy: 0.9028 - val_loss: 0.5377 - val_accuracy: 0.9655\n","Epoch 101/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5849 - accuracy: 0.9030 - val_loss: 0.5374 - val_accuracy: 0.9655\n","Epoch 102/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5874 - accuracy: 0.9002 - val_loss: 0.5376 - val_accuracy: 0.9658\n","Epoch 103/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5834 - accuracy: 0.9048 - val_loss: 0.5374 - val_accuracy: 0.9660\n","Epoch 104/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5777 - accuracy: 0.9131 - val_loss: 0.5374 - val_accuracy: 0.9655\n","Epoch 105/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5834 - accuracy: 0.9041 - val_loss: 0.5373 - val_accuracy: 0.9658\n","Epoch 106/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5842 - accuracy: 0.9051 - val_loss: 0.5372 - val_accuracy: 0.9666\n","Epoch 107/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5809 - accuracy: 0.9102 - val_loss: 0.5371 - val_accuracy: 0.9660\n","Epoch 108/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5805 - accuracy: 0.9061 - val_loss: 0.5371 - val_accuracy: 0.9660\n","Epoch 109/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5770 - accuracy: 0.9136 - val_loss: 0.5370 - val_accuracy: 0.9663\n","Epoch 110/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5794 - accuracy: 0.9087 - val_loss: 0.5369 - val_accuracy: 0.9666\n","Epoch 111/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5804 - accuracy: 0.9066 - val_loss: 0.5367 - val_accuracy: 0.9673\n","Epoch 112/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5796 - accuracy: 0.9082 - val_loss: 0.5367 - val_accuracy: 0.9678\n","Epoch 113/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5774 - accuracy: 0.9123 - val_loss: 0.5371 - val_accuracy: 0.9663\n","Epoch 114/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5764 - accuracy: 0.9138 - val_loss: 0.5371 - val_accuracy: 0.9660\n","Epoch 115/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5764 - accuracy: 0.9141 - val_loss: 0.5372 - val_accuracy: 0.9660\n","Epoch 116/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5803 - accuracy: 0.9072 - val_loss: 0.5369 - val_accuracy: 0.9666\n","Epoch 117/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5805 - accuracy: 0.9059 - val_loss: 0.5371 - val_accuracy: 0.9666\n","Epoch 118/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5792 - accuracy: 0.9087 - val_loss: 0.5370 - val_accuracy: 0.9666\n","Epoch 119/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5783 - accuracy: 0.9102 - val_loss: 0.5370 - val_accuracy: 0.9660\n","Epoch 120/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5777 - accuracy: 0.9105 - val_loss: 0.5367 - val_accuracy: 0.9678\n","Epoch 121/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5738 - accuracy: 0.9151 - val_loss: 0.5366 - val_accuracy: 0.9678\n","Epoch 122/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5784 - accuracy: 0.9095 - val_loss: 0.5365 - val_accuracy: 0.9681\n","Epoch 123/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5772 - accuracy: 0.9110 - val_loss: 0.5362 - val_accuracy: 0.9691\n","Epoch 124/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5726 - accuracy: 0.9169 - val_loss: 0.5366 - val_accuracy: 0.9678\n","Epoch 125/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5747 - accuracy: 0.9169 - val_loss: 0.5366 - val_accuracy: 0.9678\n","Epoch 126/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5762 - accuracy: 0.9120 - val_loss: 0.5367 - val_accuracy: 0.9668\n","Epoch 127/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5771 - accuracy: 0.9105 - val_loss: 0.5368 - val_accuracy: 0.9668\n","Epoch 128/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5722 - accuracy: 0.9187 - val_loss: 0.5360 - val_accuracy: 0.9691\n","Epoch 129/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5733 - accuracy: 0.9167 - val_loss: 0.5364 - val_accuracy: 0.9686\n","Epoch 130/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5751 - accuracy: 0.9156 - val_loss: 0.5367 - val_accuracy: 0.9671\n","Epoch 131/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5791 - accuracy: 0.9077 - val_loss: 0.5363 - val_accuracy: 0.9684\n","Epoch 132/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5733 - accuracy: 0.9156 - val_loss: 0.5362 - val_accuracy: 0.9686\n","Epoch 133/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5713 - accuracy: 0.9195 - val_loss: 0.5361 - val_accuracy: 0.9684\n","Epoch 134/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5750 - accuracy: 0.9133 - val_loss: 0.5366 - val_accuracy: 0.9673\n","Epoch 135/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5755 - accuracy: 0.9123 - val_loss: 0.5363 - val_accuracy: 0.9684\n","Epoch 136/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5764 - accuracy: 0.9115 - val_loss: 0.5362 - val_accuracy: 0.9686\n","Epoch 137/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5759 - accuracy: 0.9131 - val_loss: 0.5362 - val_accuracy: 0.9686\n","Epoch 138/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5786 - accuracy: 0.9082 - val_loss: 0.5364 - val_accuracy: 0.9676\n","Epoch 139/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5719 - accuracy: 0.9174 - val_loss: 0.5365 - val_accuracy: 0.9681\n","Epoch 140/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5757 - accuracy: 0.9131 - val_loss: 0.5366 - val_accuracy: 0.9676\n","Epoch 141/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5740 - accuracy: 0.9146 - val_loss: 0.5365 - val_accuracy: 0.9681\n","Epoch 142/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5699 - accuracy: 0.9208 - val_loss: 0.5359 - val_accuracy: 0.9691\n","Epoch 143/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5770 - accuracy: 0.9102 - val_loss: 0.5363 - val_accuracy: 0.9684\n","Epoch 144/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9182 - val_loss: 0.5360 - val_accuracy: 0.9689\n","Epoch 145/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5678 - accuracy: 0.9234 - val_loss: 0.5362 - val_accuracy: 0.9689\n","Epoch 146/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5750 - accuracy: 0.9126 - val_loss: 0.5363 - val_accuracy: 0.9681\n","Epoch 147/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5748 - accuracy: 0.9133 - val_loss: 0.5362 - val_accuracy: 0.9689\n","Epoch 148/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5752 - accuracy: 0.9136 - val_loss: 0.5361 - val_accuracy: 0.9686\n","Epoch 149/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5727 - accuracy: 0.9167 - val_loss: 0.5364 - val_accuracy: 0.9681\n","Epoch 150/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.9164 - val_loss: 0.5360 - val_accuracy: 0.9691\n","Epoch 151/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5686 - accuracy: 0.9231 - val_loss: 0.5356 - val_accuracy: 0.9694\n","Epoch 152/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5708 - accuracy: 0.9185 - val_loss: 0.5359 - val_accuracy: 0.9689\n","Epoch 153/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5703 - accuracy: 0.9195 - val_loss: 0.5356 - val_accuracy: 0.9691\n","Epoch 154/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5684 - accuracy: 0.9226 - val_loss: 0.5355 - val_accuracy: 0.9691\n","Epoch 155/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5708 - accuracy: 0.9192 - val_loss: 0.5355 - val_accuracy: 0.9699\n","Epoch 156/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.9164 - val_loss: 0.5356 - val_accuracy: 0.9691\n","Epoch 157/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5721 - accuracy: 0.9167 - val_loss: 0.5356 - val_accuracy: 0.9694\n","Epoch 158/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5702 - accuracy: 0.9195 - val_loss: 0.5358 - val_accuracy: 0.9694\n","Epoch 159/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5718 - accuracy: 0.9190 - val_loss: 0.5360 - val_accuracy: 0.9684\n","Epoch 160/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5695 - accuracy: 0.9216 - val_loss: 0.5353 - val_accuracy: 0.9697\n","Epoch 161/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5715 - accuracy: 0.9182 - val_loss: 0.5352 - val_accuracy: 0.9712\n","Epoch 162/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5754 - accuracy: 0.9138 - val_loss: 0.5360 - val_accuracy: 0.9689\n","Epoch 163/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5704 - accuracy: 0.9200 - val_loss: 0.5358 - val_accuracy: 0.9689\n","Epoch 164/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9182 - val_loss: 0.5359 - val_accuracy: 0.9689\n","Epoch 165/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5721 - accuracy: 0.9177 - val_loss: 0.5358 - val_accuracy: 0.9691\n","Epoch 166/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9185 - val_loss: 0.5357 - val_accuracy: 0.9697\n","Epoch 167/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5717 - accuracy: 0.9172 - val_loss: 0.5358 - val_accuracy: 0.9697\n","Epoch 168/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5693 - accuracy: 0.9198 - val_loss: 0.5359 - val_accuracy: 0.9691\n","Epoch 169/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.9216 - val_loss: 0.5356 - val_accuracy: 0.9699\n","Epoch 170/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5691 - accuracy: 0.9208 - val_loss: 0.5355 - val_accuracy: 0.9697\n","Epoch 171/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.9164 - val_loss: 0.5359 - val_accuracy: 0.9694\n","Epoch 172/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5724 - accuracy: 0.9154 - val_loss: 0.5356 - val_accuracy: 0.9694\n","Epoch 173/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5737 - accuracy: 0.9149 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 174/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5720 - accuracy: 0.9162 - val_loss: 0.5354 - val_accuracy: 0.9699\n","Epoch 175/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5708 - accuracy: 0.9185 - val_loss: 0.5351 - val_accuracy: 0.9699\n","Epoch 176/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9228 - val_loss: 0.5352 - val_accuracy: 0.9699\n","Epoch 177/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9180 - val_loss: 0.5353 - val_accuracy: 0.9697\n","Epoch 178/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9177 - val_loss: 0.5351 - val_accuracy: 0.9702\n","Epoch 179/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5702 - accuracy: 0.9195 - val_loss: 0.5355 - val_accuracy: 0.9694\n","Epoch 180/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5714 - accuracy: 0.9177 - val_loss: 0.5348 - val_accuracy: 0.9715\n","Epoch 181/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5732 - accuracy: 0.9146 - val_loss: 0.5355 - val_accuracy: 0.9694\n","Epoch 182/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5702 - accuracy: 0.9192 - val_loss: 0.5350 - val_accuracy: 0.9704\n","Epoch 183/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.9187 - val_loss: 0.5353 - val_accuracy: 0.9702\n","Epoch 184/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9218 - val_loss: 0.5354 - val_accuracy: 0.9694\n","Epoch 185/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5697 - accuracy: 0.9192 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 186/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5695 - accuracy: 0.9210 - val_loss: 0.5353 - val_accuracy: 0.9697\n","Epoch 187/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5698 - accuracy: 0.9203 - val_loss: 0.5359 - val_accuracy: 0.9686\n","Epoch 188/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5758 - accuracy: 0.9108 - val_loss: 0.5354 - val_accuracy: 0.9694\n","Epoch 189/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5721 - accuracy: 0.9164 - val_loss: 0.5352 - val_accuracy: 0.9702\n","Epoch 190/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5736 - accuracy: 0.9138 - val_loss: 0.5353 - val_accuracy: 0.9697\n","Epoch 191/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5702 - accuracy: 0.9185 - val_loss: 0.5355 - val_accuracy: 0.9691\n","Epoch 192/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9239 - val_loss: 0.5360 - val_accuracy: 0.9681\n","Epoch 193/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5713 - accuracy: 0.9172 - val_loss: 0.5355 - val_accuracy: 0.9689\n","Epoch 194/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.9151 - val_loss: 0.5356 - val_accuracy: 0.9686\n","Epoch 195/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9221 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 196/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.9216 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 197/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5727 - accuracy: 0.9159 - val_loss: 0.5346 - val_accuracy: 0.9712\n","Epoch 198/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5726 - accuracy: 0.9156 - val_loss: 0.5346 - val_accuracy: 0.9709\n","Epoch 199/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9234 - val_loss: 0.5349 - val_accuracy: 0.9707\n","Epoch 200/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9213 - val_loss: 0.5347 - val_accuracy: 0.9712\n","Epoch 201/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.9223 - val_loss: 0.5347 - val_accuracy: 0.9712\n","Epoch 202/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9218 - val_loss: 0.5346 - val_accuracy: 0.9712\n","Epoch 203/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9270 - val_loss: 0.5346 - val_accuracy: 0.9709\n","Epoch 204/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9216 - val_loss: 0.5351 - val_accuracy: 0.9699\n","Epoch 205/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9234 - val_loss: 0.5350 - val_accuracy: 0.9707\n","Epoch 206/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5736 - accuracy: 0.9149 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 207/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5733 - accuracy: 0.9138 - val_loss: 0.5357 - val_accuracy: 0.9691\n","Epoch 208/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9244 - val_loss: 0.5351 - val_accuracy: 0.9699\n","Epoch 209/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5712 - accuracy: 0.9177 - val_loss: 0.5353 - val_accuracy: 0.9699\n","Epoch 210/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5691 - accuracy: 0.9200 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 211/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9213 - val_loss: 0.5346 - val_accuracy: 0.9704\n","Epoch 212/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5707 - accuracy: 0.9187 - val_loss: 0.5352 - val_accuracy: 0.9697\n","Epoch 213/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9241 - val_loss: 0.5351 - val_accuracy: 0.9702\n","Epoch 214/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5757 - accuracy: 0.9110 - val_loss: 0.5350 - val_accuracy: 0.9704\n","Epoch 215/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9236 - val_loss: 0.5349 - val_accuracy: 0.9702\n","Epoch 216/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5712 - accuracy: 0.9172 - val_loss: 0.5356 - val_accuracy: 0.9691\n","Epoch 217/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9210 - val_loss: 0.5346 - val_accuracy: 0.9715\n","Epoch 218/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.9252 - val_loss: 0.5356 - val_accuracy: 0.9691\n","Epoch 219/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9213 - val_loss: 0.5351 - val_accuracy: 0.9702\n","Epoch 220/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5716 - accuracy: 0.9172 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 221/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5712 - accuracy: 0.9177 - val_loss: 0.5344 - val_accuracy: 0.9720\n","Epoch 222/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.9208 - val_loss: 0.5350 - val_accuracy: 0.9717\n","Epoch 223/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9216 - val_loss: 0.5351 - val_accuracy: 0.9717\n","Epoch 224/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5711 - accuracy: 0.9203 - val_loss: 0.5351 - val_accuracy: 0.9699\n","Epoch 225/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9231 - val_loss: 0.5354 - val_accuracy: 0.9694\n","Epoch 226/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5686 - accuracy: 0.9208 - val_loss: 0.5351 - val_accuracy: 0.9699\n","Epoch 227/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5694 - accuracy: 0.9198 - val_loss: 0.5349 - val_accuracy: 0.9699\n","Epoch 228/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5715 - accuracy: 0.9169 - val_loss: 0.5349 - val_accuracy: 0.9707\n","Epoch 229/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9216 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 230/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5711 - accuracy: 0.9174 - val_loss: 0.5349 - val_accuracy: 0.9704\n","Epoch 231/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5693 - accuracy: 0.9195 - val_loss: 0.5356 - val_accuracy: 0.9697\n","Epoch 232/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5697 - accuracy: 0.9190 - val_loss: 0.5352 - val_accuracy: 0.9704\n","Epoch 233/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9180 - val_loss: 0.5347 - val_accuracy: 0.9712\n","Epoch 234/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9262 - val_loss: 0.5352 - val_accuracy: 0.9699\n","Epoch 235/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5690 - accuracy: 0.9203 - val_loss: 0.5349 - val_accuracy: 0.9702\n","Epoch 236/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.9216 - val_loss: 0.5348 - val_accuracy: 0.9704\n","Epoch 237/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9241 - val_loss: 0.5348 - val_accuracy: 0.9704\n","Epoch 238/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9228 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 239/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9259 - val_loss: 0.5347 - val_accuracy: 0.9707\n","Epoch 240/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9195 - val_loss: 0.5354 - val_accuracy: 0.9694\n","Epoch 241/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9182 - val_loss: 0.5356 - val_accuracy: 0.9694\n","Epoch 242/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5692 - accuracy: 0.9200 - val_loss: 0.5355 - val_accuracy: 0.9694\n","Epoch 243/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9208 - val_loss: 0.5356 - val_accuracy: 0.9689\n","Epoch 244/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5722 - accuracy: 0.9162 - val_loss: 0.5356 - val_accuracy: 0.9691\n","Epoch 245/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9208 - val_loss: 0.5356 - val_accuracy: 0.9694\n","Epoch 246/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5698 - accuracy: 0.9187 - val_loss: 0.5357 - val_accuracy: 0.9686\n","Epoch 247/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5703 - accuracy: 0.9182 - val_loss: 0.5351 - val_accuracy: 0.9702\n","Epoch 248/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9239 - val_loss: 0.5350 - val_accuracy: 0.9702\n","Epoch 249/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5699 - accuracy: 0.9190 - val_loss: 0.5352 - val_accuracy: 0.9707\n","Epoch 250/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9246 - val_loss: 0.5347 - val_accuracy: 0.9702\n","Epoch 251/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5723 - accuracy: 0.9156 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 252/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9234 - val_loss: 0.5349 - val_accuracy: 0.9704\n","Epoch 253/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5697 - accuracy: 0.9195 - val_loss: 0.5348 - val_accuracy: 0.9702\n","Epoch 254/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5718 - accuracy: 0.9162 - val_loss: 0.5347 - val_accuracy: 0.9704\n","Epoch 255/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9234 - val_loss: 0.5351 - val_accuracy: 0.9702\n","Epoch 256/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9231 - val_loss: 0.5347 - val_accuracy: 0.9709\n","Epoch 257/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9249 - val_loss: 0.5346 - val_accuracy: 0.9704\n","Epoch 258/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.9141 - val_loss: 0.5352 - val_accuracy: 0.9699\n","Epoch 259/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5735 - accuracy: 0.9151 - val_loss: 0.5348 - val_accuracy: 0.9702\n","Epoch 260/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9249 - val_loss: 0.5350 - val_accuracy: 0.9699\n","Epoch 261/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5713 - accuracy: 0.9182 - val_loss: 0.5353 - val_accuracy: 0.9694\n","Epoch 262/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5711 - accuracy: 0.9185 - val_loss: 0.5356 - val_accuracy: 0.9689\n","Epoch 263/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9210 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 264/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9262 - val_loss: 0.5349 - val_accuracy: 0.9699\n","Epoch 265/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5693 - accuracy: 0.9195 - val_loss: 0.5355 - val_accuracy: 0.9689\n","Epoch 266/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9244 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 267/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9246 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 268/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9257 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 269/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5684 - accuracy: 0.9213 - val_loss: 0.5348 - val_accuracy: 0.9694\n","Epoch 270/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9239 - val_loss: 0.5351 - val_accuracy: 0.9699\n","Epoch 271/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5707 - accuracy: 0.9190 - val_loss: 0.5350 - val_accuracy: 0.9699\n","Epoch 272/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9254 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 273/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9244 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 274/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.9172 - val_loss: 0.5356 - val_accuracy: 0.9684\n","Epoch 275/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.9249 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 276/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.9208 - val_loss: 0.5357 - val_accuracy: 0.9684\n","Epoch 277/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5714 - accuracy: 0.9167 - val_loss: 0.5355 - val_accuracy: 0.9689\n","Epoch 278/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5691 - accuracy: 0.9203 - val_loss: 0.5353 - val_accuracy: 0.9694\n","Epoch 279/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9270 - val_loss: 0.5349 - val_accuracy: 0.9699\n","Epoch 280/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9239 - val_loss: 0.5347 - val_accuracy: 0.9704\n","Epoch 281/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5690 - accuracy: 0.9198 - val_loss: 0.5347 - val_accuracy: 0.9709\n","Epoch 282/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5345 - val_accuracy: 0.9709\n","Epoch 283/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5713 - accuracy: 0.9174 - val_loss: 0.5351 - val_accuracy: 0.9697\n","Epoch 284/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5649 - accuracy: 0.9259 - val_loss: 0.5348 - val_accuracy: 0.9699\n","Epoch 285/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9228 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 286/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5716 - accuracy: 0.9164 - val_loss: 0.5352 - val_accuracy: 0.9697\n","Epoch 287/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9244 - val_loss: 0.5349 - val_accuracy: 0.9691\n","Epoch 288/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5699 - accuracy: 0.9208 - val_loss: 0.5352 - val_accuracy: 0.9689\n","Epoch 289/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9254 - val_loss: 0.5351 - val_accuracy: 0.9697\n","Epoch 290/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9252 - val_loss: 0.5354 - val_accuracy: 0.9686\n","Epoch 291/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9226 - val_loss: 0.5356 - val_accuracy: 0.9691\n","Epoch 292/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9221 - val_loss: 0.5353 - val_accuracy: 0.9691\n","Epoch 293/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9282 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 294/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5692 - accuracy: 0.9200 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 295/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9226 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 296/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9241 - val_loss: 0.5353 - val_accuracy: 0.9691\n","Epoch 297/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9231 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 298/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9228 - val_loss: 0.5349 - val_accuracy: 0.9699\n","Epoch 299/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9213 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 300/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9267 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 301/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5699 - accuracy: 0.9216 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 302/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5692 - accuracy: 0.9210 - val_loss: 0.5354 - val_accuracy: 0.9694\n","Epoch 303/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9236 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 304/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9236 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 305/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5694 - accuracy: 0.9198 - val_loss: 0.5357 - val_accuracy: 0.9689\n","Epoch 306/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9210 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 307/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9241 - val_loss: 0.5355 - val_accuracy: 0.9691\n","Epoch 308/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.9249 - val_loss: 0.5355 - val_accuracy: 0.9689\n","Epoch 309/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9264 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 310/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9236 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 311/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9244 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 312/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.9208 - val_loss: 0.5353 - val_accuracy: 0.9691\n","Epoch 313/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 314/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9262 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 315/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9231 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 316/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9244 - val_loss: 0.5353 - val_accuracy: 0.9691\n","Epoch 317/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9226 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 318/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9216 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 319/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9226 - val_loss: 0.5345 - val_accuracy: 0.9704\n","Epoch 320/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5688 - accuracy: 0.9249 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 321/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9239 - val_loss: 0.5348 - val_accuracy: 0.9699\n","Epoch 322/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5690 - accuracy: 0.9208 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 323/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9231 - val_loss: 0.5347 - val_accuracy: 0.9702\n","Epoch 324/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9228 - val_loss: 0.5350 - val_accuracy: 0.9699\n","Epoch 325/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5704 - accuracy: 0.9190 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 326/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9295 - val_loss: 0.5350 - val_accuracy: 0.9699\n","Epoch 327/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5355 - val_accuracy: 0.9691\n","Epoch 328/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5701 - accuracy: 0.9190 - val_loss: 0.5352 - val_accuracy: 0.9697\n","Epoch 329/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5726 - accuracy: 0.9192 - val_loss: 0.5358 - val_accuracy: 0.9689\n","Epoch 330/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5684 - accuracy: 0.9221 - val_loss: 0.5357 - val_accuracy: 0.9686\n","Epoch 331/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9210 - val_loss: 0.5355 - val_accuracy: 0.9689\n","Epoch 332/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9249 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 333/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9239 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 334/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9239 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 335/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.9241 - val_loss: 0.5353 - val_accuracy: 0.9691\n","Epoch 336/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9246 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 337/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9244 - val_loss: 0.5351 - val_accuracy: 0.9697\n","Epoch 338/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.9218 - val_loss: 0.5352 - val_accuracy: 0.9697\n","Epoch 339/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5697 - accuracy: 0.9195 - val_loss: 0.5345 - val_accuracy: 0.9704\n","Epoch 340/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9226 - val_loss: 0.5350 - val_accuracy: 0.9699\n","Epoch 341/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5684 - accuracy: 0.9216 - val_loss: 0.5352 - val_accuracy: 0.9697\n","Epoch 342/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9216 - val_loss: 0.5351 - val_accuracy: 0.9699\n","Epoch 343/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9262 - val_loss: 0.5348 - val_accuracy: 0.9702\n","Epoch 344/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9259 - val_loss: 0.5352 - val_accuracy: 0.9697\n","Epoch 345/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9239 - val_loss: 0.5352 - val_accuracy: 0.9697\n","Epoch 346/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9709\n","Epoch 347/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5699 - accuracy: 0.9192 - val_loss: 0.5353 - val_accuracy: 0.9691\n","Epoch 348/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 349/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9239 - val_loss: 0.5348 - val_accuracy: 0.9704\n","Epoch 350/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9213 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 351/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9239 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 352/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5698 - accuracy: 0.9190 - val_loss: 0.5347 - val_accuracy: 0.9702\n","Epoch 353/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9221 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 354/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9246 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 355/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 356/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9216 - val_loss: 0.5353 - val_accuracy: 0.9694\n","Epoch 357/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9228 - val_loss: 0.5355 - val_accuracy: 0.9686\n","Epoch 358/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9295 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 359/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9259 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 360/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9241 - val_loss: 0.5347 - val_accuracy: 0.9702\n","Epoch 361/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9272 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 362/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9239 - val_loss: 0.5349 - val_accuracy: 0.9697\n","Epoch 363/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5699 - accuracy: 0.9190 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 364/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9221 - val_loss: 0.5348 - val_accuracy: 0.9699\n","Epoch 365/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5677 - accuracy: 0.9221 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 366/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5696 - accuracy: 0.9223 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 367/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9303 - val_loss: 0.5350 - val_accuracy: 0.9699\n","Epoch 368/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5649 - accuracy: 0.9267 - val_loss: 0.5349 - val_accuracy: 0.9699\n","Epoch 369/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9257 - val_loss: 0.5349 - val_accuracy: 0.9699\n","Epoch 370/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5684 - accuracy: 0.9213 - val_loss: 0.5345 - val_accuracy: 0.9704\n","Epoch 371/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5344 - val_accuracy: 0.9704\n","Epoch 372/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9234 - val_loss: 0.5344 - val_accuracy: 0.9704\n","Epoch 373/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 374/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9712\n","Epoch 375/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9264 - val_loss: 0.5346 - val_accuracy: 0.9704\n","Epoch 376/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9231 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 377/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9272 - val_loss: 0.5347 - val_accuracy: 0.9702\n","Epoch 378/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.9223 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 379/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 380/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9259 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 381/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9270 - val_loss: 0.5349 - val_accuracy: 0.9697\n","Epoch 382/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9264 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 383/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9290 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 384/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9257 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 385/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9231 - val_loss: 0.5344 - val_accuracy: 0.9704\n","Epoch 386/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9277 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 387/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5692 - accuracy: 0.9203 - val_loss: 0.5343 - val_accuracy: 0.9707\n","Epoch 388/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9236 - val_loss: 0.5342 - val_accuracy: 0.9707\n","Epoch 389/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 390/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 391/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.9252 - val_loss: 0.5345 - val_accuracy: 0.9704\n","Epoch 392/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9210 - val_loss: 0.5343 - val_accuracy: 0.9704\n","Epoch 393/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9707\n","Epoch 394/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9252 - val_loss: 0.5347 - val_accuracy: 0.9704\n","Epoch 395/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9275 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 396/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9264 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 397/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9262 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 398/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5698 - accuracy: 0.9216 - val_loss: 0.5353 - val_accuracy: 0.9694\n","Epoch 399/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9241 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 400/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9223 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 401/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9254 - val_loss: 0.5353 - val_accuracy: 0.9691\n","Epoch 402/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9267 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 403/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5700 - accuracy: 0.9190 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 404/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9290 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 405/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 406/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9311 - val_loss: 0.5359 - val_accuracy: 0.9684\n","Epoch 407/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5608 - accuracy: 0.9321 - val_loss: 0.5358 - val_accuracy: 0.9684\n","Epoch 408/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9295 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 409/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9236 - val_loss: 0.5354 - val_accuracy: 0.9691\n","Epoch 410/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9262 - val_loss: 0.5349 - val_accuracy: 0.9697\n","Epoch 411/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.9249 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 412/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9270 - val_loss: 0.5350 - val_accuracy: 0.9697\n","Epoch 413/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5692 - accuracy: 0.9200 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 414/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5346 - val_accuracy: 0.9699\n","Epoch 415/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9293 - val_loss: 0.5352 - val_accuracy: 0.9694\n","Epoch 416/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9257 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 417/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 418/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9226 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 419/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9221 - val_loss: 0.5347 - val_accuracy: 0.9702\n","Epoch 420/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5612 - accuracy: 0.9313 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 421/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9252 - val_loss: 0.5347 - val_accuracy: 0.9702\n","Epoch 422/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9226 - val_loss: 0.5346 - val_accuracy: 0.9702\n","Epoch 423/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5618 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9707\n","Epoch 424/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5611 - accuracy: 0.9321 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 425/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5691 - accuracy: 0.9216 - val_loss: 0.5344 - val_accuracy: 0.9704\n","Epoch 426/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9298 - val_loss: 0.5341 - val_accuracy: 0.9715\n","Epoch 427/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5702 - accuracy: 0.9205 - val_loss: 0.5348 - val_accuracy: 0.9702\n","Epoch 428/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9285 - val_loss: 0.5345 - val_accuracy: 0.9704\n","Epoch 429/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9272 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 430/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9236 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 431/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9234 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 432/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5691 - accuracy: 0.9203 - val_loss: 0.5350 - val_accuracy: 0.9691\n","Epoch 433/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9280 - val_loss: 0.5352 - val_accuracy: 0.9689\n","Epoch 434/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9280 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 435/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9216 - val_loss: 0.5353 - val_accuracy: 0.9686\n","Epoch 436/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9300 - val_loss: 0.5352 - val_accuracy: 0.9691\n","Epoch 437/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5348 - val_accuracy: 0.9697\n","Epoch 438/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9295 - val_loss: 0.5348 - val_accuracy: 0.9697\n","Epoch 439/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5620 - accuracy: 0.9303 - val_loss: 0.5343 - val_accuracy: 0.9704\n","Epoch 440/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5698 - accuracy: 0.9198 - val_loss: 0.5352 - val_accuracy: 0.9689\n","Epoch 441/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5352 - val_accuracy: 0.9689\n","Epoch 442/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9226 - val_loss: 0.5348 - val_accuracy: 0.9694\n","Epoch 443/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5697 - accuracy: 0.9234 - val_loss: 0.5352 - val_accuracy: 0.9689\n","Epoch 444/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5351 - val_accuracy: 0.9689\n","Epoch 445/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5677 - accuracy: 0.9221 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 446/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 447/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9257 - val_loss: 0.5346 - val_accuracy: 0.9697\n","Epoch 448/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9231 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 449/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 450/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.9298 - val_loss: 0.5350 - val_accuracy: 0.9694\n","Epoch 451/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9262 - val_loss: 0.5348 - val_accuracy: 0.9694\n","Epoch 452/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9246 - val_loss: 0.5344 - val_accuracy: 0.9707\n","Epoch 453/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9275 - val_loss: 0.5349 - val_accuracy: 0.9697\n","Epoch 454/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5677 - accuracy: 0.9246 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 455/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 456/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9239 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 457/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9210 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 458/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9282 - val_loss: 0.5351 - val_accuracy: 0.9691\n","Epoch 459/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9249 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 460/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9254 - val_loss: 0.5351 - val_accuracy: 0.9694\n","Epoch 461/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9231 - val_loss: 0.5346 - val_accuracy: 0.9697\n","Epoch 462/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9236 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 463/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 464/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 465/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 466/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9295 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 467/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 468/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5695 - accuracy: 0.9192 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 469/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9709\n","Epoch 470/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9257 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 471/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9236 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 472/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9244 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 473/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9241 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 474/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9298 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 475/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9262 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 476/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9275 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 477/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9262 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 478/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9254 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 479/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9308 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 480/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9280 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 481/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9254 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 482/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 483/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9231 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 484/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5620 - accuracy: 0.9303 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 485/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5610 - accuracy: 0.9321 - val_loss: 0.5346 - val_accuracy: 0.9702\n","Epoch 486/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 487/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5608 - accuracy: 0.9326 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 488/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9267 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 489/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5701 - accuracy: 0.9216 - val_loss: 0.5347 - val_accuracy: 0.9699\n","Epoch 490/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9226 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 491/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9704\n","Epoch 492/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 493/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9259 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 494/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9270 - val_loss: 0.5348 - val_accuracy: 0.9697\n","Epoch 495/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5601 - accuracy: 0.9331 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 496/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9704\n","Epoch 497/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9259 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 498/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 499/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5591 - accuracy: 0.9349 - val_loss: 0.5340 - val_accuracy: 0.9712\n","Epoch 500/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9709\n","Epoch 501/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.9213 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 502/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9231 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 503/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9236 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 504/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5346 - val_accuracy: 0.9697\n","Epoch 505/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9257 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 506/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9244 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 507/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9262 - val_loss: 0.5349 - val_accuracy: 0.9697\n","Epoch 508/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9226 - val_loss: 0.5344 - val_accuracy: 0.9704\n","Epoch 509/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5584 - accuracy: 0.9352 - val_loss: 0.5346 - val_accuracy: 0.9699\n","Epoch 510/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9704\n","Epoch 511/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9270 - val_loss: 0.5346 - val_accuracy: 0.9697\n","Epoch 512/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9228 - val_loss: 0.5346 - val_accuracy: 0.9697\n","Epoch 513/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5621 - accuracy: 0.9300 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 514/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 515/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9272 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 516/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9293 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 517/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 518/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9293 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 519/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 520/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5720 - accuracy: 0.9195 - val_loss: 0.5348 - val_accuracy: 0.9697\n","Epoch 521/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 522/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9318 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 523/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9231 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 524/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9298 - val_loss: 0.5348 - val_accuracy: 0.9697\n","Epoch 525/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9280 - val_loss: 0.5346 - val_accuracy: 0.9699\n","Epoch 526/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9239 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 527/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9285 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 528/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 529/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 530/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 531/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 532/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9241 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 533/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 534/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9236 - val_loss: 0.5349 - val_accuracy: 0.9694\n","Epoch 535/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.9334 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 536/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9280 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 537/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5346 - val_accuracy: 0.9702\n","Epoch 538/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9241 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 539/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9313 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 540/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 541/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5342 - val_accuracy: 0.9707\n","Epoch 542/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 543/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9241 - val_loss: 0.5347 - val_accuracy: 0.9694\n","Epoch 544/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 545/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9272 - val_loss: 0.5347 - val_accuracy: 0.9694\n","Epoch 546/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9239 - val_loss: 0.5347 - val_accuracy: 0.9697\n","Epoch 547/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9241 - val_loss: 0.5346 - val_accuracy: 0.9697\n","Epoch 548/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9290 - val_loss: 0.5347 - val_accuracy: 0.9694\n","Epoch 549/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9262 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 550/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9236 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 551/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9244 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 552/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.9277 - val_loss: 0.5343 - val_accuracy: 0.9704\n","Epoch 553/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9244 - val_loss: 0.5341 - val_accuracy: 0.9712\n","Epoch 554/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9241 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 555/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 556/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9257 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 557/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9246 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 558/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9311 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 559/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9244 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 560/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 561/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 562/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 563/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.9180 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 564/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 565/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 566/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9244 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 567/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5620 - accuracy: 0.9303 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 568/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9282 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 569/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9236 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 570/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 571/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9234 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 572/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 573/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 574/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 575/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9244 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 576/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 577/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 578/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 579/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9208 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 580/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 581/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5678 - accuracy: 0.9218 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 582/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 583/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5696 - accuracy: 0.9195 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 584/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 585/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 586/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 587/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9259 - val_loss: 0.5345 - val_accuracy: 0.9702\n","Epoch 588/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 589/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 590/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9277 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 591/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 592/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 593/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9231 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 594/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9277 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 595/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5620 - accuracy: 0.9303 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 596/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.9216 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 597/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9285 - val_loss: 0.5345 - val_accuracy: 0.9699\n","Epoch 598/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5584 - accuracy: 0.9354 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 599/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 600/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5344 - val_accuracy: 0.9702\n","Epoch 601/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5621 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 602/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 603/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9280 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 604/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 605/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9236 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 606/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 607/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.9313 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 608/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 609/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 610/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9311 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 611/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9280 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 612/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 613/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.9316 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 614/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5713 - accuracy: 0.9167 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 615/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 616/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.9213 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 617/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 618/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 619/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 620/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 621/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5598 - accuracy: 0.9334 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 622/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 623/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9223 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 624/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9208 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 625/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 626/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9218 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 627/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5635 - accuracy: 0.9306 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 628/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5649 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 629/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 630/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 631/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.9228 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 632/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 633/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 634/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9208 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 635/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 636/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.9216 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 637/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 638/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 639/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9254 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 640/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 641/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5686 - accuracy: 0.9223 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 642/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 643/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5677 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 644/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 645/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 646/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5649 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 647/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5684 - accuracy: 0.9223 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 648/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 649/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9249 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 650/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9262 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 651/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 652/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5605 - accuracy: 0.9324 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 653/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9234 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 654/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 655/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 656/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 657/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 658/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9267 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 659/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9285 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 660/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9313 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 661/10000\n","486/486 [==============================] - 24372s 50s/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 662/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5602 - accuracy: 0.9329 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 663/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 664/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9282 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 665/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 666/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9293 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 667/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 668/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 669/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 670/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9241 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 671/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 672/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5619 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 673/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.9236 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 674/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5635 - accuracy: 0.9280 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 675/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 676/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 677/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9267 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 678/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9311 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 679/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 680/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5620 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 681/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.9329 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 682/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9313 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 683/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5636 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 684/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 685/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 686/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 687/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5602 - accuracy: 0.9326 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 688/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 689/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5688 - accuracy: 0.9205 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 690/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5649 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 691/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5598 - accuracy: 0.9334 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 692/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9313 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 693/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 694/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.9228 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 695/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9257 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 696/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 697/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 698/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5648 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 699/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 700/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 701/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5688 - accuracy: 0.9203 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 702/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 703/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 704/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9262 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 705/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 706/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 707/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5604 - accuracy: 0.9324 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 708/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 709/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 710/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.9246 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 711/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 712/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.9311 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 713/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9228 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 714/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5660 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 715/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5698 - accuracy: 0.9226 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 716/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 717/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9249 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 718/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.9213 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 719/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 720/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 721/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 722/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 723/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 724/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5587 - accuracy: 0.9349 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 725/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 726/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 727/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 728/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 729/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9249 - val_loss: 0.5340 - val_accuracy: 0.9702\n","Epoch 730/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.9216 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 731/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5612 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 732/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.9246 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 733/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 734/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 735/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.9234 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 736/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 737/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9311 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 738/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.9249 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 739/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 740/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 741/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 742/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 743/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5623 - accuracy: 0.9298 - val_loss: 0.5340 - val_accuracy: 0.9709\n","Epoch 744/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.9264 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 745/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 746/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 747/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 748/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 749/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5594 - accuracy: 0.9342 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 750/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 751/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.9213 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 752/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9267 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 753/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5658 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 754/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9254 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 755/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.9239 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 756/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 757/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 758/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 759/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.9218 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 760/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 761/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 762/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.9295 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 763/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 764/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 765/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9280 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 766/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.9316 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 767/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9300 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 768/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5658 - accuracy: 0.9267 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 769/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.9231 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 770/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 771/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 772/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.9241 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 773/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 774/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 775/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 776/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 777/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5610 - accuracy: 0.9324 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 778/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5614 - accuracy: 0.9311 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 779/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5623 - accuracy: 0.9318 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 780/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 781/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 782/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 783/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9298 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 784/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 785/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 786/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 787/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5658 - accuracy: 0.9277 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 788/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 789/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 790/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 791/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.9259 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 792/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 793/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 794/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5642 - accuracy: 0.9275 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 795/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9313 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 796/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.9236 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 797/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 798/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 799/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5588 - accuracy: 0.9347 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 800/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 801/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.9228 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 802/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.9259 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 803/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 804/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 805/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 806/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 807/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 808/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 809/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5611 - accuracy: 0.9316 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 810/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.9218 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 811/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 812/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.9218 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 813/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 814/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 815/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 816/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 817/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 818/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5621 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 819/10000\n","486/486 [==============================] - 3s 7ms/step - loss: 0.5609 - accuracy: 0.9326 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 820/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.9329 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 821/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5650 - accuracy: 0.9254 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 822/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 823/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5678 - accuracy: 0.9218 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 824/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9262 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 825/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 826/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5595 - accuracy: 0.9339 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 827/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9290 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 828/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9280 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 829/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.9172 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 830/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 831/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 832/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5607 - accuracy: 0.9318 - val_loss: 0.5340 - val_accuracy: 0.9702\n","Epoch 833/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5336 - val_accuracy: 0.9712\n","Epoch 834/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9298 - val_loss: 0.5337 - val_accuracy: 0.9709\n","Epoch 835/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.9298 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 836/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 837/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 838/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5660 - accuracy: 0.9244 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 839/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9290 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 840/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 841/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 842/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5623 - accuracy: 0.9300 - val_loss: 0.5340 - val_accuracy: 0.9702\n","Epoch 843/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 844/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 845/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5610 - accuracy: 0.9326 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 846/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9264 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 847/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 848/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9241 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 849/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 850/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5585 - accuracy: 0.9349 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 851/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5607 - accuracy: 0.9318 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 852/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 853/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 854/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5631 - accuracy: 0.9290 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 855/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 856/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5575 - accuracy: 0.9367 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 857/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5612 - accuracy: 0.9311 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 858/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 859/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 860/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 861/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 862/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 863/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5340 - val_accuracy: 0.9702\n","Epoch 864/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 865/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 866/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 867/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 868/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 869/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 870/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9298 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 871/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9295 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 872/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 873/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9300 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 874/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5578 - accuracy: 0.9362 - val_loss: 0.5336 - val_accuracy: 0.9709\n","Epoch 875/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9267 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 876/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9252 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 877/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9226 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 878/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 879/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 880/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9257 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 881/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 882/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 883/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5605 - accuracy: 0.9324 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 884/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 885/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.9241 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 886/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.9203 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 887/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5612 - accuracy: 0.9311 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 888/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5584 - accuracy: 0.9352 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 889/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.9246 - val_loss: 0.5336 - val_accuracy: 0.9712\n","Epoch 890/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 891/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.9234 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 892/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 893/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5619 - accuracy: 0.9311 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 894/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 895/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 896/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 897/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 898/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 899/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5708 - accuracy: 0.9205 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 900/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 901/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 902/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 903/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9259 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 904/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.9226 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 905/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5637 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 906/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9285 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 907/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.9205 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 908/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.9303 - val_loss: 0.5336 - val_accuracy: 0.9712\n","Epoch 909/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 910/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 911/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.9231 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 912/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 913/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9249 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 914/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 915/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9257 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 916/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.9208 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 917/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.9257 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 918/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 919/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 920/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 921/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 922/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 923/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 924/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 925/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9228 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 926/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5602 - accuracy: 0.9331 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 927/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9293 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 928/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 929/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 930/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 931/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 932/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.9244 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 933/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9275 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 934/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5599 - accuracy: 0.9331 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 935/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 936/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9709\n","Epoch 937/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5603 - accuracy: 0.9334 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 938/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 939/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 940/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.9308 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 941/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.9244 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 942/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 943/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5615 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 944/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9303 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 945/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9318 - val_loss: 0.5340 - val_accuracy: 0.9702\n","Epoch 946/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 947/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 948/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 949/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 950/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 951/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5626 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 952/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5605 - accuracy: 0.9324 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 953/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5652 - accuracy: 0.9254 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 954/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 955/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 956/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 957/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 958/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9259 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 959/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 960/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9303 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 961/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.9280 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 962/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9303 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 963/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 964/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9303 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 965/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5635 - accuracy: 0.9277 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 966/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 967/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 968/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9311 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 969/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 970/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 971/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.9213 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 972/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.9236 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 973/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 974/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 975/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 976/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.9254 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 977/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 978/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 979/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 980/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5610 - accuracy: 0.9316 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 981/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.9246 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 982/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 983/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 984/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 985/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5602 - accuracy: 0.9326 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 986/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 987/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 988/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5692 - accuracy: 0.9203 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 989/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.9236 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 990/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 991/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 992/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 993/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.9218 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 994/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 995/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 996/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.9228 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 997/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5626 - accuracy: 0.9316 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 998/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 999/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1000/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5569 - accuracy: 0.9375 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1001/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1002/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5604 - accuracy: 0.9324 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1003/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5336 - val_accuracy: 0.9715\n","Epoch 1004/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5334 - val_accuracy: 0.9715\n","Epoch 1005/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9334 - val_loss: 0.5336 - val_accuracy: 0.9715\n","Epoch 1006/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9282 - val_loss: 0.5336 - val_accuracy: 0.9715\n","Epoch 1007/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9282 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1008/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9223 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1009/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9300 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1010/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1011/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1012/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1013/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1014/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9246 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1015/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1016/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1017/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9280 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1018/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9254 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1019/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1020/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1021/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9318 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1022/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1023/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1024/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9318 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1025/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9259 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1026/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1027/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5690 - accuracy: 0.9200 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1028/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1029/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1030/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1031/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1032/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.9221 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1033/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5610 - accuracy: 0.9354 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1034/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5598 - accuracy: 0.9334 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1035/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1036/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5608 - accuracy: 0.9318 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1037/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1038/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1039/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1040/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1041/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1042/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1043/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1044/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.9226 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1045/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1046/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9298 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1047/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5602 - accuracy: 0.9326 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1048/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9290 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1049/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9275 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1050/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.9231 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1051/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1052/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1053/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1054/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1055/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5700 - accuracy: 0.9187 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1056/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1057/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1058/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1059/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5601 - accuracy: 0.9329 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1060/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1061/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9239 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1062/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1063/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9306 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1064/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5612 - accuracy: 0.9311 - val_loss: 0.5337 - val_accuracy: 0.9709\n","Epoch 1065/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9306 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1066/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1067/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9228 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1068/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5589 - accuracy: 0.9344 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1069/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5688 - accuracy: 0.9205 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1070/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9231 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1071/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1072/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1073/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5584 - accuracy: 0.9352 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1074/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5604 - accuracy: 0.9326 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1075/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5612 - accuracy: 0.9311 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1076/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9254 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1077/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1078/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1079/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1080/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5599 - accuracy: 0.9331 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1081/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1082/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1083/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1084/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.9221 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1085/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1086/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1087/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1088/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.9311 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1089/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5340 - val_accuracy: 0.9702\n","Epoch 1090/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1091/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1092/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9295 - val_loss: 0.5337 - val_accuracy: 0.9712\n","Epoch 1093/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.9241 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1094/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1095/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1096/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.9285 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1097/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1098/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1099/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5732 - accuracy: 0.9254 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1100/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9300 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1101/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1102/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 1103/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5336 - val_accuracy: 0.9715\n","Epoch 1104/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 1105/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9216 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 1106/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 1107/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5636 - accuracy: 0.9285 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1108/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9277 - val_loss: 0.5336 - val_accuracy: 0.9715\n","Epoch 1109/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5702 - accuracy: 0.9277 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1110/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1111/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1112/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9293 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1113/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5612 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1114/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.9231 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1115/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.9231 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1116/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9285 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1117/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9295 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1118/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9295 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1119/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1120/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5678 - accuracy: 0.9216 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1121/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1122/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1123/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.9244 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1124/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1125/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1126/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5599 - accuracy: 0.9329 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1127/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.9236 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1128/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.9234 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1129/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1130/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5619 - accuracy: 0.9311 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1131/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5601 - accuracy: 0.9329 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1132/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1133/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5610 - accuracy: 0.9318 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1134/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9257 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1135/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1136/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1137/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9272 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1138/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.9264 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1139/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1140/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1141/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1142/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9252 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1143/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.9257 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1144/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5606 - accuracy: 0.9321 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1145/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5655 - accuracy: 0.9249 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1146/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5695 - accuracy: 0.9244 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1147/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9231 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1148/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5660 - accuracy: 0.9241 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1149/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5694 - accuracy: 0.9241 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1150/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1151/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5693 - accuracy: 0.9205 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1152/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5338 - val_accuracy: 0.9704\n","Epoch 1153/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5628 - accuracy: 0.9290 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1154/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1155/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9293 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1156/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9290 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1157/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5652 - accuracy: 0.9254 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1158/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1159/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1160/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9244 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1161/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1162/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.9226 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1163/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1164/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5587 - accuracy: 0.9347 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1165/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9280 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1166/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.9218 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1167/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1168/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1169/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5710 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1170/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1171/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9313 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1172/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9295 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1173/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9226 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1174/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9259 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1175/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9311 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1176/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5588 - accuracy: 0.9347 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1177/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5611 - accuracy: 0.9313 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1178/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1179/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1180/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1181/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.9236 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 1182/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1183/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1184/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9244 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 1185/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5603 - accuracy: 0.9326 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1186/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9254 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1187/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1188/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1189/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9285 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1190/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9262 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1191/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1192/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9709\n","Epoch 1193/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5602 - accuracy: 0.9326 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1194/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1195/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5601 - accuracy: 0.9326 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1196/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5339 - val_accuracy: 0.9712\n","Epoch 1197/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.9228 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1198/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5632 - accuracy: 0.9293 - val_loss: 0.5334 - val_accuracy: 0.9717\n","Epoch 1199/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9298 - val_loss: 0.5335 - val_accuracy: 0.9712\n","Epoch 1200/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.9262 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1201/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1202/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1203/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1204/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5603 - accuracy: 0.9334 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1205/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9252 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1206/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1207/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1208/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5695 - accuracy: 0.9252 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1209/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.9257 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1210/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9205 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1211/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1212/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9234 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1213/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1214/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1215/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1216/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9241 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1217/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1218/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9303 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1219/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5655 - accuracy: 0.9282 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1220/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5642 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1221/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.9282 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1222/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1223/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5611 - accuracy: 0.9313 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1224/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1225/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1226/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5340 - val_accuracy: 0.9709\n","Epoch 1227/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5338 - val_accuracy: 0.9709\n","Epoch 1228/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9285 - val_loss: 0.5336 - val_accuracy: 0.9712\n","Epoch 1229/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5584 - accuracy: 0.9352 - val_loss: 0.5337 - val_accuracy: 0.9709\n","Epoch 1230/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5338 - val_accuracy: 0.9709\n","Epoch 1231/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5658 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1232/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.9239 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1233/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5595 - accuracy: 0.9336 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1234/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9303 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1235/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1236/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1237/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1238/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1239/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1240/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.9228 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1241/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1242/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5652 - accuracy: 0.9257 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1243/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9275 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1244/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1245/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5621 - accuracy: 0.9300 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1246/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 1247/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 1248/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1249/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9239 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1250/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1251/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1252/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1253/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9254 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1254/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9223 - val_loss: 0.5340 - val_accuracy: 0.9712\n","Epoch 1255/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5339 - val_accuracy: 0.9712\n","Epoch 1256/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5339 - val_accuracy: 0.9712\n","Epoch 1257/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5653 - accuracy: 0.9252 - val_loss: 0.5339 - val_accuracy: 0.9712\n","Epoch 1258/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5607 - accuracy: 0.9321 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1259/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1260/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1261/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 1262/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5602 - accuracy: 0.9344 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1263/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9231 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1264/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5608 - accuracy: 0.9318 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1265/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1266/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5603 - accuracy: 0.9324 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1267/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.9249 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1268/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1269/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9267 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1270/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1271/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5340 - val_accuracy: 0.9709\n","Epoch 1272/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5340 - val_accuracy: 0.9709\n","Epoch 1273/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5596 - accuracy: 0.9334 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1274/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5610 - accuracy: 0.9316 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1275/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1276/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5608 - accuracy: 0.9318 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1277/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1278/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1279/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9223 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1280/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9246 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1281/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9306 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1282/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5639 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1283/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5718 - accuracy: 0.9252 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1284/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5625 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1285/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1286/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5635 - accuracy: 0.9277 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1287/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1288/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1289/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5662 - accuracy: 0.9241 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1290/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1291/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1292/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1293/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1294/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9313 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1295/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.9231 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1296/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5663 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1297/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1298/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1299/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9244 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1300/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.9298 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1301/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5650 - accuracy: 0.9259 - val_loss: 0.5336 - val_accuracy: 0.9715\n","Epoch 1302/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9252 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1303/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9264 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1304/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5612 - accuracy: 0.9321 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1305/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5621 - accuracy: 0.9303 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 1306/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1307/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1308/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1309/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1310/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1311/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1312/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1313/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1314/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9234 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1315/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.9262 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1316/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5338 - val_accuracy: 0.9709\n","Epoch 1317/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9316 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1318/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1319/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1320/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5638 - accuracy: 0.9275 - val_loss: 0.5337 - val_accuracy: 0.9707\n","Epoch 1321/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9298 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1322/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5338 - val_accuracy: 0.9704\n","Epoch 1323/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1324/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1325/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5621 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1326/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5665 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1327/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1328/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9300 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1329/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5678 - accuracy: 0.9241 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1330/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9275 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1331/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1332/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1333/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9290 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1334/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1335/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1336/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9318 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1337/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5619 - accuracy: 0.9318 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1338/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1339/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9311 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1340/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1341/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9313 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1342/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9282 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1343/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1344/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1345/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1346/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1347/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9239 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1348/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9223 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1349/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1350/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1351/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1352/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.9234 - val_loss: 0.5340 - val_accuracy: 0.9702\n","Epoch 1353/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1354/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9313 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1355/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1356/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1357/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.9244 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1358/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1359/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5635 - accuracy: 0.9313 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1360/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9290 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1361/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1362/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5693 - accuracy: 0.9195 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1363/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5627 - accuracy: 0.9326 - val_loss: 0.5339 - val_accuracy: 0.9712\n","Epoch 1364/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9280 - val_loss: 0.5338 - val_accuracy: 0.9707\n","Epoch 1365/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9293 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1366/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5611 - accuracy: 0.9313 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1367/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5622 - accuracy: 0.9295 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1368/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1369/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5606 - accuracy: 0.9321 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1370/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1371/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5601 - accuracy: 0.9339 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1372/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1373/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5633 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1374/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1375/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1376/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9275 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1377/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5662 - accuracy: 0.9241 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1378/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.9264 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1379/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1380/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9280 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1381/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1382/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5612 - accuracy: 0.9311 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1383/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5612 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1384/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5615 - accuracy: 0.9321 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1385/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5611 - accuracy: 0.9313 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1386/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9264 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1387/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9254 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1388/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5635 - accuracy: 0.9280 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1389/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1390/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9210 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1391/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9277 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1392/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1393/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9290 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1394/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1395/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5621 - accuracy: 0.9303 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1396/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1397/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9290 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1398/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1399/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1400/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1401/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1402/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9303 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1403/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5604 - accuracy: 0.9324 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1404/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1405/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1406/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.9290 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1407/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5338 - val_accuracy: 0.9704\n","Epoch 1408/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.9252 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1409/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9282 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1410/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9290 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1411/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1412/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9236 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1413/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5339 - val_accuracy: 0.9704\n","Epoch 1414/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1415/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1416/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1417/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1418/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.9223 - val_loss: 0.5339 - val_accuracy: 0.9707\n","Epoch 1419/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5338 - val_accuracy: 0.9712\n","Epoch 1420/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5579 - accuracy: 0.9360 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1421/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.9208 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1422/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9262 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 1423/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1424/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5626 - accuracy: 0.9300 - val_loss: 0.5342 - val_accuracy: 0.9704\n","Epoch 1425/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9300 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1426/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5611 - accuracy: 0.9313 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1427/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1428/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5584 - accuracy: 0.9352 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1429/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1430/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1431/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9236 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1432/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5616 - accuracy: 0.9306 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1433/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1434/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9293 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1435/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1436/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5650 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1437/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5628 - accuracy: 0.9298 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1438/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5691 - accuracy: 0.9257 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1439/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5650 - accuracy: 0.9257 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1440/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9313 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1441/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1442/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1443/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9244 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1444/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1445/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.9223 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1446/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1447/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.9259 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1448/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9280 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1449/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5593 - accuracy: 0.9339 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1450/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1451/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9318 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1452/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1453/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1454/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9272 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1455/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.9272 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1456/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5635 - accuracy: 0.9277 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1457/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.9231 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1458/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9241 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1459/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5695 - accuracy: 0.9195 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1460/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.9267 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1461/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5658 - accuracy: 0.9244 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1462/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5582 - accuracy: 0.9354 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1463/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9270 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1464/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9241 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1465/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1466/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1467/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1468/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5608 - accuracy: 0.9318 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1469/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1470/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1471/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9298 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1472/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5619 - accuracy: 0.9306 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1473/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.9236 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1474/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1475/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9239 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1476/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5672 - accuracy: 0.9228 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1477/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5660 - accuracy: 0.9241 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1478/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1479/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1480/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.9221 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1481/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9254 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1482/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1483/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1484/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5635 - accuracy: 0.9277 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1485/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5654 - accuracy: 0.9254 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1486/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1487/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5658 - accuracy: 0.9244 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1488/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1489/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9239 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1490/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1491/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5692 - accuracy: 0.9249 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1492/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.9254 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1493/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9257 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1494/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5619 - accuracy: 0.9318 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1495/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5596 - accuracy: 0.9336 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1496/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5633 - accuracy: 0.9285 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1497/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5586 - accuracy: 0.9349 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1498/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1499/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1500/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5602 - accuracy: 0.9326 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1501/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5600 - accuracy: 0.9329 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1502/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1503/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1504/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5605 - accuracy: 0.9321 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1505/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1506/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1507/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.9236 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1508/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1509/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9239 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1510/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5657 - accuracy: 0.9246 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1511/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1512/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9318 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 1513/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1514/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1515/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1516/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1517/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5622 - accuracy: 0.9298 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1518/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5638 - accuracy: 0.9272 - val_loss: 0.5337 - val_accuracy: 0.9712\n","Epoch 1519/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5693 - accuracy: 0.9223 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1520/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.9234 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1521/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1522/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5609 - accuracy: 0.9316 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1523/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5343 - val_accuracy: 0.9702\n","Epoch 1524/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5649 - accuracy: 0.9262 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1525/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5599 - accuracy: 0.9331 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1526/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1527/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5635 - accuracy: 0.9280 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1528/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.9267 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1529/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1530/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9257 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1531/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5648 - accuracy: 0.9293 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1532/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5585 - accuracy: 0.9352 - val_loss: 0.5339 - val_accuracy: 0.9709\n","Epoch 1533/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5728 - accuracy: 0.9167 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1534/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1535/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.9311 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1536/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5636 - accuracy: 0.9311 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1537/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9303 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1538/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5622 - accuracy: 0.9324 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1539/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1540/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1541/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5661 - accuracy: 0.9288 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1542/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1543/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.9308 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1544/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5715 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1545/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5604 - accuracy: 0.9324 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1546/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1547/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1548/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1549/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1550/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5641 - accuracy: 0.9295 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1551/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.9288 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1552/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1553/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5644 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1554/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1555/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1556/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5597 - accuracy: 0.9334 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1557/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1558/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5630 - accuracy: 0.9285 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1559/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5620 - accuracy: 0.9298 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1560/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1561/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.9231 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1562/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5635 - accuracy: 0.9280 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1563/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1564/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5652 - accuracy: 0.9254 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 1565/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 1566/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5630 - accuracy: 0.9288 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1567/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1568/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1569/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1570/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1571/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5706 - accuracy: 0.9329 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1572/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1573/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.9231 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1574/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5627 - accuracy: 0.9290 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1575/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5658 - accuracy: 0.9246 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1576/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9254 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1577/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5604 - accuracy: 0.9321 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1578/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1579/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1580/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5641 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1581/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5605 - accuracy: 0.9321 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1582/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.9270 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1583/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5595 - accuracy: 0.9336 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1584/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5600 - accuracy: 0.9329 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1585/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5340 - val_accuracy: 0.9707\n","Epoch 1586/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.9267 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1587/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5645 - accuracy: 0.9264 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1588/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5634 - accuracy: 0.9280 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1589/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9226 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1590/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5601 - accuracy: 0.9329 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1591/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5639 - accuracy: 0.9275 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1592/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5620 - accuracy: 0.9300 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1593/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9277 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1594/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1595/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5655 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1596/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5593 - accuracy: 0.9339 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1597/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5611 - accuracy: 0.9313 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1598/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5656 - accuracy: 0.9249 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1599/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.9275 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1600/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9288 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1601/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5682 - accuracy: 0.9252 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1602/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.9295 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1603/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5596 - accuracy: 0.9334 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1604/10000\n","486/486 [==============================] - 3s 5ms/step - loss: 0.5623 - accuracy: 0.9298 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1605/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.9293 - val_loss: 0.5344 - val_accuracy: 0.9699\n","Epoch 1606/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.9285 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1607/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.9285 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1608/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.9270 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1609/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5639 - accuracy: 0.9272 - val_loss: 0.5345 - val_accuracy: 0.9697\n","Epoch 1610/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.9282 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 1611/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5341 - val_accuracy: 0.9707\n","Epoch 1612/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5657 - accuracy: 0.9288 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1613/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9223 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1614/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5623 - accuracy: 0.9295 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1615/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9262 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1616/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5618 - accuracy: 0.9300 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1617/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1618/10000\n","486/486 [==============================] - 3s 6ms/step - loss: 0.5618 - accuracy: 0.9303 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1619/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.9306 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1620/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9303 - val_loss: 0.5344 - val_accuracy: 0.9697\n","Epoch 1621/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5602 - accuracy: 0.9326 - val_loss: 0.5342 - val_accuracy: 0.9699\n","Epoch 1622/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9259 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1623/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5593 - accuracy: 0.9339 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1624/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5638 - accuracy: 0.9275 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1625/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9259 - val_loss: 0.5341 - val_accuracy: 0.9702\n","Epoch 1626/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9252 - val_loss: 0.5343 - val_accuracy: 0.9699\n","Epoch 1627/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5606 - accuracy: 0.9321 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1628/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.9231 - val_loss: 0.5341 - val_accuracy: 0.9704\n","Epoch 1629/10000\n","486/486 [==============================] - 2s 5ms/step - loss: 0.5651 - accuracy: 0.9290 - val_loss: 0.5342 - val_accuracy: 0.9702\n","Epoch 1630/10000\n","486/486 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.9223 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1631/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5610 - accuracy: 0.9316 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1632/10000\n","486/486 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9262 - val_loss: 0.5340 - val_accuracy: 0.9704\n","Epoch 1633/10000\n","473/486 [============================>.] - ETA: 0s - loss: 0.5628 - accuracy: 0.9273"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [33], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39mlog_dir, histogram_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m subprocess\u001b[39m.\u001b[39mPopen(\u001b[39m\"\u001b[39m\u001b[39mtensorboard --logdir /home/matheus/Devtools/safran-black-belt/logs/fit\u001b[39m\u001b[39m\"\u001b[39m, shell\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m model\u001b[39m.\u001b[39mfit(train_ds,\n\u001b[1;32m     24\u001b[0m           validation_data\u001b[39m=\u001b[39mtrain_ds,\n\u001b[1;32m     25\u001b[0m           epochs\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, \n\u001b[1;32m     26\u001b[0m           callbacks\u001b[39m=\u001b[39m[tensorboard_callback])\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1460\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1457\u001b[0m   val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   1458\u001b[0m   epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1460\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[1;32m   1461\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[1;32m   1462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:416\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    414\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 416\u001b[0m   callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:2508\u001b[0m, in \u001b[0;36mTensorBoard.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_epoch_metrics(epoch, logs)\n\u001b[1;32m   2507\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistogram_freq \u001b[39mand\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistogram_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2508\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_weights(epoch)\n\u001b[1;32m   2510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_freq \u001b[39mand\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2511\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_embeddings(epoch)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:2576\u001b[0m, in \u001b[0;36mTensorBoard._log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   2574\u001b[0m \u001b[39mfor\u001b[39;00m weight \u001b[39min\u001b[39;00m layer\u001b[39m.\u001b[39mweights:\n\u001b[1;32m   2575\u001b[0m   weight_name \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2576\u001b[0m   tf\u001b[39m.\u001b[39;49msummary\u001b[39m.\u001b[39;49mhistogram(weight_name, weight, step\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m   2577\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_images:\n\u001b[1;32m   2578\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_weight_as_image(weight, weight_name, epoch)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorboard/plugins/histogram/summary_v2.py:194\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m@lazy_tensor_creator\u001b[39m\u001b[39m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlazy_tensor\u001b[39m():\n\u001b[1;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m _buckets(data, buckets)\n\u001b[0;32m--> 194\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49msummary\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    195\u001b[0m     tag\u001b[39m=\u001b[39;49mtag,\n\u001b[1;32m    196\u001b[0m     tensor\u001b[39m=\u001b[39;49mlazy_tensor,\n\u001b[1;32m    197\u001b[0m     step\u001b[39m=\u001b[39;49mstep,\n\u001b[1;32m    198\u001b[0m     metadata\u001b[39m=\u001b[39;49msummary_metadata,\n\u001b[1;32m    199\u001b[0m )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/summary_ops_v2.py:769\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies([write_summary_op]):\n\u001b[1;32m    767\u001b[0m       \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39mconstant(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 769\u001b[0m op \u001b[39m=\u001b[39m smart_cond\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[1;32m    770\u001b[0m     should_record_summaries(), record, _nothing, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msummary_cond\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    771\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    772\u001b[0m   ops\u001b[39m.\u001b[39madd_to_collection(ops\u001b[39m.\u001b[39mGraphKeys\u001b[39m.\u001b[39m_SUMMARY_COLLECTION, op)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/smart_cond.py:53\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m pred_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   \u001b[39mif\u001b[39;00m pred_value:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[1;32m     54\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/summary_ops_v2.py:759\u001b[0m, in \u001b[0;36mwrite.<locals>.record\u001b[0;34m()\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu:0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    757\u001b[0m   summary_tensor \u001b[39m=\u001b[39m tensor() \u001b[39mif\u001b[39;00m callable(tensor) \u001b[39melse\u001b[39;00m array_ops\u001b[39m.\u001b[39midentity(\n\u001b[1;32m    758\u001b[0m       tensor)\n\u001b[0;32m--> 759\u001b[0m   write_summary_op \u001b[39m=\u001b[39m gen_summary_ops\u001b[39m.\u001b[39;49mwrite_summary(\n\u001b[1;32m    760\u001b[0m       _summary_state\u001b[39m.\u001b[39;49mwriter\u001b[39m.\u001b[39;49m_resource,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    761\u001b[0m       step,\n\u001b[1;32m    762\u001b[0m       summary_tensor,\n\u001b[1;32m    763\u001b[0m       tag,\n\u001b[1;32m    764\u001b[0m       serialized_metadata,\n\u001b[1;32m    765\u001b[0m       name\u001b[39m=\u001b[39;49mscope)\n\u001b[1;32m    766\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies([write_summary_op]):\n\u001b[1;32m    767\u001b[0m     \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39mconstant(\u001b[39mTrue\u001b[39;00m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_summary_ops.py:700\u001b[0m, in \u001b[0;36mwrite_summary\u001b[0;34m(writer, step, tensor, tag, summary_metadata, name)\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 700\u001b[0m   \u001b[39mreturn\u001b[39;00m write_summary_eager_fallback(\n\u001b[1;32m    701\u001b[0m       writer, step, tensor, tag, summary_metadata, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m    702\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m    703\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_summary_ops.py:720\u001b[0m, in \u001b[0;36mwrite_summary_eager_fallback\u001b[0;34m(writer, step, tensor, tag, summary_metadata, name, ctx)\u001b[0m\n\u001b[1;32m    718\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [writer, step, tensor, tag, summary_metadata]\n\u001b[1;32m    719\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T)\n\u001b[0;32m--> 720\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWriteSummary\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat,\n\u001b[1;32m    721\u001b[0m                            attrs\u001b[39m=\u001b[39;49m_attrs, ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    722\u001b[0m _result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[39mreturn\u001b[39;00m _result\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = tf.keras.Sequential([\n","  feature_layer,\n","  layers.Dense(16, activation='relu'),\n","  layers.Dropout(.75),\n","  layers.Dense(8, activation='relu'),\n","  layers.Dropout(.50),\n","  layers.Dense(4, activation='relu'),\n","  layers.Dropout(.25),\n","  layers.Dense(1, activation='relu'),\n","  layers.Dropout(.125),\n","])\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.16e-3),\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","subprocess.Popen(\"tensorboard --logdir /home/matheus/Devtools/safran-black-belt/logs/fit\", shell=True)\n","\n","model.fit(train_ds,\n","          validation_data=train_ds,\n","          epochs=1000, \n","          callbacks=[tensorboard_callback])\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'QTN_REV_3D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'MEAN_SIZE_3D:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'DRAWING_CODE_2D:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'ATP_2D:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'QTN_REV_2D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'MEAN_SIZE_2D:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'QTY_SHEETS:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'QTY_DIMENSIONS:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'QTY_VIEWS:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'QTY_PART_LIST:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'QTY_TEXT_INFORMATION:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'LEAD_TIME:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'inputs:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'inputs_9:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'inputs_11:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'inputs_8:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'inputs_10:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'inputs:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'inputs_9:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'inputs_11:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'inputs_8:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'inputs_10:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'QTN_REV_3D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'MEAN_SIZE_3D:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'DRAWING_CODE_2D:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'ATP_2D:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'QTN_REV_2D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'MEAN_SIZE_2D:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'QTY_SHEETS:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'QTY_DIMENSIONS:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'QTY_VIEWS:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'QTY_PART_LIST:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'QTY_TEXT_INFORMATION:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'LEAD_TIME:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'QTN_REV_3D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'MEAN_SIZE_3D:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'DRAWING_CODE_2D:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'ATP_2D:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'QTN_REV_2D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'MEAN_SIZE_2D:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'QTY_SHEETS:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'QTY_DIMENSIONS:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'QTY_VIEWS:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'QTY_PART_LIST:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'QTY_TEXT_INFORMATION:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'LEAD_TIME:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Function `_wrapped_model` contains input name(s) ATP_2D, DRAWING_CODE_2D, LEAD_TIME, MEAN_SIZE_2D, MEAN_SIZE_3D, QTN_REV_2D, QTN_REV_3D, QTY_DIMENSIONS, QTY_PART_LIST, QTY_SHEETS, QTY_TEXT_INFORMATION, QTY_VIEWS with unsupported characters which will be renamed to atp_2d, drawing_code_2d, lead_time, mean_size_2d, mean_size_3d, qtn_rev_2d, qtn_rev_3d, qty_dimensions, qty_part_list, qty_sheets, qty_text_information, qty_views in the SavedModel.\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'inputs/QTN_REV_3D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'inputs/MEAN_SIZE_3D:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'inputs/DRAWING_CODE_2D:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'inputs/ATP_2D:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'inputs/QTN_REV_2D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'inputs/MEAN_SIZE_2D:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'inputs/QTY_SHEETS:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'inputs/QTY_DIMENSIONS:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'inputs/QTY_VIEWS:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'inputs/QTY_PART_LIST:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'inputs/QTY_TEXT_INFORMATION:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'inputs/LEAD_TIME:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'inputs/QTN_REV_3D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'inputs/MEAN_SIZE_3D:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'inputs/DRAWING_CODE_2D:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'inputs/ATP_2D:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'inputs/QTN_REV_2D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'inputs/MEAN_SIZE_2D:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'inputs/QTY_SHEETS:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'inputs/QTY_DIMENSIONS:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'inputs/QTY_VIEWS:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'inputs/QTY_PART_LIST:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'inputs/QTY_TEXT_INFORMATION:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'inputs/LEAD_TIME:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'inputs/QTN_REV_3D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'inputs/MEAN_SIZE_3D:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'inputs/DRAWING_CODE_2D:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'inputs/ATP_2D:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'inputs/QTN_REV_2D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'inputs/MEAN_SIZE_2D:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'inputs/QTY_SHEETS:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'inputs/QTY_DIMENSIONS:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'inputs/QTY_VIEWS:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'inputs/QTY_PART_LIST:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'inputs/QTY_TEXT_INFORMATION:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'inputs/LEAD_TIME:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'inputs/QTN_REV_3D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'inputs/MEAN_SIZE_3D:0' shape=(None,) dtype=float64>, 'DRAWING_CODE_2D': <tf.Tensor 'inputs/DRAWING_CODE_2D:0' shape=(None,) dtype=string>, 'ATP_2D': <tf.Tensor 'inputs/ATP_2D:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'inputs/QTN_REV_2D:0' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'inputs/MEAN_SIZE_2D:0' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'inputs/QTY_SHEETS:0' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'inputs/QTY_DIMENSIONS:0' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'inputs/QTY_VIEWS:0' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'inputs/QTY_PART_LIST:0' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'inputs/QTY_TEXT_INFORMATION:0' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'inputs/LEAD_TIME:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: logs/fit/20221018-233529/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: logs/fit/20221018-233529/assets\n"]}],"source":["model.save(log_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss, accuracy = model.evaluate(test_ds)\n","print(\"Accuracy\", accuracy)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1syPlu_EWeKuktOXznQC-wwmgHMFYcc5L","timestamp":1658443470778},{"file_id":"1bEMJfskpHEAw26jo8c-60Nt_qSRbntcT","timestamp":1657765031742},{"file_id":"1xNtEzyOYTQR2P7TtSP0VBDDYK99QzY24","timestamp":1655648351750}]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
