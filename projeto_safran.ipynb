{"cells":[{"cell_type":"code","execution_count":279,"metadata":{},"outputs":[],"source":["import datetime\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import feature_column\n","from tensorflow.keras import layers\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":280,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":23466,"status":"error","timestamp":1664850455528,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"sm3_um-bcJqJ","outputId":"3f8f3fcf-ed1e-4c3d-d599-93d9e1c36eaa"},"outputs":[],"source":["# IF DATA IS IN YOUR DRIVE\n","data = pd.read_excel('BLACK_BELT_DATABASE_CASE_FISRT_ANALISYS.xlsx', header=0)"]},{"cell_type":"code","execution_count":281,"metadata":{"id":"KlbTWqHBcJqL"},"outputs":[],"source":["# Função para pré-processar os dados\n","def preProcessingDataBase(data):\n","\n","    # PART_NUMBER\n","    data = data.drop('PART_NUMBER',axis=1)\n","\n","    # REV\n","    data = data.drop('REV',axis=1)\n","\n","    # DESCRIPTION\n","    data = data.drop('DESCRIPTION',axis=1) #MODIFY TO GROUP BY SIMILARITY\n","\n","    # RELEASED_DATE_1\n","    data = data.drop('RELEASED_DATE_1',axis=1)\n","\n","    # RELEASED_DATE\n","    data = data.drop('RELEASED_DATE',axis=1)\n","\n","    # QTN_REV_3D\n","    data['QTN_REV_3D'] = data['QTN_REV_3D'].dropna()\n","    data['QTN_REV_3D'] = (data['QTN_REV_3D']-data['QTN_REV_3D'].min())/(data['QTN_REV_3D'].max()-data['QTN_REV_3D'].min())\n","\n","    # MEAN_SIZE_3D\n","    data['MEAN_SIZE_3D'] = data['MEAN_SIZE_3D'].dropna()\n","    data['MEAN_SIZE_3D'] = (data['MEAN_SIZE_3D']-data['MEAN_SIZE_3D'].min())/(data['MEAN_SIZE_3D'].max()-data['MEAN_SIZE_3D'].min())\n","\n","    # DRAWING_CODE\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'].dropna()\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'][data['DRAWING_CODE'] != \"EL\"]\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'][data['DRAWING_CODE'] != \"\"]\n","    #data = data.join(pd.get_dummies(data.pop('DRAWING_CODE')))\n","\n","    # ATP\n","    data['ATP'] = data['ATP'].dropna()\n","    data['ATP'] = data['ATP'][data['ATP'] != \"\"]\n","    #data = data.join(pd.get_dummies(data.pop('ATP')))\n","\n","\n","    # QTN_REV_2D\n","    data['QTN_REV_2D'] = data['QTN_REV_2D'].dropna()\n","    data['QTN_REV_2D'] = (data['QTN_REV_2D']-data['QTN_REV_2D'].min())/(data['QTN_REV_2D'].max()-data['QTN_REV_2D'].min())\n","\n","\n","    # QTY_ECN_2D\n","    data['QTY_ECN_2D'] = data['QTY_ECN_2D'].dropna()\n","    data['QTY_ECN_2D'] = pd.Series(np.searchsorted(['BOM', 'RUIM'], data.QTY_ECN_2D.values), data.index)\n","    #data['QTY_ECN_2D'] = (data['QTY_ECN_2D']-data['QTY_ECN_2D'].min())/(data['QTY_ECN_2D'].max()-data['QTY_ECN_2D'].min())\n","\n","\n","    # QTY_ECN_2D_1\n","    data = data.drop('QTY_ECN_2D_1',axis=1)\n","\n","\n","    # MEAN_SIZE_2D\n","    data['MEAN_SIZE_2D'] = data['MEAN_SIZE_2D'].dropna()\n","    data['MEAN_SIZE_2D'] = (data['MEAN_SIZE_2D']-data['MEAN_SIZE_2D'].min())/(data['MEAN_SIZE_2D'].max()-data['MEAN_SIZE_2D'].min())\n","\n","\n","    # QTY_SHEETS\n","    data['QTY_SHEETS'] = data['QTY_SHEETS'].dropna()\n","    data['QTY_SHEETS'] = (data['QTY_SHEETS']-data['QTY_SHEETS'].min())/(data['QTY_SHEETS'].max()-data['QTY_SHEETS'].min())\n","\n","    # QTY_DIMENSIONS\n","    data['QTY_DIMENSIONS'] = data['QTY_DIMENSIONS'].dropna()\n","    data['QTY_DIMENSIONS'] = (data['QTY_DIMENSIONS']-data['QTY_DIMENSIONS'].min())/(data['QTY_DIMENSIONS'].max()-data['QTY_DIMENSIONS'].min())\n","\n","    # QTY_VIEWS\n","    data['QTY_VIEWS'] = data['QTY_VIEWS'].dropna()\n","    data['QTY_VIEWS'] = (data['QTY_VIEWS']-data['QTY_VIEWS'].min())/(data['QTY_VIEWS'].max()-data['QTY_VIEWS'].min())\n","\n","    # QTY_PART_LIST\n","    data['QTY_PART_LIST'] = data['QTY_PART_LIST'].dropna()\n","    data['QTY_PART_LIST'] = (data['QTY_PART_LIST']-data['QTY_PART_LIST'].min())/(data['QTY_PART_LIST'].max()-data['QTY_PART_LIST'].min())\n","\n","    # QTY_TEXT_INFORMATION\n","    data['QTY_TEXT_INFORMATION'] = data['QTY_TEXT_INFORMATION'].dropna()\n","    data['QTY_TEXT_INFORMATION'] = (data['QTY_TEXT_INFORMATION']-data['QTY_TEXT_INFORMATION'].min())/(data['QTY_TEXT_INFORMATION'].max()-data['QTY_TEXT_INFORMATION'].min())\n","\n","    # COMPLETED_ON\n","    data = data.drop('COMPLETED_ON',axis=1)\n","\n","    # COMPLETED_ON_1\n","    data = data.drop('COMPLETED_ON_1',axis=1)\n","\n","    # CREATED_ON\n","    data = data.drop('CREATED_ON',axis=1)\n","\n","    # CREATED_ON_1\n","    data = data.drop('CREATED_ON_1',axis=1)\n","\n","    # LEAD_TIME_1\n","    data = data.drop('LEAD_TIME_1',axis=1)\n","\n","    # LEAD_TIME\n","    data['LEAD_TIME'] = data['LEAD_TIME'].dropna()\n","    data['LEAD_TIME'] = data['LEAD_TIME'][data['LEAD_TIME'] > 0]\n","    data['LEAD_TIME'] = (data['LEAD_TIME']-data['LEAD_TIME'].min())/(data['LEAD_TIME'].max()-data['LEAD_TIME'].min())\n","\n","    # TRIM_AND_FINISH\n","    data['TRIM_AND_FINISH'] = data['TRIM_AND_FINISH'].dropna()\n","    data['TRIM_AND_FINISH'] = (data['TRIM_AND_FINISH']*-1)\n","\n","    # LEAD_TIME\n","    data['LEAD_TO_RELEASE'] = data['LEAD_TO_RELEASE'].dropna()\n","    data['LEAD_TO_RELEASE'] = data['LEAD_TO_RELEASE'][data['LEAD_TO_RELEASE'] > 0]\n","    data['LEAD_TO_RELEASE'] = (data['LEAD_TO_RELEASE']-data['LEAD_TO_RELEASE'].min())/(data['LEAD_TO_RELEASE'].max()-data['LEAD_TO_RELEASE'].min())\n","\n","    # DROP ANY ROW NULL\n","    data = data.dropna()\n","\n","    return data"]},{"cell_type":"code","execution_count":282,"metadata":{"id":"7heJVrDIcJqM"},"outputs":[],"source":["# Pré-processing\n","data = preProcessingDataBase(data)\n","data, validation_data = train_test_split(data, test_size=0.01)\n","validation_data, test_data = train_test_split(validation_data, test_size=0.5)"]},{"cell_type":"code","execution_count":283,"metadata":{},"outputs":[],"source":["def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n","  dataframe = dataframe.copy()\n","  labels = dataframe.pop('QTY_ECN_2D')\n","  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n","  if shuffle:\n","    ds = ds.shuffle(buffer_size=len(dataframe))\n","  ds = ds.batch(batch_size)\n","  return ds"]},{"cell_type":"code","execution_count":284,"metadata":{},"outputs":[],"source":["feature_columns = []\n","\n","for header in ['QTN_REV_3D', 'MEAN_SIZE_3D', 'QTN_REV_2D', 'MEAN_SIZE_2D', 'QTY_SHEETS', 'QTY_DIMENSIONS', 'QTY_VIEWS', 'QTY_PART_LIST', 'QTY_TEXT_INFORMATION', 'LEAD_TIME', 'TRIM_AND_FINISH', 'LEAD_TO_RELEASE']:\n","  feature_columns.append(feature_column.numeric_column(header))\n","\n","\n","feature_columns.append(feature_column.embedding_column(feature_column.categorical_column_with_vocabulary_list('ATP', data.ATP.unique()), dimension=8))\n","feature_columns.append(feature_column.embedding_column(feature_column.categorical_column_with_vocabulary_list('DRAWING_CODE', data.DRAWING_CODE.unique()), dimension=8))"]},{"cell_type":"code","execution_count":285,"metadata":{},"outputs":[],"source":["feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"]},{"cell_type":"code","execution_count":286,"metadata":{},"outputs":[],"source":["batch_size = 2\n","train_ds = df_to_dataset(data, batch_size=batch_size)\n","validation_ds = df_to_dataset(validation_data, shuffle=False, batch_size=batch_size)\n","test_ds = df_to_dataset(test_data, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":290,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10000\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'DRAWING_CODE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'TRIM_AND_FINISH': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'LEAD_TO_RELEASE': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'DRAWING_CODE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'TRIM_AND_FINISH': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'LEAD_TO_RELEASE': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","1335/1337 [============================>.] - ETA: 0s - loss: 0.7533 - accuracy: 0.7539WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'MEAN_SIZE_3D': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'DRAWING_CODE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'MEAN_SIZE_2D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'QTY_SHEETS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'QTY_DIMENSIONS': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'QTY_VIEWS': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'QTY_PART_LIST': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'QTY_TEXT_INFORMATION': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'TRIM_AND_FINISH': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'LEAD_TO_RELEASE': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","1337/1337 [==============================] - 37s 22ms/step - loss: 0.7532 - accuracy: 0.7536 - val_loss: 0.6993 - val_accuracy: 0.7745\n","Epoch 2/10000\n","1337/1337 [==============================] - 30s 23ms/step - loss: 0.7623 - accuracy: 0.7457 - val_loss: 0.6991 - val_accuracy: 0.7745\n","Epoch 3/10000\n","1337/1337 [==============================] - 34s 25ms/step - loss: 0.7414 - accuracy: 0.7521 - val_loss: 0.6990 - val_accuracy: 0.7745\n","Epoch 4/10000\n","1337/1337 [==============================] - 29s 22ms/step - loss: 0.7737 - accuracy: 0.7468 - val_loss: 0.6988 - val_accuracy: 0.7745\n","Epoch 5/10000\n","1337/1337 [==============================] - 30s 22ms/step - loss: 0.7479 - accuracy: 0.7539 - val_loss: 0.6986 - val_accuracy: 0.7745\n","Epoch 6/10000\n","1337/1337 [==============================] - 27s 20ms/step - loss: 0.7544 - accuracy: 0.7532 - val_loss: 0.6984 - val_accuracy: 0.7745\n","Epoch 7/10000\n","1337/1337 [==============================] - 28s 21ms/step - loss: 0.7408 - accuracy: 0.7521 - val_loss: 0.6983 - val_accuracy: 0.7745\n","Epoch 8/10000\n","1337/1337 [==============================] - 27s 20ms/step - loss: 0.7691 - accuracy: 0.7408 - val_loss: 0.6981 - val_accuracy: 0.7745\n","Epoch 9/10000\n","1337/1337 [==============================] - 43s 32ms/step - loss: 0.7593 - accuracy: 0.7453 - val_loss: 0.6979 - val_accuracy: 0.7745\n","Epoch 10/10000\n","1337/1337 [==============================] - 27s 20ms/step - loss: 0.7554 - accuracy: 0.7554 - val_loss: 0.6978 - val_accuracy: 0.7745\n","Epoch 11/10000\n","1337/1337 [==============================] - 28s 21ms/step - loss: 0.7479 - accuracy: 0.7592 - val_loss: 0.6976 - val_accuracy: 0.7745\n","Epoch 12/10000\n","1337/1337 [==============================] - 30s 22ms/step - loss: 0.7425 - accuracy: 0.7468 - val_loss: 0.6975 - val_accuracy: 0.7745\n","Epoch 13/10000\n","1337/1337 [==============================] - 30s 22ms/step - loss: 0.7733 - accuracy: 0.7483 - val_loss: 0.6973 - val_accuracy: 0.7745\n","Epoch 14/10000\n","1337/1337 [==============================] - 35s 26ms/step - loss: 0.7681 - accuracy: 0.7509 - val_loss: 0.6972 - val_accuracy: 0.7745\n","Epoch 15/10000\n","1337/1337 [==============================] - 29s 21ms/step - loss: 0.7482 - accuracy: 0.7550 - val_loss: 0.6971 - val_accuracy: 0.7745\n","Epoch 16/10000\n","1337/1337 [==============================] - 14s 10ms/step - loss: 0.7500 - accuracy: 0.7562 - val_loss: 0.6969 - val_accuracy: 0.7745\n","Epoch 17/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7523 - accuracy: 0.7532 - val_loss: 0.6968 - val_accuracy: 0.7745\n","Epoch 18/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7547 - accuracy: 0.7491 - val_loss: 0.6966 - val_accuracy: 0.7745\n","Epoch 19/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7437 - accuracy: 0.7562 - val_loss: 0.6965 - val_accuracy: 0.7745\n","Epoch 20/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7575 - accuracy: 0.7532 - val_loss: 0.6964 - val_accuracy: 0.7745\n","Epoch 21/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7739 - accuracy: 0.7532 - val_loss: 0.6963 - val_accuracy: 0.7745\n","Epoch 22/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7502 - accuracy: 0.7494 - val_loss: 0.6961 - val_accuracy: 0.7745\n","Epoch 23/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7506 - accuracy: 0.7580 - val_loss: 0.6960 - val_accuracy: 0.7745\n","Epoch 24/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7531 - accuracy: 0.7506 - val_loss: 0.6959 - val_accuracy: 0.7745\n","Epoch 25/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7597 - accuracy: 0.7513 - val_loss: 0.6958 - val_accuracy: 0.7745\n","Epoch 26/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7405 - accuracy: 0.7528 - val_loss: 0.6957 - val_accuracy: 0.7745\n","Epoch 27/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7575 - accuracy: 0.7539 - val_loss: 0.6956 - val_accuracy: 0.7745\n","Epoch 28/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7427 - accuracy: 0.7562 - val_loss: 0.6955 - val_accuracy: 0.7745\n","Epoch 29/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7585 - accuracy: 0.7476 - val_loss: 0.6954 - val_accuracy: 0.7745\n","Epoch 30/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7476 - accuracy: 0.7517 - val_loss: 0.6953 - val_accuracy: 0.7745\n","Epoch 31/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7429 - accuracy: 0.7554 - val_loss: 0.6952 - val_accuracy: 0.7745\n","Epoch 32/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7520 - accuracy: 0.7536 - val_loss: 0.6951 - val_accuracy: 0.7745\n","Epoch 33/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7408 - accuracy: 0.7517 - val_loss: 0.6950 - val_accuracy: 0.7745\n","Epoch 34/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7499 - accuracy: 0.7498 - val_loss: 0.6949 - val_accuracy: 0.7745\n","Epoch 35/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7719 - accuracy: 0.7483 - val_loss: 0.6948 - val_accuracy: 0.7745\n","Epoch 36/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7428 - accuracy: 0.7577 - val_loss: 0.6948 - val_accuracy: 0.7745\n","Epoch 37/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7603 - accuracy: 0.7554 - val_loss: 0.6947 - val_accuracy: 0.7745\n","Epoch 38/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7527 - accuracy: 0.7513 - val_loss: 0.6946 - val_accuracy: 0.7745\n","Epoch 39/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7526 - accuracy: 0.7539 - val_loss: 0.6946 - val_accuracy: 0.7745\n","Epoch 40/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7489 - accuracy: 0.7547 - val_loss: 0.6945 - val_accuracy: 0.7745\n","Epoch 41/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7491 - accuracy: 0.7565 - val_loss: 0.6944 - val_accuracy: 0.7745\n","Epoch 42/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7502 - accuracy: 0.7592 - val_loss: 0.6944 - val_accuracy: 0.7745\n","Epoch 43/10000\n","1337/1337 [==============================] - 11s 9ms/step - loss: 0.7371 - accuracy: 0.7543 - val_loss: 0.6943 - val_accuracy: 0.7745\n","Epoch 44/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7579 - accuracy: 0.7498 - val_loss: 0.6943 - val_accuracy: 0.7745\n","Epoch 45/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7476 - accuracy: 0.7569 - val_loss: 0.6942 - val_accuracy: 0.7745\n","Epoch 46/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7353 - accuracy: 0.7580 - val_loss: 0.6942 - val_accuracy: 0.7745\n","Epoch 47/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7659 - accuracy: 0.7513 - val_loss: 0.6941 - val_accuracy: 0.7745\n","Epoch 48/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7485 - accuracy: 0.7543 - val_loss: 0.6941 - val_accuracy: 0.7745\n","Epoch 49/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7572 - accuracy: 0.7487 - val_loss: 0.6940 - val_accuracy: 0.7745\n","Epoch 50/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7407 - accuracy: 0.7509 - val_loss: 0.6940 - val_accuracy: 0.7745\n","Epoch 51/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7434 - accuracy: 0.7569 - val_loss: 0.6939 - val_accuracy: 0.7745\n","Epoch 52/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7395 - accuracy: 0.7554 - val_loss: 0.6939 - val_accuracy: 0.7745\n","Epoch 53/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7345 - accuracy: 0.7532 - val_loss: 0.6938 - val_accuracy: 0.7745\n","Epoch 54/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7512 - accuracy: 0.7506 - val_loss: 0.6938 - val_accuracy: 0.7745\n","Epoch 55/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7539 - accuracy: 0.7483 - val_loss: 0.6938 - val_accuracy: 0.7745\n","Epoch 56/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7497 - accuracy: 0.7539 - val_loss: 0.6937 - val_accuracy: 0.7745\n","Epoch 57/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7356 - accuracy: 0.7565 - val_loss: 0.6937 - val_accuracy: 0.7745\n","Epoch 58/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7359 - accuracy: 0.7595 - val_loss: 0.6937 - val_accuracy: 0.7745\n","Epoch 59/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7350 - accuracy: 0.7569 - val_loss: 0.6936 - val_accuracy: 0.7745\n","Epoch 60/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7445 - accuracy: 0.7536 - val_loss: 0.6936 - val_accuracy: 0.7745\n","Epoch 61/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7510 - accuracy: 0.7577 - val_loss: 0.6936 - val_accuracy: 0.7745\n","Epoch 62/10000\n","1337/1337 [==============================] - 11s 9ms/step - loss: 0.7321 - accuracy: 0.7573 - val_loss: 0.6936 - val_accuracy: 0.7745\n","Epoch 63/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7602 - accuracy: 0.7464 - val_loss: 0.6936 - val_accuracy: 0.7745\n","Epoch 64/10000\n","1337/1337 [==============================] - 11s 9ms/step - loss: 0.7574 - accuracy: 0.7532 - val_loss: 0.6935 - val_accuracy: 0.7745\n","Epoch 65/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7461 - accuracy: 0.7550 - val_loss: 0.6935 - val_accuracy: 0.7745\n","Epoch 66/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7368 - accuracy: 0.7569 - val_loss: 0.6935 - val_accuracy: 0.7745\n","Epoch 67/10000\n","1337/1337 [==============================] - 11s 9ms/step - loss: 0.7334 - accuracy: 0.7588 - val_loss: 0.6935 - val_accuracy: 0.7745\n","Epoch 68/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7313 - accuracy: 0.7554 - val_loss: 0.6935 - val_accuracy: 0.7745\n","Epoch 69/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7379 - accuracy: 0.7521 - val_loss: 0.6935 - val_accuracy: 0.7745\n","Epoch 70/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7508 - accuracy: 0.7494 - val_loss: 0.6935 - val_accuracy: 0.7745\n","Epoch 71/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7479 - accuracy: 0.7547 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 72/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7289 - accuracy: 0.7603 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 73/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7535 - accuracy: 0.7479 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 74/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7653 - accuracy: 0.7479 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 75/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7463 - accuracy: 0.7528 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 76/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7371 - accuracy: 0.7547 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 77/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7526 - accuracy: 0.7573 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 78/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7452 - accuracy: 0.7580 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 79/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7452 - accuracy: 0.7577 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 80/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7311 - accuracy: 0.7573 - val_loss: 0.6934 - val_accuracy: 0.7745\n","Epoch 81/10000\n","1337/1337 [==============================] - 7s 5ms/step - loss: 0.7525 - accuracy: 0.7565 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 82/10000\n","1337/1337 [==============================] - 7s 5ms/step - loss: 0.7519 - accuracy: 0.7573 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 83/10000\n","1337/1337 [==============================] - 7s 5ms/step - loss: 0.7381 - accuracy: 0.7573 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 84/10000\n","1337/1337 [==============================] - 9s 6ms/step - loss: 0.7411 - accuracy: 0.7554 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 85/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7448 - accuracy: 0.7506 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 86/10000\n","1337/1337 [==============================] - 9s 7ms/step - loss: 0.7465 - accuracy: 0.7569 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 87/10000\n","1337/1337 [==============================] - 9s 6ms/step - loss: 0.7420 - accuracy: 0.7517 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 88/10000\n","1337/1337 [==============================] - 9s 6ms/step - loss: 0.7243 - accuracy: 0.7625 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 89/10000\n","1337/1337 [==============================] - 9s 6ms/step - loss: 0.7438 - accuracy: 0.7592 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 90/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7303 - accuracy: 0.7577 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 91/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7433 - accuracy: 0.7521 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 92/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7215 - accuracy: 0.7655 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 93/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7535 - accuracy: 0.7532 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 94/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7372 - accuracy: 0.7543 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 95/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7455 - accuracy: 0.7539 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 96/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7319 - accuracy: 0.7577 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 97/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7474 - accuracy: 0.7532 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 98/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7350 - accuracy: 0.7565 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 99/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7269 - accuracy: 0.7569 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 100/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7308 - accuracy: 0.7562 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 101/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7278 - accuracy: 0.7580 - val_loss: 0.6933 - val_accuracy: 0.7745\n","Epoch 102/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7492 - accuracy: 0.7524 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 103/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7494 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 104/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7460 - accuracy: 0.7524 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 105/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7326 - accuracy: 0.7569 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 106/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7412 - accuracy: 0.7599 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 107/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7391 - accuracy: 0.7558 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 108/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7216 - accuracy: 0.7584 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 109/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7453 - accuracy: 0.7521 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 110/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7445 - accuracy: 0.7521 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 111/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7460 - accuracy: 0.7543 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 112/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7438 - accuracy: 0.7547 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 113/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7544 - accuracy: 0.7502 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 114/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7406 - accuracy: 0.7539 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 115/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7225 - accuracy: 0.7622 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 116/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7260 - accuracy: 0.7588 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 117/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7328 - accuracy: 0.7603 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 118/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7351 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 119/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7253 - accuracy: 0.7610 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 120/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7283 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 121/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7388 - accuracy: 0.7539 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 122/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7322 - accuracy: 0.7599 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 123/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7480 - accuracy: 0.7517 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 124/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7313 - accuracy: 0.7573 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 125/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7375 - accuracy: 0.7573 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 126/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7339 - accuracy: 0.7603 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 127/10000\n","1337/1337 [==============================] - 10s 7ms/step - loss: 0.7275 - accuracy: 0.7577 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 128/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7346 - accuracy: 0.7539 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 129/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7323 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 130/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7365 - accuracy: 0.7524 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 131/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7294 - accuracy: 0.7573 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 132/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7279 - accuracy: 0.7599 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 133/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7310 - accuracy: 0.7618 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 134/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7276 - accuracy: 0.7577 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 135/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7492 - accuracy: 0.7536 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 136/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7286 - accuracy: 0.7592 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 137/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7319 - accuracy: 0.7588 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 138/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7331 - accuracy: 0.7565 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 139/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7293 - accuracy: 0.7614 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 140/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7348 - accuracy: 0.7588 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 141/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7350 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 142/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7246 - accuracy: 0.7618 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 143/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7384 - accuracy: 0.7547 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 144/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7412 - accuracy: 0.7569 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 145/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7211 - accuracy: 0.7644 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 146/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7316 - accuracy: 0.7607 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 147/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7259 - accuracy: 0.7610 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 148/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7251 - accuracy: 0.7565 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 149/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7335 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 150/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7487 - accuracy: 0.7577 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 151/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7211 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 152/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7302 - accuracy: 0.7607 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 153/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7224 - accuracy: 0.7603 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 154/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7359 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 155/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7248 - accuracy: 0.7614 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 156/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7299 - accuracy: 0.7573 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 157/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7209 - accuracy: 0.7610 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 158/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7281 - accuracy: 0.7603 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 159/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7295 - accuracy: 0.7573 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 160/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7224 - accuracy: 0.7629 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 161/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7506 - accuracy: 0.7502 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 162/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7385 - accuracy: 0.7554 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 163/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7443 - accuracy: 0.7532 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 164/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7287 - accuracy: 0.7622 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 165/10000\n","1337/1337 [==============================] - 10s 7ms/step - loss: 0.7228 - accuracy: 0.7603 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 166/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7329 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 167/10000\n","1337/1337 [==============================] - 12s 9ms/step - loss: 0.7232 - accuracy: 0.7607 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 168/10000\n","1337/1337 [==============================] - 7s 6ms/step - loss: 0.7238 - accuracy: 0.7633 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 169/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7280 - accuracy: 0.7592 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 170/10000\n","1337/1337 [==============================] - 7s 5ms/step - loss: 0.7327 - accuracy: 0.7625 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 171/10000\n","1337/1337 [==============================] - 10s 7ms/step - loss: 0.7214 - accuracy: 0.7622 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 172/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7218 - accuracy: 0.7625 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 173/10000\n","1337/1337 [==============================] - 7s 5ms/step - loss: 0.7443 - accuracy: 0.7607 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 174/10000\n","1337/1337 [==============================] - 6s 5ms/step - loss: 0.7313 - accuracy: 0.7599 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 175/10000\n","1337/1337 [==============================] - 11s 8ms/step - loss: 0.7248 - accuracy: 0.7622 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 176/10000\n","1337/1337 [==============================] - 9s 7ms/step - loss: 0.7283 - accuracy: 0.7577 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 177/10000\n","1337/1337 [==============================] - 8s 6ms/step - loss: 0.7335 - accuracy: 0.7595 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 178/10000\n","1337/1337 [==============================] - 7s 6ms/step - loss: 0.7253 - accuracy: 0.7580 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 179/10000\n","1337/1337 [==============================] - 7s 5ms/step - loss: 0.7251 - accuracy: 0.7622 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 180/10000\n","1337/1337 [==============================] - 6s 5ms/step - loss: 0.7176 - accuracy: 0.7625 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 181/10000\n","1337/1337 [==============================] - 9s 7ms/step - loss: 0.7176 - accuracy: 0.7625 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 182/10000\n","1337/1337 [==============================] - 10s 7ms/step - loss: 0.7247 - accuracy: 0.7607 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 183/10000\n","1337/1337 [==============================] - 9s 7ms/step - loss: 0.7260 - accuracy: 0.7607 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 184/10000\n","1337/1337 [==============================] - 9s 6ms/step - loss: 0.7244 - accuracy: 0.7577 - val_loss: 0.6932 - val_accuracy: 0.7745\n","Epoch 185/10000\n"," 363/1337 [=======>......................] - ETA: 4s - loss: 0.7469 - accuracy: 0.7479"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [290], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs/fit/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m tensorboard_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39mlog_dir, histogram_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_ds,\n\u001b[1;32m     22\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39mtrain_ds,\n\u001b[1;32m     23\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, \n\u001b[1;32m     24\u001b[0m           callbacks\u001b[38;5;241m=\u001b[39m[tensorboard_callback])\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:495\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    493\u001b[0m attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mexecutor_type\u001b[39m\u001b[39m\"\u001b[39m, executor_type, \u001b[39m\"\u001b[39m\u001b[39mconfig_proto\u001b[39m\u001b[39m\"\u001b[39m, config)\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m executing_eagerly:\n\u001b[0;32m--> 495\u001b[0m   \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m       outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m    498\u001b[0m           \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    499\u001b[0m           num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m    500\u001b[0m           inputs\u001b[39m=\u001b[39margs,\n\u001b[1;32m    501\u001b[0m           attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m    502\u001b[0m           ctx\u001b[39m=\u001b[39mctx)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = tf.keras.Sequential([\n","  feature_layer,\n","  layers.Dense(16, activation='relu'),\n","  layers.Dropout(.9),\n","  layers.Dense(8, activation='relu'),\n","  layers.Dropout(0.75),\n","  layers.Dense(4, activation='relu'),\n","  layers.Dropout(.50),\n","  layers.Dense(1, activation='relu'),\n","  layers.Dropout(.25),\n","])\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","model.fit(train_ds,\n","          validation_data=train_ds,\n","          epochs=10000, \n","          callbacks=[tensorboard_callback])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss, accuracy = model.evaluate(test_ds)\n","print(\"Accuracy\", accuracy)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1syPlu_EWeKuktOXznQC-wwmgHMFYcc5L","timestamp":1658443470778},{"file_id":"1bEMJfskpHEAw26jo8c-60Nt_qSRbntcT","timestamp":1657765031742},{"file_id":"1xNtEzyOYTQR2P7TtSP0VBDDYK99QzY24","timestamp":1655648351750}]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
