{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import datetime\n","import subprocess\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns \n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow import feature_column\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":23466,"status":"error","timestamp":1664850455528,"user":{"displayName":"Matheus Gomes de Almeida Moreira da Silva","userId":"01394349635488107455"},"user_tz":180},"id":"sm3_um-bcJqJ","outputId":"3f8f3fcf-ed1e-4c3d-d599-93d9e1c36eaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6264 entries, 0 to 6263\n","Data columns (total 35 columns):\n"," #   Column                Non-Null Count  Dtype         \n","---  ------                --------------  -----         \n"," 0   PART_NUMBER           6264 non-null   object        \n"," 1   REV                   6264 non-null   object        \n"," 2   DESCRIPTION           6264 non-null   object        \n"," 3   CONFIGURATION         6264 non-null   object        \n"," 4   RELEASED_DATE         6264 non-null   datetime64[ns]\n"," 5   OBJECT_ID_3D          6262 non-null   float64       \n"," 6   FILE_NAME_3D          0 non-null      float64       \n"," 7   CLASS_3D              6264 non-null   object        \n"," 8   DRAWING_CODE_3D       6259 non-null   object        \n"," 9   ATP_3D                6262 non-null   object        \n"," 10  QTN_REV_3D            6264 non-null   int64         \n"," 11  MEAN_SIZE_3D          1697 non-null   object        \n"," 12  OBJECT_ID_2D          6264 non-null   int64         \n"," 13  FILE_NAME_2D          0 non-null      float64       \n"," 14  CLASS_2D              6264 non-null   object        \n"," 15  DRAWING_CODE          6260 non-null   object        \n"," 16  ATP                   6264 non-null   object        \n"," 17  QTN_REV_2D            6264 non-null   int64         \n"," 18  QTY_ECN_2D            6264 non-null   int64         \n"," 19  MEAN_SIZE_2D          1640 non-null   float64       \n"," 20  QTY_SHEETS            1636 non-null   float64       \n"," 21  QTY_DIMENSIONS        1636 non-null   float64       \n"," 22  QTY_VIEWS             1636 non-null   float64       \n"," 23  QTY_PART_LIST         1635 non-null   float64       \n"," 24  QTY_TEXT_INFORMATION  1636 non-null   float64       \n"," 25  WORKFLOW              6256 non-null   object        \n"," 26  CREATED_ON            6256 non-null   datetime64[ns]\n"," 27  COMPLETED_ON          6241 non-null   datetime64[ns]\n"," 28  LEAD_TIME             5802 non-null   float64       \n"," 29  NEW_DESIGN            0 non-null      float64       \n"," 30  TRIM_AND_FINISH       1638 non-null   float64       \n"," 31  COMPLEXITY            764 non-null    object        \n"," 32  RTF                   764 non-null    float64       \n"," 33  HOV                   764 non-null    float64       \n"," 34  NEW_DEV               764 non-null    float64       \n","dtypes: datetime64[ns](3), float64(15), int64(4), object(13)\n","memory usage: 1.7+ MB\n"]}],"source":["# IF DATA IS IN YOUR DRIVE\n","data = pd.read_excel('BLACK_BELT_DATABASE_CASE_COMPLETE_TESTE.xlsx', header=0)\n","data.info()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KlbTWqHBcJqL"},"outputs":[],"source":["# Função para pré-processar os dados\n","def preProcessingDataBase(data):\n","\n","    to_drop = ['NEW_DEV',\n","               'HOV',\n","               'RTF',\n","               'COMPLEXITY',\n","               'CREATED_ON',\n","               'COMPLETED_ON',\n","               'CLASS_2D',\n","               'PART_NUMBER',\n","               'REV',\n","               'DESCRIPTION',\n","               'CONFIGURATION',\n","               'RELEASED_DATE',\n","               'OBJECT_ID_3D',\n","               'FILE_NAME_3D',\n","               'CLASS_3D',\n","               'DRAWING_CODE_3D',\n","               'ATP_3D',\n","               'OBJECT_ID_2D',\n","               'FILE_NAME_2D',\n","               'MEAN_SIZE_3D',\n","               'MEAN_SIZE_2D', \n","               'QTY_SHEETS',\n","               'QTY_DIMENSIONS',\n","               'QTY_VIEWS',\n","               'QTY_PART_LIST',\n","               'QTY_TEXT_INFORMATION',\n","               'TRIM_AND_FINISH',\n","               'NEW_DESIGN']\n","\n","    data.drop(to_drop, inplace=True, axis=1)\n","\n","    # QTN_REV_3D\n","    data = data[~data['QTN_REV_3D'].isnull()]\n","    data['QTN_REV_3D'] = data['QTN_REV_3D'].dropna()\n","    data['QTN_REV_3D'] = (data['QTN_REV_3D']-data['QTN_REV_3D'].min())/(data['QTN_REV_3D'].max()-data['QTN_REV_3D'].min())\n","\n","    # WORKFLOW\n","    data = data[~data['WORKFLOW'].isnull()]\n","    data['WORKFLOW'] = data['WORKFLOW'].dropna()\n","\n","    # DRAWING_CODE\n","    data = data[~data['DRAWING_CODE'].isnull()]\n","    data['DRAWING_CODE'] = data['DRAWING_CODE'].dropna()\n","    #data = data.join(pd.get_dummies(data.pop('DRAWING_CODE')))\n","\n","    # ATP\n","    data = data[~data['ATP'].isnull()]\n","    data['ATP'] = data['ATP'].dropna()\n","    #data = data.join(pd.get_dummies(data.pop('ATP')))\n","\n","    # QTN_REV_2D\n","    data = data[~data['QTN_REV_2D'].isnull()]\n","    data['ATP'] = data['QTN_REV_2D'].dropna()\n","    data['QTN_REV_2D'] = (data['QTN_REV_2D']-data['QTN_REV_2D'].min())/(data['QTN_REV_2D'].max()-data['QTN_REV_2D'].min())\n","\n","    # QTY_ECN_2D\n","    data = data[~data['QTY_ECN_2D'].isnull()]\n","    data['QTY_ECN_2D'] = data['QTY_ECN_2D'].dropna()\n","    data.loc[(data.QTY_ECN_2D != 0), 'QTY_ECN_2D'] = \"RUIM\"\n","    data.loc[(data.QTY_ECN_2D == 0), 'QTY_ECN_2D'] = \"BOM\"\n","    data['QTY_ECN_2D'] = pd.Series(np.searchsorted(['BOM', 'RUIM'], data.QTY_ECN_2D.values), data.index)\n","    #data['QTY_ECN_2D'] = (data['QTY_ECN_2D']-data['QTY_ECN_2D'].min())/(data['QTY_ECN_2D'].max()-data['QTY_ECN_2D'].min())\n","\n","    # LEAD_TIME\n","    data = data[~data['LEAD_TIME'].isnull()]\n","    data['LEAD_TIME'] = data['LEAD_TIME'].dropna()\n","    data['LEAD_TIME'] = data['LEAD_TIME'][data['LEAD_TIME'] > 0]\n","    data['LEAD_TIME'] = data['LEAD_TIME'].astype('int')\n","    data['LEAD_TIME'] = (data['LEAD_TIME']-data['LEAD_TIME'].min())/(data['LEAD_TIME'].max()-data['LEAD_TIME'].min())\n","\n","    # DROP ANY ROW NULL\n","    #data = data.dropna()\n","\n","    return data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 5793 entries, 0 to 6136\n","Data columns (total 7 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   QTN_REV_3D    5793 non-null   float64\n"," 1   DRAWING_CODE  5793 non-null   object \n"," 2   ATP           5793 non-null   int64  \n"," 3   QTN_REV_2D    5793 non-null   float64\n"," 4   QTY_ECN_2D    5793 non-null   int64  \n"," 5   WORKFLOW      5793 non-null   object \n"," 6   LEAD_TIME     5793 non-null   float64\n","dtypes: float64(3), int64(2), object(2)\n","memory usage: 362.1+ KB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>QTN_REV_3D</th>\n","      <th>DRAWING_CODE</th>\n","      <th>ATP</th>\n","      <th>QTN_REV_2D</th>\n","      <th>QTY_ECN_2D</th>\n","      <th>WORKFLOW</th>\n","      <th>LEAD_TIME</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.111111</td>\n","      <td>PL</td>\n","      <td>1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>SJ_Process-163227</td>\n","      <td>0.082192</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.111111</td>\n","      <td>DA</td>\n","      <td>1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>SJ_Process-163703</td>\n","      <td>0.065332</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.111111</td>\n","      <td>NM</td>\n","      <td>1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>SJ_Process-163703</td>\n","      <td>0.065332</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.222222</td>\n","      <td>IN</td>\n","      <td>2</td>\n","      <td>0.125</td>\n","      <td>1</td>\n","      <td>GG_Process-029086</td>\n","      <td>0.062171</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.111111</td>\n","      <td>TA</td>\n","      <td>1</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>SJ_Process-163420</td>\n","      <td>0.076923</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   QTN_REV_3D DRAWING_CODE  ATP  QTN_REV_2D  QTY_ECN_2D           WORKFLOW  \\\n","0    0.111111           PL    1       0.000           0  SJ_Process-163227   \n","1    0.111111           DA    1       0.000           0  SJ_Process-163703   \n","2    0.111111           NM    1       0.000           0  SJ_Process-163703   \n","3    0.222222           IN    2       0.125           1  GG_Process-029086   \n","4    0.111111           TA    1       0.000           0  SJ_Process-163420   \n","\n","   LEAD_TIME  \n","0   0.082192  \n","1   0.065332  \n","2   0.065332  \n","3   0.062171  \n","4   0.076923  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data = preProcessingDataBase(data)\n","data.info()\n","data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7heJVrDIcJqM"},"outputs":[],"source":["# Post pré-processing\n","data, validation_data = train_test_split(data, test_size=0.3)\n","validation_data, test_data = train_test_split(validation_data, test_size=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Contar saídas\n","data[\"QTY_ECN_2D\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Balancear saídas\n","data = data.groupby('QTY_ECN_2D').sample(n=5600)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Visualizar\n","sample_data = data.sample(frac=0.3)\n","sns.pairplot(sample_data, hue=\"QTY_ECN_2D\", palette=\"tab10\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n","  dataframe = dataframe.copy()\n","  labels = dataframe.pop('QTY_ECN_2D')\n","  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n","  if shuffle:\n","    ds = ds.shuffle(buffer_size=len(dataframe))\n","  ds = ds.batch(batch_size)\n","  return ds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["to_feature = ['QTN_REV_3D', \n","              'MEAN_SIZE_3D', \n","              'QTN_REV_2D', \n","              'MEAN_SIZE_2D', \n","              'QTY_SHEETS', \n","              'QTY_DIMENSIONS', \n","              'QTY_VIEWS', \n","              'QTY_PART_LIST', \n","              'QTY_TEXT_INFORMATION', \n","              'LEAD_TIME', \n","              'TRIM_AND_FINISH', \n","              'LEAD_TO_RELEASE']"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["feature_columns = []\n","\n","to_feature = ['QTN_REV_3D', \n","              'QTN_REV_2D', \n","              'LEAD_TIME']\n","\n","for header in to_feature:\n","  feature_columns.append(feature_column.numeric_column(header))\n","\n","\n","feature_columns.append(feature_column.embedding_column(feature_column.categorical_column_with_vocabulary_list('ATP', data.ATP.unique()), dimension=8))\n","feature_columns.append(feature_column.embedding_column(feature_column.categorical_column_with_vocabulary_list('WORKFLOW', data.DRAWING_CODE.unique()), dimension=8))\n","feature_columns.append(feature_column.embedding_column(feature_column.categorical_column_with_vocabulary_list('DRAWING_CODE', data.DRAWING_CODE.unique()), dimension=8))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-10-07 11:43:54.364040: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n","2022-10-07 11:43:54.364074: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: matheus-notebook\n","2022-10-07 11:43:54.364082: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: matheus-notebook\n","2022-10-07 11:43:54.364236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.85.2\n","2022-10-07 11:43:54.364268: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.1\n","2022-10-07 11:43:54.364278: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 515.65.1 does not match DSO version 510.85.2 -- cannot find working devices in this configuration\n","2022-10-07 11:43:54.365624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["batch_size = 8\n","train_ds = df_to_dataset(data, shuffle=True, batch_size=batch_size)\n","validation_ds = df_to_dataset(validation_data, shuffle=True, batch_size=batch_size)\n","test_ds = df_to_dataset(test_data, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10000\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'DRAWING_CODE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'WORKFLOW': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'DRAWING_CODE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'WORKFLOW': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","497/507 [============================>.] - ETA: 0s - loss: 0.8100 - accuracy: 0.6114WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'QTN_REV_3D': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'DRAWING_CODE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'ATP': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'QTN_REV_2D': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'WORKFLOW': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'LEAD_TIME': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n","507/507 [==============================] - 5s 6ms/step - loss: 0.8108 - accuracy: 0.6104 - val_loss: 0.7519 - val_accuracy: 0.5573\n","Epoch 2/10000\n","507/507 [==============================] - 3s 6ms/step - loss: 0.8014 - accuracy: 0.6340 - val_loss: 0.7478 - val_accuracy: 0.6020\n","Epoch 3/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7976 - accuracy: 0.6313 - val_loss: 0.7438 - val_accuracy: 0.6074\n","Epoch 4/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.7927 - accuracy: 0.6412 - val_loss: 0.7398 - val_accuracy: 0.6089\n","Epoch 5/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7866 - accuracy: 0.6375 - val_loss: 0.7361 - val_accuracy: 0.6091\n","Epoch 6/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7787 - accuracy: 0.6560 - val_loss: 0.7323 - val_accuracy: 0.6099\n","Epoch 7/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7818 - accuracy: 0.6439 - val_loss: 0.7286 - val_accuracy: 0.9088\n","Epoch 8/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7696 - accuracy: 0.6678 - val_loss: 0.7249 - val_accuracy: 0.9551\n","Epoch 9/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7720 - accuracy: 0.6609 - val_loss: 0.7212 - val_accuracy: 0.9593\n","Epoch 10/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7657 - accuracy: 0.6658 - val_loss: 0.7176 - val_accuracy: 0.9620\n","Epoch 11/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7656 - accuracy: 0.6649 - val_loss: 0.7140 - val_accuracy: 0.9620\n","Epoch 12/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7637 - accuracy: 0.6691 - val_loss: 0.7104 - val_accuracy: 0.9625\n","Epoch 13/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7566 - accuracy: 0.6792 - val_loss: 0.7068 - val_accuracy: 0.9625\n","Epoch 14/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7565 - accuracy: 0.6735 - val_loss: 0.7033 - val_accuracy: 0.9625\n","Epoch 15/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7501 - accuracy: 0.6873 - val_loss: 0.6997 - val_accuracy: 0.9625\n","Epoch 16/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7441 - accuracy: 0.6964 - val_loss: 0.6963 - val_accuracy: 0.9625\n","Epoch 17/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7427 - accuracy: 0.6937 - val_loss: 0.6928 - val_accuracy: 0.9625\n","Epoch 18/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.7465 - accuracy: 0.6930 - val_loss: 0.6894 - val_accuracy: 0.9625\n","Epoch 19/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.7337 - accuracy: 0.7041 - val_loss: 0.6860 - val_accuracy: 0.9625\n","Epoch 20/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7413 - accuracy: 0.6959 - val_loss: 0.6827 - val_accuracy: 0.9625\n","Epoch 21/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.7340 - accuracy: 0.7085 - val_loss: 0.6794 - val_accuracy: 0.9625\n","Epoch 22/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.7270 - accuracy: 0.7152 - val_loss: 0.6762 - val_accuracy: 0.9625\n","Epoch 23/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7251 - accuracy: 0.7285 - val_loss: 0.6731 - val_accuracy: 0.9625\n","Epoch 24/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7263 - accuracy: 0.7233 - val_loss: 0.6698 - val_accuracy: 0.9625\n","Epoch 25/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7124 - accuracy: 0.7485 - val_loss: 0.6668 - val_accuracy: 0.9625\n","Epoch 26/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7186 - accuracy: 0.7309 - val_loss: 0.6637 - val_accuracy: 0.9625\n","Epoch 27/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7160 - accuracy: 0.7423 - val_loss: 0.6607 - val_accuracy: 0.9625\n","Epoch 28/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7116 - accuracy: 0.7504 - val_loss: 0.6577 - val_accuracy: 0.9625\n","Epoch 29/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7083 - accuracy: 0.7514 - val_loss: 0.6548 - val_accuracy: 0.9625\n","Epoch 30/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7012 - accuracy: 0.7670 - val_loss: 0.6520 - val_accuracy: 0.9623\n","Epoch 31/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6991 - accuracy: 0.7687 - val_loss: 0.6491 - val_accuracy: 0.9620\n","Epoch 32/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.7027 - accuracy: 0.7620 - val_loss: 0.6462 - val_accuracy: 0.9620\n","Epoch 33/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6908 - accuracy: 0.7859 - val_loss: 0.6435 - val_accuracy: 0.9618\n","Epoch 34/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6905 - accuracy: 0.7894 - val_loss: 0.6407 - val_accuracy: 0.9618\n","Epoch 35/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6911 - accuracy: 0.7872 - val_loss: 0.6379 - val_accuracy: 0.9618\n","Epoch 36/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6840 - accuracy: 0.7988 - val_loss: 0.6352 - val_accuracy: 0.9618\n","Epoch 37/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6863 - accuracy: 0.7998 - val_loss: 0.6325 - val_accuracy: 0.9618\n","Epoch 38/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6823 - accuracy: 0.7988 - val_loss: 0.6299 - val_accuracy: 0.9618\n","Epoch 39/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6785 - accuracy: 0.8185 - val_loss: 0.6272 - val_accuracy: 0.9618\n","Epoch 40/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6774 - accuracy: 0.8141 - val_loss: 0.6247 - val_accuracy: 0.9618\n","Epoch 41/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6735 - accuracy: 0.8254 - val_loss: 0.6222 - val_accuracy: 0.9618\n","Epoch 42/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6720 - accuracy: 0.8168 - val_loss: 0.6197 - val_accuracy: 0.9618\n","Epoch 43/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6683 - accuracy: 0.8296 - val_loss: 0.6172 - val_accuracy: 0.9618\n","Epoch 44/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.6667 - accuracy: 0.8296 - val_loss: 0.6148 - val_accuracy: 0.9618\n","Epoch 45/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6645 - accuracy: 0.8333 - val_loss: 0.6124 - val_accuracy: 0.9618\n","Epoch 46/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6630 - accuracy: 0.8343 - val_loss: 0.6100 - val_accuracy: 0.9618\n","Epoch 47/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6636 - accuracy: 0.8427 - val_loss: 0.6079 - val_accuracy: 0.9618\n","Epoch 48/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6581 - accuracy: 0.8478 - val_loss: 0.6058 - val_accuracy: 0.9618\n","Epoch 49/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6570 - accuracy: 0.8461 - val_loss: 0.6039 - val_accuracy: 0.9618\n","Epoch 50/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6573 - accuracy: 0.8473 - val_loss: 0.6021 - val_accuracy: 0.9618\n","Epoch 51/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6508 - accuracy: 0.8631 - val_loss: 0.6003 - val_accuracy: 0.9618\n","Epoch 52/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.8607 - val_loss: 0.5986 - val_accuracy: 0.9618\n","Epoch 53/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6474 - accuracy: 0.8649 - val_loss: 0.5969 - val_accuracy: 0.9618\n","Epoch 54/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.8644 - val_loss: 0.5952 - val_accuracy: 0.9618\n","Epoch 55/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.8787 - val_loss: 0.5935 - val_accuracy: 0.9618\n","Epoch 56/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6403 - accuracy: 0.8787 - val_loss: 0.5918 - val_accuracy: 0.9618\n","Epoch 57/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6421 - accuracy: 0.8725 - val_loss: 0.5901 - val_accuracy: 0.9618\n","Epoch 58/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6391 - accuracy: 0.8762 - val_loss: 0.5884 - val_accuracy: 0.9618\n","Epoch 59/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.8895 - val_loss: 0.5867 - val_accuracy: 0.9618\n","Epoch 60/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.8883 - val_loss: 0.5851 - val_accuracy: 0.9618\n","Epoch 61/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.8935 - val_loss: 0.5835 - val_accuracy: 0.9618\n","Epoch 62/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6302 - accuracy: 0.8925 - val_loss: 0.5819 - val_accuracy: 0.9618\n","Epoch 63/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6303 - accuracy: 0.8930 - val_loss: 0.5803 - val_accuracy: 0.9618\n","Epoch 64/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6311 - accuracy: 0.8915 - val_loss: 0.5787 - val_accuracy: 0.9618\n","Epoch 65/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.8945 - val_loss: 0.5771 - val_accuracy: 0.9618\n","Epoch 66/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6269 - accuracy: 0.8984 - val_loss: 0.5754 - val_accuracy: 0.9618\n","Epoch 67/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.9038 - val_loss: 0.5739 - val_accuracy: 0.9618\n","Epoch 68/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.9004 - val_loss: 0.5725 - val_accuracy: 0.9618\n","Epoch 69/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.9051 - val_loss: 0.5712 - val_accuracy: 0.9618\n","Epoch 70/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6191 - accuracy: 0.9065 - val_loss: 0.5699 - val_accuracy: 0.9618\n","Epoch 71/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6211 - accuracy: 0.9006 - val_loss: 0.5687 - val_accuracy: 0.9618\n","Epoch 72/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6147 - accuracy: 0.9097 - val_loss: 0.5675 - val_accuracy: 0.9618\n","Epoch 73/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.9097 - val_loss: 0.5663 - val_accuracy: 0.9618\n","Epoch 74/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6171 - accuracy: 0.9060 - val_loss: 0.5650 - val_accuracy: 0.9618\n","Epoch 75/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6130 - accuracy: 0.9095 - val_loss: 0.5638 - val_accuracy: 0.9618\n","Epoch 76/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6083 - accuracy: 0.9191 - val_loss: 0.5627 - val_accuracy: 0.9618\n","Epoch 77/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6082 - accuracy: 0.9139 - val_loss: 0.5619 - val_accuracy: 0.9618\n","Epoch 78/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.6032 - accuracy: 0.9250 - val_loss: 0.5616 - val_accuracy: 0.9618\n","Epoch 79/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6097 - accuracy: 0.9107 - val_loss: 0.5614 - val_accuracy: 0.9618\n","Epoch 80/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6095 - accuracy: 0.9115 - val_loss: 0.5612 - val_accuracy: 0.9618\n","Epoch 81/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6054 - accuracy: 0.9191 - val_loss: 0.5609 - val_accuracy: 0.9618\n","Epoch 82/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6023 - accuracy: 0.9211 - val_loss: 0.5607 - val_accuracy: 0.9618\n","Epoch 83/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6035 - accuracy: 0.9203 - val_loss: 0.5604 - val_accuracy: 0.9618\n","Epoch 84/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6047 - accuracy: 0.9147 - val_loss: 0.5602 - val_accuracy: 0.9618\n","Epoch 85/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6001 - accuracy: 0.9179 - val_loss: 0.5600 - val_accuracy: 0.9618\n","Epoch 86/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6001 - accuracy: 0.9184 - val_loss: 0.5598 - val_accuracy: 0.9618\n","Epoch 87/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6004 - accuracy: 0.9176 - val_loss: 0.5595 - val_accuracy: 0.9618\n","Epoch 88/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5968 - accuracy: 0.9223 - val_loss: 0.5593 - val_accuracy: 0.9618\n","Epoch 89/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6009 - accuracy: 0.9179 - val_loss: 0.5591 - val_accuracy: 0.9618\n","Epoch 90/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.6017 - accuracy: 0.9132 - val_loss: 0.5588 - val_accuracy: 0.9618\n","Epoch 91/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5954 - accuracy: 0.9245 - val_loss: 0.5586 - val_accuracy: 0.9618\n","Epoch 92/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5964 - accuracy: 0.9208 - val_loss: 0.5584 - val_accuracy: 0.9618\n","Epoch 93/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5974 - accuracy: 0.9201 - val_loss: 0.5582 - val_accuracy: 0.9618\n","Epoch 94/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5953 - accuracy: 0.9236 - val_loss: 0.5580 - val_accuracy: 0.9618\n","Epoch 95/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5918 - accuracy: 0.9255 - val_loss: 0.5578 - val_accuracy: 0.9618\n","Epoch 96/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5961 - accuracy: 0.9191 - val_loss: 0.5576 - val_accuracy: 0.9618\n","Epoch 97/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5960 - accuracy: 0.9186 - val_loss: 0.5574 - val_accuracy: 0.9618\n","Epoch 98/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5938 - accuracy: 0.9201 - val_loss: 0.5572 - val_accuracy: 0.9618\n","Epoch 99/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5918 - accuracy: 0.9228 - val_loss: 0.5570 - val_accuracy: 0.9618\n","Epoch 100/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5909 - accuracy: 0.9236 - val_loss: 0.5567 - val_accuracy: 0.9618\n","Epoch 101/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5895 - accuracy: 0.9250 - val_loss: 0.5566 - val_accuracy: 0.9618\n","Epoch 102/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5937 - accuracy: 0.9159 - val_loss: 0.5564 - val_accuracy: 0.9618\n","Epoch 103/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5908 - accuracy: 0.9201 - val_loss: 0.5562 - val_accuracy: 0.9618\n","Epoch 104/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5929 - accuracy: 0.9174 - val_loss: 0.5560 - val_accuracy: 0.9618\n","Epoch 105/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5880 - accuracy: 0.9243 - val_loss: 0.5558 - val_accuracy: 0.9618\n","Epoch 106/10000\n","507/507 [==============================] - 3s 5ms/step - loss: 0.5894 - accuracy: 0.9238 - val_loss: 0.5556 - val_accuracy: 0.9618\n","Epoch 107/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5859 - accuracy: 0.9285 - val_loss: 0.5554 - val_accuracy: 0.9618\n","Epoch 108/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5883 - accuracy: 0.9199 - val_loss: 0.5552 - val_accuracy: 0.9618\n","Epoch 109/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5855 - accuracy: 0.9245 - val_loss: 0.5550 - val_accuracy: 0.9618\n","Epoch 110/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5872 - accuracy: 0.9248 - val_loss: 0.5548 - val_accuracy: 0.9618\n","Epoch 111/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5868 - accuracy: 0.9231 - val_loss: 0.5547 - val_accuracy: 0.9618\n","Epoch 112/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5851 - accuracy: 0.9255 - val_loss: 0.5545 - val_accuracy: 0.9618\n","Epoch 113/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5858 - accuracy: 0.9228 - val_loss: 0.5543 - val_accuracy: 0.9618\n","Epoch 114/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5815 - accuracy: 0.9295 - val_loss: 0.5541 - val_accuracy: 0.9618\n","Epoch 115/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5872 - accuracy: 0.9196 - val_loss: 0.5540 - val_accuracy: 0.9618\n","Epoch 116/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5859 - accuracy: 0.9248 - val_loss: 0.5538 - val_accuracy: 0.9618\n","Epoch 117/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5852 - accuracy: 0.9226 - val_loss: 0.5536 - val_accuracy: 0.9618\n","Epoch 118/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5857 - accuracy: 0.9228 - val_loss: 0.5534 - val_accuracy: 0.9618\n","Epoch 119/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5835 - accuracy: 0.9238 - val_loss: 0.5533 - val_accuracy: 0.9618\n","Epoch 120/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5854 - accuracy: 0.9206 - val_loss: 0.5531 - val_accuracy: 0.9618\n","Epoch 121/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5821 - accuracy: 0.9253 - val_loss: 0.5529 - val_accuracy: 0.9618\n","Epoch 122/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5836 - accuracy: 0.9228 - val_loss: 0.5528 - val_accuracy: 0.9618\n","Epoch 123/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5828 - accuracy: 0.9255 - val_loss: 0.5526 - val_accuracy: 0.9618\n","Epoch 124/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5831 - accuracy: 0.9233 - val_loss: 0.5525 - val_accuracy: 0.9618\n","Epoch 125/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5851 - accuracy: 0.9206 - val_loss: 0.5523 - val_accuracy: 0.9618\n","Epoch 126/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5827 - accuracy: 0.9240 - val_loss: 0.5521 - val_accuracy: 0.9618\n","Epoch 127/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5821 - accuracy: 0.9238 - val_loss: 0.5520 - val_accuracy: 0.9618\n","Epoch 128/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5801 - accuracy: 0.9260 - val_loss: 0.5518 - val_accuracy: 0.9618\n","Epoch 129/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5844 - accuracy: 0.9199 - val_loss: 0.5517 - val_accuracy: 0.9618\n","Epoch 130/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5813 - accuracy: 0.9240 - val_loss: 0.5515 - val_accuracy: 0.9618\n","Epoch 131/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5803 - accuracy: 0.9238 - val_loss: 0.5514 - val_accuracy: 0.9618\n","Epoch 132/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5824 - accuracy: 0.9231 - val_loss: 0.5513 - val_accuracy: 0.9618\n","Epoch 133/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5815 - accuracy: 0.9238 - val_loss: 0.5511 - val_accuracy: 0.9618\n","Epoch 134/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5792 - accuracy: 0.9270 - val_loss: 0.5510 - val_accuracy: 0.9618\n","Epoch 135/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5793 - accuracy: 0.9255 - val_loss: 0.5508 - val_accuracy: 0.9618\n","Epoch 136/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5788 - accuracy: 0.9265 - val_loss: 0.5507 - val_accuracy: 0.9618\n","Epoch 137/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5816 - accuracy: 0.9206 - val_loss: 0.5505 - val_accuracy: 0.9618\n","Epoch 138/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5797 - accuracy: 0.9236 - val_loss: 0.5504 - val_accuracy: 0.9618\n","Epoch 139/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5802 - accuracy: 0.9238 - val_loss: 0.5503 - val_accuracy: 0.9618\n","Epoch 140/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5783 - accuracy: 0.9268 - val_loss: 0.5501 - val_accuracy: 0.9618\n","Epoch 141/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5770 - accuracy: 0.9277 - val_loss: 0.5500 - val_accuracy: 0.9618\n","Epoch 142/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5787 - accuracy: 0.9275 - val_loss: 0.5499 - val_accuracy: 0.9618\n","Epoch 143/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5782 - accuracy: 0.9260 - val_loss: 0.5497 - val_accuracy: 0.9618\n","Epoch 144/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5821 - accuracy: 0.9208 - val_loss: 0.5496 - val_accuracy: 0.9618\n","Epoch 145/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5792 - accuracy: 0.9250 - val_loss: 0.5495 - val_accuracy: 0.9618\n","Epoch 146/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5772 - accuracy: 0.9277 - val_loss: 0.5494 - val_accuracy: 0.9618\n","Epoch 147/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5779 - accuracy: 0.9240 - val_loss: 0.5493 - val_accuracy: 0.9618\n","Epoch 148/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.9275 - val_loss: 0.5491 - val_accuracy: 0.9618\n","Epoch 149/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5794 - accuracy: 0.9238 - val_loss: 0.5490 - val_accuracy: 0.9618\n","Epoch 150/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5791 - accuracy: 0.9263 - val_loss: 0.5489 - val_accuracy: 0.9620\n","Epoch 151/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5800 - accuracy: 0.9211 - val_loss: 0.5488 - val_accuracy: 0.9620\n","Epoch 152/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5773 - accuracy: 0.9260 - val_loss: 0.5487 - val_accuracy: 0.9620\n","Epoch 153/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5763 - accuracy: 0.9277 - val_loss: 0.5486 - val_accuracy: 0.9625\n","Epoch 154/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5756 - accuracy: 0.9282 - val_loss: 0.5484 - val_accuracy: 0.9628\n","Epoch 155/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5785 - accuracy: 0.9231 - val_loss: 0.5483 - val_accuracy: 0.9628\n","Epoch 156/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5765 - accuracy: 0.9292 - val_loss: 0.5482 - val_accuracy: 0.9628\n","Epoch 157/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5787 - accuracy: 0.9260 - val_loss: 0.5481 - val_accuracy: 0.9628\n","Epoch 158/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5789 - accuracy: 0.9240 - val_loss: 0.5480 - val_accuracy: 0.9628\n","Epoch 159/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5764 - accuracy: 0.9277 - val_loss: 0.5479 - val_accuracy: 0.9628\n","Epoch 160/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5762 - accuracy: 0.9277 - val_loss: 0.5478 - val_accuracy: 0.9628\n","Epoch 161/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5770 - accuracy: 0.9268 - val_loss: 0.5477 - val_accuracy: 0.9628\n","Epoch 162/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5756 - accuracy: 0.9270 - val_loss: 0.5476 - val_accuracy: 0.9628\n","Epoch 163/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5758 - accuracy: 0.9273 - val_loss: 0.5475 - val_accuracy: 0.9628\n","Epoch 164/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5767 - accuracy: 0.9268 - val_loss: 0.5474 - val_accuracy: 0.9628\n","Epoch 165/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5763 - accuracy: 0.9275 - val_loss: 0.5473 - val_accuracy: 0.9628\n","Epoch 166/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5762 - accuracy: 0.9258 - val_loss: 0.5472 - val_accuracy: 0.9628\n","Epoch 167/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5791 - accuracy: 0.9223 - val_loss: 0.5471 - val_accuracy: 0.9628\n","Epoch 168/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5760 - accuracy: 0.9253 - val_loss: 0.5470 - val_accuracy: 0.9628\n","Epoch 169/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5773 - accuracy: 0.9238 - val_loss: 0.5469 - val_accuracy: 0.9628\n","Epoch 170/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5760 - accuracy: 0.9265 - val_loss: 0.5469 - val_accuracy: 0.9628\n","Epoch 171/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5760 - accuracy: 0.9250 - val_loss: 0.5468 - val_accuracy: 0.9628\n","Epoch 172/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5745 - accuracy: 0.9290 - val_loss: 0.5467 - val_accuracy: 0.9628\n","Epoch 173/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5760 - accuracy: 0.9260 - val_loss: 0.5466 - val_accuracy: 0.9628\n","Epoch 174/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5752 - accuracy: 0.9268 - val_loss: 0.5465 - val_accuracy: 0.9628\n","Epoch 175/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5771 - accuracy: 0.9253 - val_loss: 0.5464 - val_accuracy: 0.9628\n","Epoch 176/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.9268 - val_loss: 0.5463 - val_accuracy: 0.9628\n","Epoch 177/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5749 - accuracy: 0.9275 - val_loss: 0.5463 - val_accuracy: 0.9628\n","Epoch 178/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5736 - accuracy: 0.9287 - val_loss: 0.5462 - val_accuracy: 0.9628\n","Epoch 179/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5724 - accuracy: 0.9305 - val_loss: 0.5461 - val_accuracy: 0.9628\n","Epoch 180/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5770 - accuracy: 0.9223 - val_loss: 0.5460 - val_accuracy: 0.9628\n","Epoch 181/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5771 - accuracy: 0.9233 - val_loss: 0.5459 - val_accuracy: 0.9628\n","Epoch 182/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5763 - accuracy: 0.9248 - val_loss: 0.5459 - val_accuracy: 0.9628\n","Epoch 183/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5739 - accuracy: 0.9270 - val_loss: 0.5458 - val_accuracy: 0.9628\n","Epoch 184/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5716 - accuracy: 0.9314 - val_loss: 0.5457 - val_accuracy: 0.9628\n","Epoch 185/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5726 - accuracy: 0.9309 - val_loss: 0.5456 - val_accuracy: 0.9628\n","Epoch 186/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5758 - accuracy: 0.9268 - val_loss: 0.5456 - val_accuracy: 0.9628\n","Epoch 187/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5742 - accuracy: 0.9273 - val_loss: 0.5455 - val_accuracy: 0.9628\n","Epoch 188/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.9233 - val_loss: 0.5454 - val_accuracy: 0.9628\n","Epoch 189/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5752 - accuracy: 0.9263 - val_loss: 0.5454 - val_accuracy: 0.9628\n","Epoch 190/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5733 - accuracy: 0.9287 - val_loss: 0.5453 - val_accuracy: 0.9628\n","Epoch 191/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5740 - accuracy: 0.9282 - val_loss: 0.5452 - val_accuracy: 0.9628\n","Epoch 192/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5736 - accuracy: 0.9277 - val_loss: 0.5452 - val_accuracy: 0.9628\n","Epoch 193/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5725 - accuracy: 0.9273 - val_loss: 0.5451 - val_accuracy: 0.9628\n","Epoch 194/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5758 - accuracy: 0.9268 - val_loss: 0.5450 - val_accuracy: 0.9628\n","Epoch 195/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5744 - accuracy: 0.9253 - val_loss: 0.5450 - val_accuracy: 0.9628\n","Epoch 196/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5724 - accuracy: 0.9297 - val_loss: 0.5449 - val_accuracy: 0.9628\n","Epoch 197/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5718 - accuracy: 0.9290 - val_loss: 0.5448 - val_accuracy: 0.9630\n","Epoch 198/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.9339 - val_loss: 0.5448 - val_accuracy: 0.9630\n","Epoch 199/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5718 - accuracy: 0.9300 - val_loss: 0.5447 - val_accuracy: 0.9630\n","Epoch 200/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5734 - accuracy: 0.9265 - val_loss: 0.5447 - val_accuracy: 0.9630\n","Epoch 201/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5735 - accuracy: 0.9290 - val_loss: 0.5446 - val_accuracy: 0.9630\n","Epoch 202/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5737 - accuracy: 0.9263 - val_loss: 0.5445 - val_accuracy: 0.9630\n","Epoch 203/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5731 - accuracy: 0.9285 - val_loss: 0.5445 - val_accuracy: 0.9630\n","Epoch 204/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5725 - accuracy: 0.9300 - val_loss: 0.5444 - val_accuracy: 0.9630\n","Epoch 205/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5726 - accuracy: 0.9270 - val_loss: 0.5444 - val_accuracy: 0.9630\n","Epoch 206/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5725 - accuracy: 0.9285 - val_loss: 0.5443 - val_accuracy: 0.9630\n","Epoch 207/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5733 - accuracy: 0.9285 - val_loss: 0.5443 - val_accuracy: 0.9630\n","Epoch 208/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5714 - accuracy: 0.9302 - val_loss: 0.5442 - val_accuracy: 0.9630\n","Epoch 209/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5724 - accuracy: 0.9287 - val_loss: 0.5441 - val_accuracy: 0.9630\n","Epoch 210/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5749 - accuracy: 0.9231 - val_loss: 0.5441 - val_accuracy: 0.9630\n","Epoch 211/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5718 - accuracy: 0.9280 - val_loss: 0.5440 - val_accuracy: 0.9630\n","Epoch 212/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5699 - accuracy: 0.9322 - val_loss: 0.5440 - val_accuracy: 0.9630\n","Epoch 213/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5702 - accuracy: 0.9319 - val_loss: 0.5439 - val_accuracy: 0.9630\n","Epoch 214/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5713 - accuracy: 0.9282 - val_loss: 0.5439 - val_accuracy: 0.9630\n","Epoch 215/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.9305 - val_loss: 0.5438 - val_accuracy: 0.9630\n","Epoch 216/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5723 - accuracy: 0.9265 - val_loss: 0.5438 - val_accuracy: 0.9630\n","Epoch 217/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.9285 - val_loss: 0.5437 - val_accuracy: 0.9630\n","Epoch 218/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5711 - accuracy: 0.9302 - val_loss: 0.5437 - val_accuracy: 0.9630\n","Epoch 219/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.9258 - val_loss: 0.5436 - val_accuracy: 0.9630\n","Epoch 220/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5706 - accuracy: 0.9285 - val_loss: 0.5436 - val_accuracy: 0.9630\n","Epoch 221/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5711 - accuracy: 0.9305 - val_loss: 0.5435 - val_accuracy: 0.9630\n","Epoch 222/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5730 - accuracy: 0.9268 - val_loss: 0.5435 - val_accuracy: 0.9630\n","Epoch 223/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5741 - accuracy: 0.9253 - val_loss: 0.5435 - val_accuracy: 0.9630\n","Epoch 224/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5739 - accuracy: 0.9255 - val_loss: 0.5434 - val_accuracy: 0.9630\n","Epoch 225/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5695 - accuracy: 0.9302 - val_loss: 0.5434 - val_accuracy: 0.9630\n","Epoch 226/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5701 - accuracy: 0.9295 - val_loss: 0.5433 - val_accuracy: 0.9630\n","Epoch 227/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5726 - accuracy: 0.9270 - val_loss: 0.5433 - val_accuracy: 0.9630\n","Epoch 228/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5717 - accuracy: 0.9265 - val_loss: 0.5433 - val_accuracy: 0.9630\n","Epoch 229/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5702 - accuracy: 0.9300 - val_loss: 0.5432 - val_accuracy: 0.9630\n","Epoch 230/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5729 - accuracy: 0.9265 - val_loss: 0.5432 - val_accuracy: 0.9630\n","Epoch 231/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5701 - accuracy: 0.9295 - val_loss: 0.5431 - val_accuracy: 0.9630\n","Epoch 232/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5718 - accuracy: 0.9277 - val_loss: 0.5431 - val_accuracy: 0.9630\n","Epoch 233/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5721 - accuracy: 0.9280 - val_loss: 0.5431 - val_accuracy: 0.9630\n","Epoch 234/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5713 - accuracy: 0.9275 - val_loss: 0.5430 - val_accuracy: 0.9630\n","Epoch 235/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5689 - accuracy: 0.9327 - val_loss: 0.5430 - val_accuracy: 0.9630\n","Epoch 236/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5705 - accuracy: 0.9290 - val_loss: 0.5429 - val_accuracy: 0.9630\n","Epoch 237/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5715 - accuracy: 0.9273 - val_loss: 0.5429 - val_accuracy: 0.9630\n","Epoch 238/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5718 - accuracy: 0.9290 - val_loss: 0.5429 - val_accuracy: 0.9630\n","Epoch 239/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5716 - accuracy: 0.9268 - val_loss: 0.5428 - val_accuracy: 0.9630\n","Epoch 240/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5731 - accuracy: 0.9240 - val_loss: 0.5428 - val_accuracy: 0.9630\n","Epoch 241/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.9312 - val_loss: 0.5428 - val_accuracy: 0.9630\n","Epoch 242/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.9317 - val_loss: 0.5427 - val_accuracy: 0.9630\n","Epoch 243/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5690 - accuracy: 0.9319 - val_loss: 0.5427 - val_accuracy: 0.9630\n","Epoch 244/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5703 - accuracy: 0.9292 - val_loss: 0.5427 - val_accuracy: 0.9630\n","Epoch 245/10000\n","507/507 [==============================] - 3s 6ms/step - loss: 0.5720 - accuracy: 0.9263 - val_loss: 0.5426 - val_accuracy: 0.9630\n","Epoch 246/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.9319 - val_loss: 0.5426 - val_accuracy: 0.9630\n","Epoch 247/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5717 - accuracy: 0.9270 - val_loss: 0.5426 - val_accuracy: 0.9630\n","Epoch 248/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5714 - accuracy: 0.9265 - val_loss: 0.5425 - val_accuracy: 0.9630\n","Epoch 249/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5704 - accuracy: 0.9297 - val_loss: 0.5425 - val_accuracy: 0.9630\n","Epoch 250/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.9332 - val_loss: 0.5425 - val_accuracy: 0.9630\n","Epoch 251/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.9280 - val_loss: 0.5424 - val_accuracy: 0.9630\n","Epoch 252/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5691 - accuracy: 0.9309 - val_loss: 0.5424 - val_accuracy: 0.9630\n","Epoch 253/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.9317 - val_loss: 0.5424 - val_accuracy: 0.9630\n","Epoch 254/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5651 - accuracy: 0.9354 - val_loss: 0.5424 - val_accuracy: 0.9630\n","Epoch 255/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5690 - accuracy: 0.9309 - val_loss: 0.5423 - val_accuracy: 0.9630\n","Epoch 256/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5711 - accuracy: 0.9273 - val_loss: 0.5423 - val_accuracy: 0.9630\n","Epoch 257/10000\n","507/507 [==============================] - 3s 5ms/step - loss: 0.5667 - accuracy: 0.9337 - val_loss: 0.5423 - val_accuracy: 0.9630\n","Epoch 258/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9327 - val_loss: 0.5422 - val_accuracy: 0.9630\n","Epoch 259/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9359 - val_loss: 0.5422 - val_accuracy: 0.9630\n","Epoch 260/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.9312 - val_loss: 0.5422 - val_accuracy: 0.9630\n","Epoch 261/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.9307 - val_loss: 0.5422 - val_accuracy: 0.9630\n","Epoch 262/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5697 - accuracy: 0.9285 - val_loss: 0.5421 - val_accuracy: 0.9630\n","Epoch 263/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9334 - val_loss: 0.5421 - val_accuracy: 0.9630\n","Epoch 264/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.9337 - val_loss: 0.5421 - val_accuracy: 0.9630\n","Epoch 265/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.9307 - val_loss: 0.5420 - val_accuracy: 0.9630\n","Epoch 266/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5701 - accuracy: 0.9277 - val_loss: 0.5420 - val_accuracy: 0.9630\n","Epoch 267/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5708 - accuracy: 0.9275 - val_loss: 0.5420 - val_accuracy: 0.9630\n","Epoch 268/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5709 - accuracy: 0.9280 - val_loss: 0.5420 - val_accuracy: 0.9630\n","Epoch 269/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5690 - accuracy: 0.9300 - val_loss: 0.5419 - val_accuracy: 0.9630\n","Epoch 270/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5715 - accuracy: 0.9258 - val_loss: 0.5419 - val_accuracy: 0.9630\n","Epoch 271/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5710 - accuracy: 0.9270 - val_loss: 0.5419 - val_accuracy: 0.9630\n","Epoch 272/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.9312 - val_loss: 0.5419 - val_accuracy: 0.9630\n","Epoch 273/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.9314 - val_loss: 0.5419 - val_accuracy: 0.9630\n","Epoch 274/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.9317 - val_loss: 0.5418 - val_accuracy: 0.9630\n","Epoch 275/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.9290 - val_loss: 0.5418 - val_accuracy: 0.9630\n","Epoch 276/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.9309 - val_loss: 0.5418 - val_accuracy: 0.9630\n","Epoch 277/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5659 - accuracy: 0.9339 - val_loss: 0.5418 - val_accuracy: 0.9630\n","Epoch 278/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5691 - accuracy: 0.9287 - val_loss: 0.5417 - val_accuracy: 0.9630\n","Epoch 279/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5705 - accuracy: 0.9270 - val_loss: 0.5417 - val_accuracy: 0.9630\n","Epoch 280/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.9312 - val_loss: 0.5417 - val_accuracy: 0.9630\n","Epoch 281/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5691 - accuracy: 0.9287 - val_loss: 0.5417 - val_accuracy: 0.9630\n","Epoch 282/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5705 - accuracy: 0.9285 - val_loss: 0.5417 - val_accuracy: 0.9630\n","Epoch 283/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5668 - accuracy: 0.9317 - val_loss: 0.5416 - val_accuracy: 0.9630\n","Epoch 284/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.9290 - val_loss: 0.5416 - val_accuracy: 0.9630\n","Epoch 285/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5714 - accuracy: 0.9258 - val_loss: 0.5416 - val_accuracy: 0.9630\n","Epoch 286/10000\n","507/507 [==============================] - 1s 3ms/step - loss: 0.5684 - accuracy: 0.9282 - val_loss: 0.5416 - val_accuracy: 0.9630\n","Epoch 287/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5691 - accuracy: 0.9305 - val_loss: 0.5416 - val_accuracy: 0.9630\n","Epoch 288/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.9332 - val_loss: 0.5415 - val_accuracy: 0.9630\n","Epoch 289/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.9305 - val_loss: 0.5415 - val_accuracy: 0.9630\n","Epoch 290/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.9300 - val_loss: 0.5415 - val_accuracy: 0.9630\n","Epoch 291/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5677 - accuracy: 0.9302 - val_loss: 0.5415 - val_accuracy: 0.9630\n","Epoch 292/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5660 - accuracy: 0.9327 - val_loss: 0.5415 - val_accuracy: 0.9630\n","Epoch 293/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.9327 - val_loss: 0.5414 - val_accuracy: 0.9630\n","Epoch 294/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.9307 - val_loss: 0.5414 - val_accuracy: 0.9630\n","Epoch 295/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5657 - accuracy: 0.9346 - val_loss: 0.5414 - val_accuracy: 0.9630\n","Epoch 296/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5714 - accuracy: 0.9268 - val_loss: 0.5414 - val_accuracy: 0.9630\n","Epoch 297/10000\n","507/507 [==============================] - 3s 6ms/step - loss: 0.5659 - accuracy: 0.9337 - val_loss: 0.5414 - val_accuracy: 0.9630\n","Epoch 298/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.9295 - val_loss: 0.5414 - val_accuracy: 0.9630\n","Epoch 299/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9337 - val_loss: 0.5413 - val_accuracy: 0.9630\n","Epoch 300/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9314 - val_loss: 0.5413 - val_accuracy: 0.9630\n","Epoch 301/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9324 - val_loss: 0.5413 - val_accuracy: 0.9630\n","Epoch 302/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.9297 - val_loss: 0.5413 - val_accuracy: 0.9630\n","Epoch 303/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.9337 - val_loss: 0.5413 - val_accuracy: 0.9630\n","Epoch 304/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.9287 - val_loss: 0.5413 - val_accuracy: 0.9630\n","Epoch 305/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.9317 - val_loss: 0.5412 - val_accuracy: 0.9630\n","Epoch 306/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.9295 - val_loss: 0.5412 - val_accuracy: 0.9630\n","Epoch 307/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9339 - val_loss: 0.5412 - val_accuracy: 0.9630\n","Epoch 308/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9314 - val_loss: 0.5412 - val_accuracy: 0.9630\n","Epoch 309/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.9287 - val_loss: 0.5412 - val_accuracy: 0.9630\n","Epoch 310/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.9319 - val_loss: 0.5412 - val_accuracy: 0.9630\n","Epoch 311/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5694 - accuracy: 0.9273 - val_loss: 0.5411 - val_accuracy: 0.9630\n","Epoch 312/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.9292 - val_loss: 0.5411 - val_accuracy: 0.9630\n","Epoch 313/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.9307 - val_loss: 0.5411 - val_accuracy: 0.9630\n","Epoch 314/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9346 - val_loss: 0.5411 - val_accuracy: 0.9630\n","Epoch 315/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.9287 - val_loss: 0.5411 - val_accuracy: 0.9630\n","Epoch 316/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5690 - accuracy: 0.9270 - val_loss: 0.5411 - val_accuracy: 0.9630\n","Epoch 317/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.9295 - val_loss: 0.5411 - val_accuracy: 0.9630\n","Epoch 318/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.9302 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 319/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.9280 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 320/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9346 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 321/10000\n","507/507 [==============================] - 3s 6ms/step - loss: 0.5712 - accuracy: 0.9250 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 322/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5677 - accuracy: 0.9300 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 323/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.9300 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 324/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.9312 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 325/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5684 - accuracy: 0.9282 - val_loss: 0.5410 - val_accuracy: 0.9630\n","Epoch 326/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.9314 - val_loss: 0.5409 - val_accuracy: 0.9630\n","Epoch 327/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5623 - accuracy: 0.9388 - val_loss: 0.5409 - val_accuracy: 0.9630\n","Epoch 328/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.9290 - val_loss: 0.5409 - val_accuracy: 0.9630\n","Epoch 329/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5655 - accuracy: 0.9334 - val_loss: 0.5409 - val_accuracy: 0.9630\n","Epoch 330/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.9312 - val_loss: 0.5409 - val_accuracy: 0.9630\n","Epoch 331/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.9282 - val_loss: 0.5409 - val_accuracy: 0.9630\n","Epoch 332/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.9282 - val_loss: 0.5409 - val_accuracy: 0.9630\n","Epoch 333/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9302 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 334/10000\n","507/507 [==============================] - 3s 6ms/step - loss: 0.5695 - accuracy: 0.9260 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 335/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5622 - accuracy: 0.9366 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 336/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9334 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 337/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5655 - accuracy: 0.9329 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 338/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9334 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 339/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.9287 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 340/10000\n","507/507 [==============================] - 3s 6ms/step - loss: 0.5691 - accuracy: 0.9277 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 341/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5654 - accuracy: 0.9307 - val_loss: 0.5408 - val_accuracy: 0.9630\n","Epoch 342/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.9361 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 343/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.9346 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 344/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.9300 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 345/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.9300 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 346/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9307 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 347/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9327 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 348/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5698 - accuracy: 0.9253 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 349/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.9307 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 350/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5650 - accuracy: 0.9327 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 351/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5646 - accuracy: 0.9332 - val_loss: 0.5407 - val_accuracy: 0.9630\n","Epoch 352/10000\n","507/507 [==============================] - 2s 5ms/step - loss: 0.5669 - accuracy: 0.9312 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 353/10000\n","507/507 [==============================] - 3s 5ms/step - loss: 0.5653 - accuracy: 0.9322 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 354/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5648 - accuracy: 0.9334 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 355/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5692 - accuracy: 0.9263 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 356/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5676 - accuracy: 0.9292 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 357/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.9346 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 358/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.9285 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 359/10000\n","507/507 [==============================] - 3s 5ms/step - loss: 0.5653 - accuracy: 0.9327 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 360/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.9300 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 361/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.9277 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 362/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9314 - val_loss: 0.5406 - val_accuracy: 0.9630\n","Epoch 363/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.9280 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 364/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.9314 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 365/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.9302 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 366/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.9327 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 367/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.9295 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 368/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5644 - accuracy: 0.9329 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 369/10000\n","507/507 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.9356 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 370/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5642 - accuracy: 0.9339 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 371/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.9319 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 372/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.9302 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 373/10000\n","507/507 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.9329 - val_loss: 0.5405 - val_accuracy: 0.9630\n","Epoch 374/10000\n"," 23/507 [>.............................] - ETA: 1s - loss: 0.5609 - accuracy: 0.9348 "]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [13], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m log_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlogs/fit/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39mlog_dir, histogram_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m model\u001b[39m.\u001b[39mfit(train_ds,\n\u001b[1;32m     20\u001b[0m           validation_data\u001b[39m=\u001b[39mtrain_ds,\n\u001b[1;32m     21\u001b[0m           epochs\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, \n\u001b[1;32m     22\u001b[0m           callbacks\u001b[39m=\u001b[39m[tensorboard_callback])\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = tf.keras.Sequential([\n","  feature_layer,\n","  layers.Dense(16, activation='relu'),\n","  layers.Dropout(.5),\n","  layers.Dense(8, activation='relu'),\n","  layers.Dropout(.25),\n","  layers.Dense(1, activation='relu'),\n","  layers.Dropout(0.125),\n","])\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","subprocess.run(\"tensorboard --logdir /home/matheus/Devtools/safran-black-belt/logs/fit\")\n","\n","model.fit(train_ds,\n","          validation_data=train_ds,\n","          epochs=10000, \n","          callbacks=[tensorboard_callback])\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["109/109 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.9597\n","Accuracy 0.9597238302230835\n"]}],"source":["loss, accuracy = model.evaluate(test_ds)\n","print(\"Accuracy\", accuracy)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1syPlu_EWeKuktOXznQC-wwmgHMFYcc5L","timestamp":1658443470778},{"file_id":"1bEMJfskpHEAw26jo8c-60Nt_qSRbntcT","timestamp":1657765031742},{"file_id":"1xNtEzyOYTQR2P7TtSP0VBDDYK99QzY24","timestamp":1655648351750}]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
